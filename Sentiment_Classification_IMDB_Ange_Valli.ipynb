{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MZMiPrTIAkiU"
   },
   "source": [
    "<a href=\"https://www.kaggle.com/code/angevalli/sentiment-classification/notebook\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a> <a href=\"https://colab.research.google.com/drive/1kZdKcvVXTebR4gh-PKFN4bIq7wxL_oMd\" target=\"_blank\"><img align=\"left\" alt=\"Colab\" title=\"Open In Colab\" src=\"https://colab.research.google.com/assets/colab-badge.svg\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Tm1qSjsAuhi"
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RiFYCsR9ci8w"
   },
   "outputs": [],
   "source": [
    "!wget 'http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz'\n",
    "!tar -xvf /content/aclImdb_v1.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SCKs7oOq383E"
   },
   "source": [
    "## Text classification with Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l-fH84tT383b"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G5ZSEmpy383r"
   },
   "source": [
    "The main interest in us using Pytorch is the ```autograd``` package. ```torch.Tensor```objects have an attribute ```.requires_grad```; if set as True, it starts to track all operations on it. When you finish your computation, can call ```.backward()``` and all the gradients are computed automatically (and stored in the ```.grad``` attribute).\n",
    "\n",
    "One way to easily cut a tensor from the computational once it is not needed anymore is to use ```.detach()```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DknOM4wL383s"
   },
   "outputs": [],
   "source": [
    "x = torch.tensor(1., requires_grad=True)\n",
    "w = torch.tensor(2., requires_grad=True)\n",
    "b = torch.tensor(3., requires_grad=True)\n",
    "\n",
    "# Build a computational graph.\n",
    "y = w * x + b    # y = 2 * x + 3\n",
    "\n",
    "# Compute gradients.\n",
    "y.backward()\n",
    "\n",
    "# Print out the gradients.\n",
    "print(x.grad)    # x.grad = 2 \n",
    "print(w.grad)    # w.grad = 1 \n",
    "print(b.grad)    # b.grad = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qOWnO0Np383v"
   },
   "outputs": [],
   "source": [
    "x = torch.randn(10, 3)\n",
    "y = torch.randn(10, 2)\n",
    "\n",
    "# Build a fully connected layer.\n",
    "linear = nn.Linear(3, 2)\n",
    "for name, p in linear.named_parameters():\n",
    "    print(name)\n",
    "    print(p)\n",
    "\n",
    "# Build loss function - Mean Square Error\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Forward pass.\n",
    "pred = linear(x)\n",
    "\n",
    "# Compute loss.\n",
    "loss = criterion(pred, y)\n",
    "print('Initial loss: ', loss.item())\n",
    "\n",
    "# Backward pass.\n",
    "loss.backward()\n",
    "\n",
    "# Print out the gradients.\n",
    "print ('dL/dw: ', linear.weight.grad) \n",
    "print ('dL/db: ', linear.bias.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2vH9gsMg383z"
   },
   "outputs": [],
   "source": [
    "# You can perform gradient descent manually, with an in-place update ...\n",
    "linear.weight.data.sub_(0.01 * linear.weight.grad.data)\n",
    "linear.bias.data.sub_(0.01 * linear.bias.grad.data)\n",
    "\n",
    "# Print out the loss after 1-step gradient descent.\n",
    "pred = linear(x)\n",
    "loss = criterion(pred, y)\n",
    "print('Loss after one update: ', loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XULb7tlU3834"
   },
   "outputs": [],
   "source": [
    "# Use the optim package to define an Optimizer that will update the weights of the model.\n",
    "optimizer = torch.optim.SGD(linear.parameters(), lr=0.01)\n",
    "\n",
    "# By default, gradients are accumulated in buffers( i.e, not overwritten) whenever .backward()\n",
    "# is called. Before the backward pass, we need to use the optimizer object to zero all of the\n",
    "# gradients.\n",
    "optimizer.zero_grad()\n",
    "loss.backward()\n",
    "\n",
    "# Calling the step function on an Optimizer makes an update to its parameters\n",
    "optimizer.step()\n",
    "\n",
    "# Print out the loss after the second step of gradient descent.\n",
    "pred = linear(x)\n",
    "loss = criterion(pred, y)\n",
    "print('Loss after two updates: ', loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dE7kgqt93836"
   },
   "source": [
    "### Tools for data processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CRevuIi63836"
   },
   "outputs": [],
   "source": [
    "toy_corpus = ['I walked down down the boulevard',\n",
    "              'I walked down the avenue',\n",
    "              'I ran down the boulevard',\n",
    "              'I walk down the city',\n",
    "              'I walk down the the avenue']\n",
    "\n",
    "toy_categories = [0, 0, 1, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UTpc6CIz3837"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    # A pytorch dataset class for holding data for a text classification task.\n",
    "    def __init__(self, data, categories):\n",
    "        # Upon creating the Dataset object, store the data in an attribute\n",
    "        # Split the text data and labels from each other\n",
    "        self.X, self.Y = [], []\n",
    "        for x, y in zip(data, categories):\n",
    "            # We will propably need to preprocess the data - have it done in a separate method\n",
    "            # We do it here because we might need corpus-wide info to do the preprocessing \n",
    "            # For example, cutting all examples to the same length\n",
    "            self.X.append(self.preprocess(x))\n",
    "            self.Y.append(y)\n",
    "                \n",
    "    # Method allowing you to preprocess data                      \n",
    "    def preprocess(self, text):\n",
    "        text_pp = text.lower().strip()\n",
    "        return text_pp\n",
    "    \n",
    "    # Overriding the method __len__ so that len(CustomDatasetName) returns the number of data samples                     \n",
    "    def __len__(self):\n",
    "        return len(self.Y)\n",
    "   \n",
    "    # Overriding the method __getitem__ so that CustomDatasetName[i] returns the i-th sample of the dataset                      \n",
    "    def __getitem__(self, idx):\n",
    "           return self.X[idx], self.Y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mo4ftfao3838"
   },
   "outputs": [],
   "source": [
    "toy_dataset = CustomDataset(toy_corpus, toy_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k5zGirEc3838"
   },
   "outputs": [],
   "source": [
    "print(len(toy_dataset))\n",
    "for i in range(len(toy_dataset)):\n",
    "    print(toy_dataset[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "32ebRYmG383_"
   },
   "source": [
    "```torch.utils.data.DataLoader``` is what we call an iterator, which provides very useful features:\n",
    "- Batching the data\n",
    "- Shuffling the data\n",
    "- Load the data in parallel using multiprocessing workers.\n",
    "and can be created very simply from a ```Dataset```. Continuing on our simple example: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jYdMpAok383_"
   },
   "outputs": [],
   "source": [
    "toy_dataloader = DataLoader(toy_dataset, batch_size = 2, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "En0VWyg-384B",
    "outputId": "02accf33-b5a6-49b9-d83f-944a64fa2ed5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0\n",
      "Batch: ('i walked down down the boulevard', 'i walked down the avenue'); labels: tensor([0, 0])\n",
      "Batch: ('i walk down the city', 'i walk down the the avenue'); labels: tensor([0, 0])\n",
      "Batch: ('i ran down the boulevard',); labels: tensor([1])\n",
      "Epoch:1\n",
      "Batch: ('i ran down the boulevard', 'i walk down the city'); labels: tensor([1, 0])\n",
      "Batch: ('i walk down the the avenue', 'i walked down down the boulevard'); labels: tensor([0, 0])\n",
      "Batch: ('i walked down the avenue',); labels: tensor([0])\n",
      "Epoch:2\n",
      "Batch: ('i walked down the avenue', 'i walk down the the avenue'); labels: tensor([0, 0])\n",
      "Batch: ('i walk down the city', 'i ran down the boulevard'); labels: tensor([0, 1])\n",
      "Batch: ('i walked down down the boulevard',); labels: tensor([0])\n"
     ]
    }
   ],
   "source": [
    "for e in range(3):\n",
    "    print(\"Epoch:\" + str(e))\n",
    "    for x, y in toy_dataloader:\n",
    "        print(\"Batch: \" + str(x) + \"; labels: \" + str(y))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R28AHVvn384D"
   },
   "source": [
    "### Data processing of a text dataset\n",
    "\n",
    "Now, we would like to apply what we saw to our case, and **create a specific class** ```TextClassificationDataset``` **inheriting** ```Dataset``` that will:\n",
    "- Create a vocabulary from the data (use what we saw in the previous TP)\n",
    "- Preprocess the data using this vocabulary, adding whatever we need for our pytorch model\n",
    "- Have a ```__getitem__``` method that allows us to use the class with a ```Dataloader``` to easily build batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0QS7xnRT384D"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from torch.nn import functional as F\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from nltk import word_tokenize\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "import re # Regex for clean_and_tokenize\n",
    "import time # For evaluating durations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BPEy2B68384E"
   },
   "source": [
    "First, we get the filenames and the corresponding categories: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wL4v-y-m384G",
    "outputId": "e8a12b27-4df5-4ad9-9c23-2a53d1e59935"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000 documents\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "filenames_neg = sorted(glob(os.path.join('.', 'data', 'imdb1', 'neg', '*.txt')))\n",
    "filenames_pos = sorted(glob(os.path.join('.', 'data', 'imdb1', 'pos', '*.txt')))\n",
    "filenames = filenames_neg + filenames_pos\n",
    "\n",
    "# The first half of the elements of the list are string of negative reviews, and the second half positive ones\n",
    "# We create the labels, as an array of [1,len(texts)], filled with 1, and change the first half to 0\n",
    "categories = np.ones(len(filenames), dtype=np.int)\n",
    "categories[:len(filenames_neg)] = 0.\n",
    "\n",
    "print(\"%d documents\" % len(filenames))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yD7uUwTl384J"
   },
   "source": [
    "We will need to create a ```TextClassificationDataset``` and a ```Dataloader``` for the training data, the validation data, and the testing data. We need to implement a function that will help us split the data in three, according to proportions we give in input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZjWsOAgx384K"
   },
   "outputs": [],
   "source": [
    "# Create a function allowing you to simply shuffle then split the filenames and categories into the desired\n",
    "# proportions for a training, validation and testing set. \n",
    "def get_splits(x, y, splits):\n",
    "    \"\"\"\n",
    "    The idea is to use an index list as reference:\n",
    "    Indexes = [0 1 2 3 4 5 6 7 8 9]\n",
    "    To shuffle it randomly:\n",
    "    Indexes = [7 1 5 0 2 9 8 6 4 3]\n",
    "    We need 'splits' to contain 2 values. Assuming those are = (0.8, 0.1), we'll have:\n",
    "    Train_indexes = [7 1 5 0 2 9 8 6]\n",
    "    Valid_indexes = [4]\n",
    "    Test_indexes = [3]\n",
    "    \"\"\"\n",
    "    # Create an index list and shuffle it - use the function random.shuffle\n",
    "    indexes = list(range(len(x)))\n",
    "    random.shuffle(indexes)\n",
    "\n",
    "    # Find the two indexes we'll use to cut the lists from the splits\n",
    "    train_cut = int(splits[0]*len(x))\n",
    "    valid_cut = int((splits[0]+splits[1])*len(x))\n",
    "    train_indexes = indexes[:train_cut]\n",
    "    valid_indexes = indexes[train_cut:valid_cut]\n",
    "    test_indexes = indexes[valid_cut:]\n",
    "    \n",
    "    # Do the cutting (careful: you can't use a list as index for a list - this only works with tensors)\n",
    "    # (you need to use list comprehensions - or go through numpy)\n",
    "    train_x, train_y = [x[i] for i in train_indexes], y[train_indexes]\n",
    "    valid_x, valid_y = [x[i] for i in valid_indexes], y[valid_indexes]\n",
    "    test_x, test_y = [x[i] for i in test_indexes], y[test_indexes]\n",
    "    return (train_x, train_y), (valid_x, valid_y), (test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IMkJktSO384K"
   },
   "outputs": [],
   "source": [
    "# Fixed seed for reproducibility\n",
    "random.seed(42)\n",
    "\n",
    "# Choose the training, validation, testing splits\n",
    "splits = (0.8, 0.1)\n",
    "(train_f, train_c), (valid_f, valid_c), (test_f, test_c) = get_splits(filenames, categories, splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MybMnA697A3a",
    "outputId": "af09e445-d058-4a86-dc80-6fdad78318d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 400\n",
      "Validation samples: 50\n",
      "Testing samples: 50\n"
     ]
    }
   ],
   "source": [
    "REDUCT = 50 # Take only 1 sample every REDUCT samples\n",
    "\n",
    "reduct_len_train = int(len(train_f) / REDUCT)\n",
    "reduct_len_valid = int(len(valid_f) / REDUCT)\n",
    "reduct_len_test = int(len(test_f) / REDUCT)\n",
    "(train_f, train_c) = (train_f[:reduct_len_train], train_c[:reduct_len_train])\n",
    "(valid_f, valid_c) = (valid_f[:reduct_len_valid], valid_c[:reduct_len_valid])\n",
    "(test_f, test_c) = (test_f[:reduct_len_test], test_c[:reduct_len_test])\n",
    "\n",
    "# Check the new lengths of the datasets\n",
    "print(\"Training samples:\", len(train_f))\n",
    "print(\"Validation samples:\", len(valid_f))\n",
    "print(\"Testing samples:\", len(test_f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HnFXjv3n384L"
   },
   "source": [
    "We can now implement our ```TextClassificationDataset``` class, that we will build from:\n",
    "- A list of path to the IMDB files in the training set: ```path_to_file```\n",
    "- A list of the corresponding categories: ```categories```\n",
    "We will add three optional arguments:\n",
    "- First, a way to input a vocabulary (so that we can re-use the training vocabulary on the validation and training ```TextClassificationDataset```). By default, the value of the argument is ```None```.\n",
    "- In order to work with batches, we will need to have sequences of the same size. That can be done via **padding** but we will still need to limit the size of documents (to avoid having batches of huge sequences that are mostly empty because of one very long documents) to a ```max_length```. Let's put it to 100 by default.\n",
    "- Lastly, a ```min_freq``` that indicates how many times a word must appear to be taken in the vocabulary. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-xCn8IFz384L"
   },
   "source": [
    "The idea behind **padding** is to transform a list of pytorch tensors (of maybe different length) into a two dimensional tensor - which we can see as a batch. The size of the first dimension is the one of the longest tensor - and other are **padded** with a chosen symbol: here, we choose 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1t1JHTJb384M"
   },
   "outputs": [],
   "source": [
    "tensor_1 = torch.LongTensor([1, 4, 5])\n",
    "tensor_2 = torch.LongTensor([2])\n",
    "tensor_3 = torch.LongTensor([6, 7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gTsL1SHg384M",
    "outputId": "d4d35ae5-f285-47c4-8d3b-62bdaa1359cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 4, 5],\n",
      "        [2, 0, 0],\n",
      "        [6, 7, 0]])\n"
     ]
    }
   ],
   "source": [
    "tensor_padded = pad_sequence([tensor_1, tensor_2, tensor_3], batch_first=True, padding_value=0)\n",
    "print(tensor_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HYU7qK51TUAY"
   },
   "outputs": [],
   "source": [
    "def clean_and_tokenize(text):\n",
    "    \"\"\"\n",
    "    Cleaning a document with:\n",
    "        - Lowercase        \n",
    "        - Removing numbers with regular expressions\n",
    "        - Removing punctuation with regular expressions\n",
    "        - Removing other artifacts\n",
    "    And separate the document into words by simply splitting at spaces\n",
    "    Params:\n",
    "        text (string): a sentence or a document\n",
    "    Returns:\n",
    "        tokens (list of strings): the list of tokens (word units) forming the document\n",
    "    \"\"\"\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    # Remove numbers\n",
    "    text = re.sub(r\"[0-9]+\", \"\", text)\n",
    "    # Remove punctuation\n",
    "    REMOVE_PUNCT = re.compile(\"[.;:!\\'?,\\\"()\\[\\]]\")\n",
    "    text = REMOVE_PUNCT.sub(\"\", text)\n",
    "    # Remove HTML artifacts specific to the corpus we're going to work with\n",
    "    REPLACE_HTML = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\")\n",
    "    text = REPLACE_HTML.sub(\" \", text)\n",
    "    \n",
    "    tokens = text.split()        \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZtoWOmWU384M"
   },
   "outputs": [],
   "source": [
    "class TextClassificationDataset(Dataset):\n",
    "    def __init__(self, paths_to_files, categories, vocab=None,\n",
    "                 max_length=100, min_freq=5):\n",
    "        # Read all files and put the data in a list of strings\n",
    "        start_time = time.monotonic() \n",
    "        self.data = [open(f, encoding=\"utf8\").read() for f in paths_to_files]\n",
    "        print(\"Load data content in {}s ({} samples)\".format(\n",
    "            time.monotonic() - start_time, len(paths_to_files)\n",
    "        ))\n",
    "\n",
    "        # Set the maximum length we will keep for the sequences\n",
    "        self.max_length = max_length\n",
    "        \n",
    "        # Allow to import a vocabulary (for valid/test datasets, that will use the training vocabulary)\n",
    "        if vocab is not None:\n",
    "            self.word2idx, self.idx2word = vocab\n",
    "        else:\n",
    "            # If no vocabulary imported, build it (and reverse)\n",
    "            self.word2idx, self.idx2word = self.build_vocab(self.data, min_freq)\n",
    "        \n",
    "        # We then need to tokenize the data ...\n",
    "        tokenized_data = [\n",
    "            clean_and_tokenize(sent) for sent in self.data\n",
    "        ]\n",
    "        # Transform words into lists of indexes ... (use the .get() method to redirect unknown words to the UNK token)\n",
    "        unk_id = self.word2idx['UNK']\n",
    "        indexed_data = [\n",
    "            [self.word2idx.get(token, unk_id) for token in tok_sent]\n",
    "            for tok_sent in tokenized_data\n",
    "        ]\n",
    "        # And transform this list of lists into a list of Pytorch LongTensors\n",
    "        tensor_data = [\n",
    "            torch.LongTensor(indexed_sent)\n",
    "            for indexed_sent in indexed_data\n",
    "        ]\n",
    "        # And the categories into a FloatTensor\n",
    "        tensor_y = torch.FloatTensor(categories)\n",
    "        # To finally cut it when it's above the maximum length\n",
    "        cut_tensor_data = [\n",
    "            tensor_sent[:self.max_length]\n",
    "            for tensor_sent in tensor_data\n",
    "        ]\n",
    "        \n",
    "        # Now, we need to use the pad_sequence function to have the whole dataset represented as one tensor,\n",
    "        # containing sequences of the same length. We choose the padding_value to be 0, the we want the\n",
    "        # batch dimension to be the first dimension\n",
    "        self.tensor_data = pad_sequence(\n",
    "            cut_tensor_data,\n",
    "            batch_first=True,\n",
    "            padding_value=0\n",
    "        )\n",
    "        self.tensor_y = tensor_y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # The iterator just gets one particular example with its category\n",
    "        # The dataloader will take care of the shuffling and batching\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        return self.tensor_data[idx], self.tensor_y[idx] \n",
    "    \n",
    "    def build_vocab(self, corpus, count_threshold):\n",
    "        \"\"\"\n",
    "        We output word_index, a dictionary containing words \n",
    "        and their corresponding indexes as {word : indexes} \n",
    "        But also the reverse, which is a dictionary {indexes: word}\n",
    "        We add a UNK token that we need when encountering unknown words\n",
    "        We also choose '0' to represent the padding index, so begin the vocabulary index at 1 ! \n",
    "        \"\"\"\n",
    "        # Collect and count all distinct words\n",
    "        word_counts = {}\n",
    "        for sent in corpus:\n",
    "            tok_sent = clean_and_tokenize(sent)\n",
    "            for token in tok_sent:\n",
    "                if token in word_counts:\n",
    "                    word_counts[token] += 1\n",
    "                else:\n",
    "                    word_counts[token] = 1\n",
    "\n",
    "        # Keep only the words that appear frequently enough\n",
    "        filtered_word_counts = []\n",
    "        for token, count in word_counts.items():\n",
    "            if count >= count_threshold:\n",
    "                filtered_word_counts.append([token, count])\n",
    "\n",
    "        # Sort the words by frequency (optional)\n",
    "        filtered_word_counts.sort(key= lambda x: x[1], reverse=True)\n",
    "\n",
    "        # Build the vocabulary dictionaries\n",
    "        word_index = dict(zip(\n",
    "            [word_count[0] for word_count in filtered_word_counts], # token\n",
    "            range(1, 1+len(filtered_word_counts)) # index\n",
    "        ))\n",
    "        idx_word = dict(zip(\n",
    "            range(1, 1+len(filtered_word_counts)), # index\n",
    "            filtered_word_counts[:][0]  # token\n",
    "        ))\n",
    "\n",
    "        # Add UNK token\n",
    "        word_index['UNK'] = 1+len(filtered_word_counts)\n",
    "        idx_word[1+len(filtered_word_counts)] = 'UNK'\n",
    "\n",
    "        return word_index, idx_word\n",
    "    \n",
    "    def get_vocab(self):\n",
    "        # A simple way to get the training vocab when building the valid/test \n",
    "        return self.word2idx, self.idx2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hWoucaQGJYSV",
    "outputId": "dd8ab1ad-8e43-416d-c382-0b3c59d0cbf7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data content in 182.27123725100006s (400 samples)\n",
      "Size of vocabulary: 2168\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "MAX_LENGTH = 100\n",
    "MIN_FREQ = 5\n",
    "\n",
    "# Build dataset and vocabulary\n",
    "training_dataset = TextClassificationDataset(\n",
    "    train_f, train_c,\n",
    "    max_length=MAX_LENGTH, min_freq=MIN_FREQ\n",
    ")\n",
    "training_word2idx, training_idx2word = training_dataset.get_vocab()\n",
    "#print(\"Vocabulary:\", training_word2idx) # for debugging\n",
    "print(\"Size of vocabulary:\", len(training_word2idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3ULj2oiv384Q",
    "outputId": "2c47e415-d2cd-4318-d6f1-0caca8146660"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data content in 21.20292835700002s (50 samples)\n",
      "Load data content in 23.243693093000047s (50 samples)\n"
     ]
    }
   ],
   "source": [
    "valid_dataset = TextClassificationDataset(valid_f, valid_c, (training_word2idx, training_idx2word))\n",
    "test_dataset = TextClassificationDataset(test_f, test_c, (training_word2idx, training_idx2word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "102IRQOz384Q"
   },
   "outputs": [],
   "source": [
    "training_dataloader = DataLoader(training_dataset, batch_size=200, shuffle=True)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=25)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jo40lnPm384U"
   },
   "source": [
    "## A simple averaging model\n",
    "\n",
    "Now, we will implement in Pytorch a simple averaging model. For each model we will implement, we need to create a class which inherits from ```nn.Module``` and redifine the ```__init__``` method as well as the ```forward``` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ue4ruWCT384V"
   },
   "outputs": [],
   "source": [
    "# Models are usually implemented as custom nn.Module subclass\n",
    "# We need to redefine the __init__ method, which creates the object\n",
    "# We also need to redefine the forward method, which transform the input into outputs\n",
    "\n",
    "class AveragingModel(nn.Module):    \n",
    "    def __init__(self, embedding_dim, vocabulary_size):\n",
    "        super().__init__()\n",
    "        # Create an embedding object. Be careful to padding - you need to increase the vocabulary size by one !\n",
    "        # Look into the arguments of the nn.Embedding class\n",
    "        self.embeddings = nn.Embedding(\n",
    "            num_embeddings=vocabulary_size + 1,\n",
    "            embedding_dim=embedding_dim\n",
    "        ) # Completed\n",
    "        # Create a linear layer that will transform the mean of the embeddings into a classification score\n",
    "        self.linear = nn.Linear(\n",
    "            in_features=embedding_dim,\n",
    "            out_features=1\n",
    "        ) # Completed\n",
    "        \n",
    "        # No need for sigmoid, it will be into the criterion ! \n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        # Remember: the inpts are written as Batch_size * seq_length * embedding_dim\n",
    "        # First, take the mean of the embeddings of the document\n",
    "        x = torch.mean(self.embeddings(inputs), 1) # Completed\n",
    "        # Then make it go through the linear layer and remove the extra dimension with the method .squeeze()\n",
    "        o = torch.squeeze(self.linear(x)) # Completed\n",
    "        return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dlwybgh0384W"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oAajy8IM384X"
   },
   "outputs": [],
   "source": [
    "model = AveragingModel(300, len(training_word2idx))\n",
    "#model = PretrainedAveragingModel(GloveEmbeddings, freeze=True) # to run pretrained Glove\n",
    "\n",
    "# Create an optimizer\n",
    "opt = optim.Adam(model.parameters(), lr=0.0025, betas=(0.9, 0.999))\n",
    "# The criterion is a binary cross entropy loss based on logits - meaning that the sigmoid is integrated into the criterion\n",
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XNvEJJlS384a"
   },
   "outputs": [],
   "source": [
    "# Implement a training function, which will train the model with the corresponding optimizer and criterion,\n",
    "# with the appropriate dataloader, for one epoch.\n",
    "\n",
    "def train_epoch(model, opt, criterion, dataloader):\n",
    "    model.train()\n",
    "    losses = []\n",
    "    for i, (x, y) in enumerate(dataloader):\n",
    "        opt.zero_grad()\n",
    "        # (1) Forward\n",
    "        pred = model(x) # Completed\n",
    "        # (2) Compute the loss \n",
    "        loss = criterion(pred, y) # Completed\n",
    "        # (3) Compute gradients with the criterion\n",
    "        loss.backward() # Completed\n",
    "        # (4) Update weights with the optimizer\n",
    "        opt.step() # Completed     \n",
    "        losses.append(loss.item())\n",
    "        # Count the number of correct predictions in the batch - here, you'll need to use the sigmoid\n",
    "        num_corrects = sum(torch.round(torch.sigmoid(pred)) == y) # Completed\n",
    "        acc = 100.0 * num_corrects/len(y)\n",
    "        \n",
    "        if (i%20 == 0):\n",
    "            print(\"Batch \" + str(i) + \" : training loss = \" + str(loss.item()) + \"; training acc = \" + str(acc.item()))\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ohgmfJSJ384a"
   },
   "outputs": [],
   "source": [
    "# Same for the evaluation ! We don't need the optimizer here. \n",
    "def eval_model(model, criterion, evalloader):\n",
    "    model.eval()\n",
    "    total_epoch_loss = 0\n",
    "    total_epoch_acc = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (x, y) in enumerate(evalloader):\n",
    "            pred = model(x) # Completed\n",
    "            loss = criterion(pred, y) # Completed\n",
    "            num_corrects = sum(torch.round(torch.sigmoid(pred)) == y) # Completed\n",
    "            acc = 100.0 * num_corrects/len(y)\n",
    "            total_epoch_loss += loss.item()\n",
    "            total_epoch_acc += acc.item()\n",
    "\n",
    "    return total_epoch_loss/(i+1), total_epoch_acc/(i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wp5w1q0n384b"
   },
   "outputs": [],
   "source": [
    "# A function which will help you execute experiments rapidly - with a early_stopping option when necessary. \n",
    "def experiment(model, opt, criterion, num_epochs = 5, early_stopping = True):\n",
    "    train_losses = []\n",
    "    if early_stopping:\n",
    "        best_valid_loss = 10.\n",
    "    print(\"Beginning training...\")\n",
    "    start_time = time.monotonic() # ADDED line\n",
    "    for e in range(num_epochs):\n",
    "        print(\"Epoch \" + str(e+1) + \":\")\n",
    "        train_losses += train_epoch(model, opt, criterion, training_dataloader)\n",
    "        valid_loss, valid_acc = eval_model(model, criterion, valid_dataloader)\n",
    "        print(\"Epoch \" + str(e+1) + \" : Validation loss = \" + str(valid_loss) + \"; Validation acc = \" + str(valid_acc))\n",
    "        if early_stopping:\n",
    "            if valid_loss < best_valid_loss:\n",
    "                best_valid_loss = valid_loss\n",
    "            else:\n",
    "                print(\"Early stopping.\")\n",
    "                break  \n",
    "    test_loss, test_acc = eval_model(model, criterion, test_dataloader)\n",
    "    print(\"Epoch \" + str(e+1) + \" : Test loss = \" + str(test_loss) + \"; Test acc = \" + str(test_acc))\n",
    "    print(\"Total duration: {} epochs in {}s\".format( # ADDED line\n",
    "        e+1,\n",
    "        time.monotonic() - start_time,\n",
    "    ))\n",
    "    return train_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b0-IEk8g384d",
    "outputId": "04a5079a-4752-4f00-b985-0f6deee1cc82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6941554546356201; training acc = 51.5\n",
      "Epoch 1 : Validation loss = 0.6843913793563843; Validation acc = 60.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6950291991233826; training acc = 50.5\n",
      "Epoch 2 : Validation loss = 0.6839759647846222; Validation acc = 58.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6867280006408691; training acc = 55.5\n",
      "Epoch 3 : Validation loss = 0.6836389899253845; Validation acc = 58.0\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.6868730187416077; training acc = 52.5\n",
      "Epoch 4 : Validation loss = 0.6832371056079865; Validation acc = 58.0\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.6686186194419861; training acc = 59.0\n",
      "Epoch 5 : Validation loss = 0.6832980513572693; Validation acc = 60.0\n",
      "Early stopping.\n",
      "Epoch 5 : Test loss = 0.6848028898239136; Test acc = 54.0\n",
      "Total duration: 5 epochs in 0.6132919039999933s\n"
     ]
    }
   ],
   "source": [
    "train_losses = experiment(model, opt, criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HRChJZXl384d"
   },
   "source": [
    "### With Glove embeddings: \n",
    "\n",
    "Now, we integrate pre-trained word embeddings into our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GX1y3qCP384d"
   },
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "loaded_glove_model = api.load(\"glove-wiki-gigaword-300\")\n",
    "loaded_glove_embeddings = loaded_glove_model.vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rbs28_00384e"
   },
   "outputs": [],
   "source": [
    "def get_glove_adapted_embeddings(glove_model, input_voc):\n",
    "    keys = {i: glove_model.vocab.get(w, None) for w, i in input_voc.items()}\n",
    "    index_dict = {i: key.index for i, key in keys.items() if key is not None}\n",
    "    embeddings = np.zeros((len(input_voc)+1,glove_model.vectors.shape[1]))\n",
    "    for i, ind in index_dict.items():\n",
    "        embeddings[i] = glove_model.vectors[ind]\n",
    "    return embeddings\n",
    "\n",
    "GloveEmbeddings = get_glove_adapted_embeddings(loaded_glove_model, training_word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JH_2al_X384g"
   },
   "outputs": [],
   "source": [
    "print(GloveEmbeddings.shape)\n",
    "# We should check that the \"padding\" vector is at zero\n",
    "print(GloveEmbeddings[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lcNG6Ejl384i"
   },
   "source": [
    "Here, implement a ```PretrainedAveragingModel``` very similar to the previous model, using the ```nn.Embedding``` method ```from_pretrained()``` to initialize the embeddings from a numpy array. Use the ```requires_grad_``` method to specify if the model must fine-tune the embeddings or not ! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xmSUbs2z384l"
   },
   "outputs": [],
   "source": [
    "class PretrainedAveragingModel(nn.Module):\n",
    "    # Completed\n",
    "    def __init__(self, pretrained_embeddings, fine_tuning=False):\n",
    "        \"\"\"\n",
    "        Initialize Averaging model with pretrained embeddings weights\n",
    "        \n",
    "        pretrained_embeddings: pretrained embeddings weights\n",
    "        fine_tuning (bool): If False, the embeddings tensor does not get updated\n",
    "            in the learning process. Defaults to False. Equivalent to\n",
    "            embedding.weight.requires_grad = False. See 'freeze' argument\n",
    "            in https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # Create an embedding object from pretrained\n",
    "        self.embeddings = nn.Embedding.from_pretrained(\n",
    "            embeddings=torch.Tensor(pretrained_embeddings),\n",
    "            freeze=not fine_tuning\n",
    "        )\n",
    "        # Create a linear layer that will transform the mean of the embeddings into a classification score\n",
    "        embedding_dim = pretrained_embeddings.shape[1] # =300 for Glove\n",
    "        self.linear = nn.Linear(\n",
    "            in_features=embedding_dim,\n",
    "            out_features=1\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # The inputs are written as Batch_size * seq_length * embedding_dim\n",
    "        # First, take the mean of the embeddings of the document\n",
    "        x = torch.mean(self.embeddings(inputs), 1)\n",
    "        # Then make it go through the linear layer and remove the extra dimension with the method .squeeze()\n",
    "        o = torch.squeeze(self.linear(x))\n",
    "        return o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PZEiBiyZ384o"
   },
   "source": [
    "# LSTM Cells in pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bKVbQICN384p",
    "outputId": "72d5bb9e-0975-455c-b8f4-2cec52b319a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.1571, -0.4284,  0.2217]],\n",
      "\n",
      "        [[ 0.2212, -0.3245, -0.2939]],\n",
      "\n",
      "        [[ 0.3902,  0.0851, -0.0344]],\n",
      "\n",
      "        [[ 0.5499,  0.2773,  0.0102]],\n",
      "\n",
      "        [[ 0.4572,  0.1448, -0.2210]]], grad_fn=<StackBackward>)\n",
      "(tensor([[[ 0.4572,  0.1448, -0.2210]]], grad_fn=<StackBackward>), tensor([[[ 0.9262,  0.2277, -0.3543]]], grad_fn=<StackBackward>))\n"
     ]
    }
   ],
   "source": [
    "# Create a toy example of LSTM: \n",
    "lstm = nn.LSTM(3, 3)  # Input dim is 3, output dim is 3\n",
    "inputs = [torch.randn(1, 3) for _ in range(5)]  # make a sequence of length 5\n",
    "\n",
    "# LSTMs expect inputs having 3 dimensions:\n",
    "# - The first dimension is the temporal dimension, along which we (in our case) have the different words\n",
    "# - The second dimension is the batch dimension, along which we stack the independant batches\n",
    "# - The third dimension is the feature dimension, along which are the features of the vector representing the words\n",
    "\n",
    "# In our toy case, we have inputs and outputs containing 3 features (third dimension !)\n",
    "# We created a sequence of 5 different inputs (first dimension !)\n",
    "# We don't use batch (the second dimension will have one lement)\n",
    "\n",
    "# We need an initial hidden state, of the right sizes for dimension 2/3, but with only one temporal element:\n",
    "# Here, it is:\n",
    "hidden = (torch.randn(1, 1, 3),\n",
    "          torch.randn(1, 1, 3))\n",
    "# We create a tuple of two tensors because we use LSTMs: they use two sets of weights,\n",
    "# and two hidden states (Hidden state, and Cell state). Read: https://colah.github.io/posts/2015-08-Understanding-LSTMs/\n",
    "# If we used a classic RNN, we would simply have:\n",
    "# hidden = torch.randn(1, 1, 3)\n",
    "\n",
    "# The naive way of applying a lstm to inputs is to apply it one step at a time, and loop through the sequence\n",
    "for i in inputs:\n",
    "    # After each step, hidden contains the hidden states (remember, it's a tuple of two states).\n",
    "    out, hidden = lstm(i.view(1, 1, -1), hidden)\n",
    "    \n",
    "# Alternatively, we can do the entire sequence all at once.\n",
    "# The first value returned by LSTM is all of the Hidden states throughout the sequence.\n",
    "# The second is just the most recent Hidden state and Cell state (you can compare the values)\n",
    "# The reason for this is that:\n",
    "# \"out\" will give you access to all hidden states in the sequence, for each temporal step\n",
    "# \"hidden\" will allow you to continue the sequence and backpropagate later, with another sequence\n",
    "inputs = torch.cat(inputs).view(len(inputs), 1, -1)\n",
    "hidden = (torch.randn(1, 1, 3), torch.randn(1, 1, 3))  # Re-initialize\n",
    "out, hidden = lstm(inputs, hidden)\n",
    "print(out)\n",
    "print(hidden)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eaC7UfDy384q"
   },
   "source": [
    "### Creating our own LSTM Model\n",
    "\n",
    "We'll implement now a LSTM model, taking the same inputs and also outputing a score for the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DiW6qQv58tdY"
   },
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, embedding_dim, vocabulary_size, hidden_dim,\n",
    "          embeddings=None, fine_tuning=False):\n",
    "      super().__init__()\n",
    "      self.hidden_dim = hidden_dim\n",
    "\n",
    "      if embeddings is not None :\n",
    "        self.embeddings = nn.Embedding.from_pretrained(embeddings=torch.Tensor(embeddings), freeze=not fine_tuning)\n",
    "        embedding_dim=embeddings.shape[1]\n",
    "      else :\n",
    "        self.embeddings = nn.Embedding(\n",
    "            vocabulary_size+1, embedding_dim\n",
    "        )\n",
    "      self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "      self.linear = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "      embeddings = self.embeddings(inputs)\n",
    "      _, (last_hidden_state, _) = self.lstm(embeddings)\n",
    "      linear_out = torch.squeeze(self.linear(last_hidden_state))\n",
    "      return linear_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l488S8P-MUdg"
   },
   "source": [
    "## Run LSTM model without pretraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LtfRUPqMAvD8",
    "outputId": "9371e660-b40e-46d9-a9fa-d087167a3c31"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6963910460472107; training acc = 47.5\n",
      "Epoch 1 : Validation loss = 0.6882959306240082; Validation acc = 56.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.627260684967041; training acc = 67.5\n",
      "Epoch 2 : Validation loss = 0.6987157166004181; Validation acc = 54.0\n",
      "Early stopping.\n",
      "Epoch 2 : Test loss = 0.7395232021808624; Test acc = 50.0\n",
      "Total duration: 2 epochs in 5.50652630400009s\n"
     ]
    }
   ],
   "source": [
    "model = LSTMModel(\n",
    "    embedding_dim=300,\n",
    "    vocabulary_size=len(training_word2idx),\n",
    "    hidden_dim=300\n",
    ")\n",
    "# Create an optimizer\n",
    "opt = optim.Adam(model.parameters(), lr=0.0025, betas=(0.9, 0.999))\n",
    "# The criterion is a binary cross entropy loss based on logits - meaning that the sigmoid is integrated into the criterion\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "train_losses = experiment(model, opt, criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wurpzml-KA-Y"
   },
   "source": [
    "## Run LSTM model with pretrained embeddings (fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "64cNq9UcnlM5",
    "outputId": "ad29e43d-97b5-4c5f-f05d-4ae208ca20df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6923812627792358; training acc = 52.0\n",
      "Epoch 1 : Validation loss = 0.6822963654994965; Validation acc = 54.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6815677881240845; training acc = 53.5\n",
      "Epoch 2 : Validation loss = 0.6804623901844025; Validation acc = 56.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6675193309783936; training acc = 58.5\n",
      "Epoch 3 : Validation loss = 0.6831582188606262; Validation acc = 60.0\n",
      "Early stopping.\n",
      "Epoch 3 : Test loss = 0.7196337878704071; Test acc = 44.0\n",
      "Total duration: 3 epochs in 6.908174721000023s\n"
     ]
    }
   ],
   "source": [
    "model = LSTMModel(\n",
    "    embedding_dim=300,\n",
    "    vocabulary_size=len(training_word2idx),\n",
    "    hidden_dim=300,\n",
    "    embeddings=GloveEmbeddings\n",
    ")\n",
    "# Create an optimizer\n",
    "opt = optim.Adam(model.parameters(), lr=0.0025, betas=(0.9, 0.999))\n",
    "# The criterion is a binary cross entropy loss based on logits - meaning that the sigmoid is integrated into the criterion\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "train_losses = experiment(model, opt, criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Rf0qJjFKQ3P"
   },
   "source": [
    "## Run LSTM model with pretrained embeddings and fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PyhVhzvMpRhV",
    "outputId": "b2a024e1-91a2-4ba8-e49d-a897b9225869"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6927673816680908; training acc = 49.5\n",
      "Epoch 1 : Validation loss = 0.6823270320892334; Validation acc = 52.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6571475863456726; training acc = 56.5\n",
      "Epoch 2 : Validation loss = 0.6990417838096619; Validation acc = 58.0\n",
      "Early stopping.\n",
      "Epoch 2 : Test loss = 0.7328164875507355; Test acc = 44.0\n",
      "Total duration: 2 epochs in 5.366575243999932s\n"
     ]
    }
   ],
   "source": [
    "model = LSTMModel(\n",
    "    embedding_dim=300,\n",
    "    vocabulary_size=len(training_word2idx),\n",
    "    hidden_dim=300,\n",
    "    embeddings=GloveEmbeddings,\n",
    "    fine_tuning=True\n",
    ")\n",
    "# Create an optimizer\n",
    "opt = optim.Adam(model.parameters(), lr=0.0025, betas=(0.9, 0.999))\n",
    "# The criterion is a binary cross entropy loss based on logits - meaning that the sigmoid is integrated into the criterion\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "train_losses = experiment(model, opt, criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jjQfq97q384q"
   },
   "source": [
    "## And with a CNN ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fIOjoTGOqtGL"
   },
   "source": [
    "Reference: *Using convolution neural networks to classify text in pytorch*, Blog Post [link](https://tzuruey.medium.com/using-convolution-neural-networks-to-classify-text-in-pytorch-3b626a42c3ca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2W53YZat384r"
   },
   "outputs": [],
   "source": [
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, embedding_dim, vocabulary_size,\n",
    "              embeddings=None, fine_tuning=False, window_size: int=16,\n",
    "              filter_multiplier=64):\n",
    "         super().__init__()\n",
    "         if embeddings is not None :\n",
    "           self.embeddings = nn.Embedding.from_pretrained(embeddings=torch.Tensor(embeddings), freeze=not fine_tuning)\n",
    "           embedding_dim=embeddings.shape[1]\n",
    "         else :\n",
    "           self.embeddings = nn.Embedding(\n",
    "               vocabulary_size+1, embedding_dim\n",
    "           )\n",
    "         self.conv = nn.Conv2d(in_channels=1, out_channels=filter_multiplier, kernel_size=(window_size,embedding_dim))\n",
    "         self.linear = nn.Linear(filter_multiplier, out_features=1)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "         x = self.embeddings(inputs)\n",
    "         x = torch.unsqueeze(x, 1)\n",
    "         x = self.conv(x)\n",
    "         x = torch.squeeze(x, 3)\n",
    "         x = F.relu(x)\n",
    "         x = F.max_pool1d(x, x.shape[2]).squeeze(2)\n",
    "         x = self.linear(x)\n",
    "         return torch.squeeze(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CE6tp6jj3D4K"
   },
   "source": [
    "## Train CNN model without pretrained embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eNql-ccnqzFR",
    "outputId": "07d083f9-eac5-42a2-d326-a4c63b142ff0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.7702906131744385; training acc = 52.5\n",
      "Epoch 1 : Validation loss = 0.8369641900062561; Validation acc = 40.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.5364144444465637; training acc = 73.0\n",
      "Epoch 2 : Validation loss = 1.0656010806560516; Validation acc = 54.0\n",
      "Early stopping.\n",
      "Epoch 2 : Test loss = 0.9522664546966553; Test acc = 58.0\n",
      "Total duration: 2 epochs in 6.500939182000138s\n"
     ]
    }
   ],
   "source": [
    "model = CNNModel(embedding_dim=300, vocabulary_size=len(training_word2idx))\n",
    "# Create an optimizer\n",
    "opt = optim.Adam(model.parameters(), lr=0.0025, betas=(0.9, 0.999))\n",
    "# The criterion is a binary cross entropy loss based on logits - meaning that the sigmoid is integrated into the criterion\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "train_losses = experiment(model, opt, criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bYAEQdw1Ka7M"
   },
   "source": [
    "## Train CNN model with pretrained embeddings but without fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "koGdEatY1Je_",
    "outputId": "2db0603f-39a4-4855-a74c-083d83f15d6d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6925008893013; training acc = 52.0\n",
      "Epoch 1 : Validation loss = 0.7378141582012177; Validation acc = 46.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6293485760688782; training acc = 50.0\n",
      "Epoch 2 : Validation loss = 0.6675723791122437; Validation acc = 54.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.5026382207870483; training acc = 69.5\n",
      "Epoch 3 : Validation loss = 0.7164798080921173; Validation acc = 48.0\n",
      "Early stopping.\n",
      "Epoch 3 : Test loss = 0.7474651336669922; Test acc = 44.0\n",
      "Total duration: 3 epochs in 6.60121419699999s\n"
     ]
    }
   ],
   "source": [
    "model = CNNModel(embedding_dim=300, vocabulary_size=len(training_word2idx), embeddings=GloveEmbeddings, fine_tuning=False)\n",
    "# Create an optimizer\n",
    "opt = optim.Adam(model.parameters(), lr=0.0025, betas=(0.9, 0.999))\n",
    "# The criterion is a binary cross entropy loss based on logits - meaning that the sigmoid is integrated into the criterion\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "train_losses = experiment(model, opt, criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hyha_lpKKhZ-"
   },
   "source": [
    "## Train CNN model with pretrained embeddings and fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HnVDb34F1ckv",
    "outputId": "9bc0c969-9ca4-4907-e70e-ae9673ec482d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.7140135169029236; training acc = 48.0\n",
      "Epoch 1 : Validation loss = 0.7727560698986053; Validation acc = 54.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.7112321257591248; training acc = 57.5\n",
      "Epoch 2 : Validation loss = 0.6959434747695923; Validation acc = 46.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6918337941169739; training acc = 49.5\n",
      "Epoch 3 : Validation loss = 0.6977367699146271; Validation acc = 46.0\n",
      "Early stopping.\n",
      "Epoch 3 : Test loss = 0.7032230496406555; Test acc = 40.0\n",
      "Total duration: 3 epochs in 9.441260064000062s\n"
     ]
    }
   ],
   "source": [
    "model = CNNModel(embedding_dim=300, vocabulary_size=len(training_word2idx), embeddings=GloveEmbeddings, fine_tuning=True)\n",
    "# Create an optimizer\n",
    "opt = optim.Adam(model.parameters(), lr=0.0025, betas=(0.9, 0.999))\n",
    "# The criterion is a binary cross entropy loss based on logits - meaning that the sigmoid is integrated into the criterion\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "train_losses = experiment(model, opt, criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HOHHEn2yCBHA"
   },
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kl7G9n-tgw-N"
   },
   "source": [
    "\n",
    "\n",
    "## Grid Search\n",
    "\n",
    "In this section, we provide an implementation for performing gridsearch over our different models. We especially investigate the influence of the size of the vocabulary for different sizes of dataset. Outputs are saved in the file `grid_search.csv` in current working directory.\n",
    "\n",
    "The size of the training dataset is chosen in `[400, 800, 1600]`; it corresponds to reduction factors of `[50, 25, 12.5]` over the initial dataset. The size of the vocabulary is changed using the `min_freq` parameter, among the values `[1,3,5,10,20]`. For reproducibility, dataset splits are made after initializing random seed to 42 for `random` standard Python library. Average runtime for exploring Averaging models (with the three cases of embedding) is about 10min, for LSTM about 20min and for CNN models about 15min, run on Google Colab computing infrastructure (CPU only).\n",
    "\n",
    "In all these experiments, hyperparameters are fixed as follow:\n",
    "- number of epochs: 10\n",
    "- early stopping: True\n",
    "- batchsize: 200 for training set, 25 for testing and validation sets\n",
    "- optimizer: Adam, with param `betas=(0.9, 0.999)`\n",
    "- learning rate: 0.0025\n",
    "- maximum length of the samples (`max_length`): 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AoTDRZbpKuDg"
   },
   "source": [
    "## Modified versions of `TextClassificationDataset` and `experiment` to avoid loading data multiple times and retrieve test loss and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yj076i6UL76r"
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "MAX_LENGTH = 100\n",
    "MIN_FREQ = 5\n",
    "\n",
    "class TextClassificationDataset(Dataset):\n",
    "    def __init__(self, paths_to_files, categories, vocab=None,\n",
    "            max_length=MAX_LENGTH, min_freq=MIN_FREQ, data=None):\n",
    "        # Read all files and put the data in a list of strings\n",
    "        # MODIFIED: avoid loading data multiple times\n",
    "        if data is None:\n",
    "          self.data = [open(f, encoding=\"utf8\").read() for f in paths_to_files]\n",
    "        else:\n",
    "          self.data = data\n",
    "        \n",
    "        # Set the maximum length we will keep for the sequences\n",
    "        self.max_length = max_length\n",
    "        \n",
    "        # Allow to import a vocabulary (for valid/test datasets, that will use the training vocabulary)\n",
    "        if vocab is not None:\n",
    "            self.word2idx, self.idx2word = vocab\n",
    "        else:\n",
    "            # If no vocabulary imported, build it (and reverse)\n",
    "            self.word2idx, self.idx2word = self.build_vocab(self.data, min_freq)\n",
    "        \n",
    "        # We then need to tokenize the data .. \n",
    "        tokenized_data = [\n",
    "            clean_and_tokenize(sent) for sent in self.data\n",
    "        ]\n",
    "        # Transform words into lists of indexes ... (use the .get() method to redirect unknown words to the UNK token)\n",
    "        unk_id = self.word2idx['UNK']\n",
    "        indexed_data = [\n",
    "            [self.word2idx.get(token, unk_id) for token in tok_sent]\n",
    "            for tok_sent in tokenized_data\n",
    "        ]\n",
    "        # And transform this list of lists into a list of Pytorch LongTensors\n",
    "        tensor_data = [\n",
    "            torch.LongTensor(indexed_sent)\n",
    "            for indexed_sent in indexed_data\n",
    "        ]\n",
    "        # And the categories into a FloatTensor\n",
    "        tensor_y = torch.FloatTensor(categories)\n",
    "        # To finally cut it when it's above the maximum length\n",
    "        cut_tensor_data = cut_tensor_data = [\n",
    "            tensor_sent[:self.max_length]\n",
    "            for tensor_sent in tensor_data\n",
    "        ]\n",
    "        \n",
    "        # Now, we need to use the pad_sequence function to have the whole dataset represented as one tensor,\n",
    "        # containing sequences of the same length. We choose the padding_value to be 0, the we want the\n",
    "        # batch dimension to be the first dimension \n",
    "        self.tensor_data = pad_sequence(\n",
    "            cut_tensor_data,\n",
    "            batch_first=True,\n",
    "            padding_value=0\n",
    "        )\n",
    "        self.tensor_y = tensor_y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # The iterator just gets one particular example with its category\n",
    "        # The dataloader will take care of the shuffling and batching\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        return self.tensor_data[idx], self.tensor_y[idx] \n",
    "    \n",
    "    def build_vocab(self, corpus, count_threshold):\n",
    "        \"\"\"\n",
    "        We output word_index, a dictionary containing words \n",
    "        and their corresponding indexes as {word : indexes} \n",
    "        But also the reverse, which is a dictionary {indexes: word}\n",
    "        We add a UNK token that we need when encountering unknown words\n",
    "        We also choose '0' to represent the padding index, so begin the vocabulary index at 1 ! \n",
    "        \"\"\"\n",
    "        # Collect and count all distinct words\n",
    "        word_counts = {}\n",
    "        for sent in corpus:\n",
    "            tok_sent = clean_and_tokenize(sent)\n",
    "            for token in tok_sent:\n",
    "                if token in word_counts:\n",
    "                    word_counts[token] += 1\n",
    "                else:\n",
    "                    word_counts[token] = 1\n",
    "\n",
    "        # Keep only the words that appear frequently enough\n",
    "        filtered_word_counts = []\n",
    "        for token, count in word_counts.items():\n",
    "            if count >= count_threshold:\n",
    "                filtered_word_counts.append([token, count])\n",
    "\n",
    "        # Sort the words by frequency (optional)\n",
    "        filtered_word_counts.sort(key= lambda x: x[1], reverse=True)\n",
    "\n",
    "        # Build the vocabulary dictionaries\n",
    "        word_index = dict(zip(\n",
    "            [word_count[0] for word_count in filtered_word_counts],  # token\n",
    "            range(1, 1+len(filtered_word_counts))  # index\n",
    "        ))\n",
    "        idx_word = dict(zip(\n",
    "            range(1, 1+len(filtered_word_counts)),  # index\n",
    "            filtered_word_counts[:][0]  # token\n",
    "        ))\n",
    "\n",
    "        # Add UNK token\n",
    "        word_index['UNK'] = 1+len(filtered_word_counts)\n",
    "        idx_word[1+len(filtered_word_counts)] = 'UNK'\n",
    "        return word_index, idx_word\n",
    "    \n",
    "    def get_vocab(self):\n",
    "        # A simple way to get the training vocab when building the valid/test \n",
    "        return self.word2idx, self.idx2word\n",
    "\n",
    "def experiment_gridsearch(model, opt, criterion,\n",
    "        num_epochs=10, early_stopping=True):\n",
    "    \"\"\"\n",
    "    Modified version of 'experiment' function\n",
    "    which returns final test loss and accuracy\n",
    "    \"\"\"\n",
    "    train_losses = []\n",
    "    if early_stopping: \n",
    "        best_valid_loss = 10. \n",
    "    print(\"Beginning training...\")\n",
    "    for e in range(num_epochs):\n",
    "        print(\"Epoch \" + str(e+1) + \":\")\n",
    "        train_losses += train_epoch(model, opt, criterion, training_dataloader)\n",
    "        valid_loss, valid_acc = eval_model(model, criterion, valid_dataloader)\n",
    "        print(\"Epoch \" + str(e+1) + \" : Validation loss = \" + str(valid_loss) + \"; Validation acc = \" + str(valid_acc))\n",
    "        if early_stopping:\n",
    "            if valid_loss < best_valid_loss:\n",
    "                best_valid_loss = valid_loss\n",
    "            else:\n",
    "                print(\"Early stopping.\")\n",
    "                break  \n",
    "    test_loss, test_acc = eval_model(model, criterion, test_dataloader)\n",
    "    return valid_acc, test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5UwuPXt9LlmA"
   },
   "source": [
    "## Define function to perform trainings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MM9z-9i3lFUi"
   },
   "outputs": [],
   "source": [
    "def trainings(model_type, vocabulary_size, embeddings=None, fine_tuning=False):\n",
    "  \"\"\"Declare and train a model\"\"\"\n",
    "  # Initialize the model\n",
    "  if model_type == 'Average' and embeddings is None:\n",
    "    model = AveragingModel(300, vocabulary_size)\n",
    "  elif model_type == 'Average' and embeddings is not None:\n",
    "    model = PretrainedAveragingModel(GloveEmbeddings, fine_tuning=fine_tuning)\n",
    "  elif model_type == 'LSTM':\n",
    "    model = LSTMModel(\n",
    "        embedding_dim=300, vocabulary_size=vocabulary_size,\n",
    "        hidden_dim=300, embeddings=embeddings, fine_tuning=fine_tuning\n",
    "    )\n",
    "  elif model_type == 'CNN':\n",
    "    model = CNNModel(\n",
    "        embedding_dim=300, vocabulary_size=vocabulary_size,\n",
    "        embeddings=embeddings, fine_tuning=fine_tuning\n",
    "    )\n",
    "\n",
    "  opt = optim.Adam(model.parameters(), lr=0.0025, betas=(0.9, 0.999))\n",
    "  criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "  # Train the model\n",
    "  valid_acc, test_acc = experiment_gridsearch(model, opt, criterion, num_epochs=10, early_stopping=True)\n",
    "  return valid_acc, test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RX-jptuzK6vB"
   },
   "source": [
    "## Load GloVe embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cldrOK8hJmo3"
   },
   "outputs": [],
   "source": [
    "loaded_glove_model = api.load(\"glove-wiki-gigaword-300\")\n",
    "loaded_glove_embeddings = loaded_glove_model.vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BNfT7JR2K_OG"
   },
   "source": [
    "## Perform trainings for grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F-1UuLuBlFUx",
    "outputId": "f5e3cf28-c7e4-4700-8667-f2019667d460"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;30;43mLe flux de sortie a été tronqué et ne contient que les 5000 dernières lignes.\u001b[0m\n",
      "Epoch 6 : Validation loss = 0.49053118005394936; Validation acc = 81.0\n",
      "Epoch 7:\n",
      "Batch 0 : training loss = 0.06259764730930328; training acc = 100.0\n",
      "Epoch 7 : Validation loss = 0.5039448104798794; Validation acc = 82.0\n",
      "Early stopping.\n",
      "RUN COURANT = 0\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6905484795570374; training acc = 52.5\n",
      "Epoch 1 : Validation loss = 0.6907703205943108; Validation acc = 54.5\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6763463020324707; training acc = 70.5\n",
      "Epoch 2 : Validation loss = 0.6841566637158394; Validation acc = 55.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.668154776096344; training acc = 66.5\n",
      "Epoch 3 : Validation loss = 0.6763539984822273; Validation acc = 58.0\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.6418187022209167; training acc = 75.0\n",
      "Epoch 4 : Validation loss = 0.6756289452314377; Validation acc = 57.0\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.6405028700828552; training acc = 68.0\n",
      "Epoch 5 : Validation loss = 0.6621209681034088; Validation acc = 63.0\n",
      "Epoch 6:\n",
      "Batch 0 : training loss = 0.6355007290840149; training acc = 70.5\n",
      "Epoch 6 : Validation loss = 0.6504205465316772; Validation acc = 63.5\n",
      "Epoch 7:\n",
      "Batch 0 : training loss = 0.6005904674530029; training acc = 78.5\n",
      "Epoch 7 : Validation loss = 0.6413349807262421; Validation acc = 65.5\n",
      "Epoch 8:\n",
      "Batch 0 : training loss = 0.5909469127655029; training acc = 76.5\n",
      "Epoch 8 : Validation loss = 0.6280234679579735; Validation acc = 66.0\n",
      "Epoch 9:\n",
      "Batch 0 : training loss = 0.5762407779693604; training acc = 80.0\n",
      "Epoch 9 : Validation loss = 0.6114179193973541; Validation acc = 67.5\n",
      "Epoch 10:\n",
      "Batch 0 : training loss = 0.5454076528549194; training acc = 78.5\n",
      "Epoch 10 : Validation loss = 0.6007926687598228; Validation acc = 67.5\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6930088996887207; training acc = 52.0\n",
      "Epoch 1 : Validation loss = 0.6834334284067154; Validation acc = 56.5\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6841468214988708; training acc = 54.5\n",
      "Epoch 2 : Validation loss = 0.6891719102859497; Validation acc = 52.5\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6934615969657898; training acc = 51.5\n",
      "Epoch 1 : Validation loss = 0.6911474242806435; Validation acc = 51.5\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6814950704574585; training acc = 61.5\n",
      "Epoch 2 : Validation loss = 0.679678812623024; Validation acc = 65.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6738535165786743; training acc = 66.0\n",
      "Epoch 3 : Validation loss = 0.6724774390459061; Validation acc = 65.0\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.6585801839828491; training acc = 71.5\n",
      "Epoch 4 : Validation loss = 0.6615808308124542; Validation acc = 66.0\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.6373971104621887; training acc = 77.5\n",
      "Epoch 5 : Validation loss = 0.6479040384292603; Validation acc = 68.5\n",
      "Epoch 6:\n",
      "Batch 0 : training loss = 0.6090874671936035; training acc = 79.0\n",
      "Epoch 6 : Validation loss = 0.6299945265054703; Validation acc = 71.0\n",
      "Epoch 7:\n",
      "Batch 0 : training loss = 0.602435290813446; training acc = 75.5\n",
      "Epoch 7 : Validation loss = 0.6113073751330376; Validation acc = 76.0\n",
      "Epoch 8:\n",
      "Batch 0 : training loss = 0.5526412725448608; training acc = 83.0\n",
      "Epoch 8 : Validation loss = 0.590676873922348; Validation acc = 75.0\n",
      "Epoch 9:\n",
      "Batch 0 : training loss = 0.5111925005912781; training acc = 84.5\n",
      "Epoch 9 : Validation loss = 0.5689360573887825; Validation acc = 75.5\n",
      "Epoch 10:\n",
      "Batch 0 : training loss = 0.47635653614997864; training acc = 83.5\n",
      "Epoch 10 : Validation loss = 0.548217162489891; Validation acc = 77.0\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6950488090515137; training acc = 53.5\n",
      "Epoch 1 : Validation loss = 0.6845857426524162; Validation acc = 53.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.645945131778717; training acc = 66.0\n",
      "Epoch 2 : Validation loss = 0.7213864400982857; Validation acc = 46.5\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6941494941711426; training acc = 50.5\n",
      "Epoch 1 : Validation loss = 0.6733052432537079; Validation acc = 56.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.650520384311676; training acc = 65.5\n",
      "Epoch 2 : Validation loss = 0.7002136334776878; Validation acc = 49.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6923664808273315; training acc = 51.0\n",
      "Epoch 1 : Validation loss = 0.6937661916017532; Validation acc = 50.5\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6587047576904297; training acc = 64.5\n",
      "Epoch 2 : Validation loss = 0.6821484863758087; Validation acc = 55.5\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6314272284507751; training acc = 65.5\n",
      "Epoch 3 : Validation loss = 0.6753843501210213; Validation acc = 59.5\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.6328061819076538; training acc = 57.0\n",
      "Epoch 4 : Validation loss = 0.6751691922545433; Validation acc = 59.5\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.5811349749565125; training acc = 75.0\n",
      "Epoch 5 : Validation loss = 0.6944035291671753; Validation acc = 54.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.7380958795547485; training acc = 50.5\n",
      "Epoch 1 : Validation loss = 0.6916076615452766; Validation acc = 58.5\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.44249019026756287; training acc = 83.5\n",
      "Epoch 2 : Validation loss = 0.7213272750377655; Validation acc = 60.5\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.693732500076294; training acc = 50.0\n",
      "Epoch 1 : Validation loss = 0.6739860847592354; Validation acc = 54.5\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6148278117179871; training acc = 69.0\n",
      "Epoch 2 : Validation loss = 0.6288869604468346; Validation acc = 67.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.5126039981842041; training acc = 82.0\n",
      "Epoch 3 : Validation loss = 0.6416812986135483; Validation acc = 57.5\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.7192714810371399; training acc = 46.5\n",
      "Epoch 1 : Validation loss = 0.694032609462738; Validation acc = 45.5\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6922712922096252; training acc = 55.0\n",
      "Epoch 2 : Validation loss = 0.6952769905328751; Validation acc = 45.0\n",
      "Early stopping.\n",
      "RUN COURANT = 0\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.7060728669166565; training acc = 46.5\n",
      "Epoch 1 : Validation loss = 0.6923482790589333; Validation acc = 52.5\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6891048550605774; training acc = 53.0\n",
      "Epoch 2 : Validation loss = 0.6857323050498962; Validation acc = 57.5\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6721627712249756; training acc = 66.0\n",
      "Epoch 3 : Validation loss = 0.673982098698616; Validation acc = 57.0\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.6671438813209534; training acc = 64.0\n",
      "Epoch 4 : Validation loss = 0.6712711527943611; Validation acc = 60.0\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.646267831325531; training acc = 70.5\n",
      "Epoch 5 : Validation loss = 0.6633646935224533; Validation acc = 60.5\n",
      "Epoch 6:\n",
      "Batch 0 : training loss = 0.6248226761817932; training acc = 76.0\n",
      "Epoch 6 : Validation loss = 0.6546308472752571; Validation acc = 61.5\n",
      "Epoch 7:\n",
      "Batch 0 : training loss = 0.6051837205886841; training acc = 72.5\n",
      "Epoch 7 : Validation loss = 0.6430403292179108; Validation acc = 66.0\n",
      "Epoch 8:\n",
      "Batch 0 : training loss = 0.5906456112861633; training acc = 78.5\n",
      "Epoch 8 : Validation loss = 0.6333261728286743; Validation acc = 67.5\n",
      "Epoch 9:\n",
      "Batch 0 : training loss = 0.5869181156158447; training acc = 78.0\n",
      "Epoch 9 : Validation loss = 0.6200278252363205; Validation acc = 68.0\n",
      "Epoch 10:\n",
      "Batch 0 : training loss = 0.557763934135437; training acc = 78.5\n",
      "Epoch 10 : Validation loss = 0.6082745939493179; Validation acc = 67.0\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.704631507396698; training acc = 46.5\n",
      "Epoch 1 : Validation loss = 0.6882955655455589; Validation acc = 59.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6888267397880554; training acc = 58.5\n",
      "Epoch 2 : Validation loss = 0.6865643933415413; Validation acc = 60.5\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6876972913742065; training acc = 60.5\n",
      "Epoch 3 : Validation loss = 0.6855165436863899; Validation acc = 62.0\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.680633544921875; training acc = 65.5\n",
      "Epoch 4 : Validation loss = 0.6824375614523888; Validation acc = 61.0\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.6799739599227905; training acc = 59.5\n",
      "Epoch 5 : Validation loss = 0.677842915058136; Validation acc = 62.0\n",
      "Epoch 6:\n",
      "Batch 0 : training loss = 0.6766068339347839; training acc = 63.0\n",
      "Epoch 6 : Validation loss = 0.6760653629899025; Validation acc = 60.0\n",
      "Epoch 7:\n",
      "Batch 0 : training loss = 0.673210859298706; training acc = 65.0\n",
      "Epoch 7 : Validation loss = 0.6738938242197037; Validation acc = 60.5\n",
      "Epoch 8:\n",
      "Batch 0 : training loss = 0.6653757691383362; training acc = 65.5\n",
      "Epoch 8 : Validation loss = 0.6717105880379677; Validation acc = 61.0\n",
      "Epoch 9:\n",
      "Batch 0 : training loss = 0.6677448153495789; training acc = 65.5\n",
      "Epoch 9 : Validation loss = 0.668090745806694; Validation acc = 61.5\n",
      "Epoch 10:\n",
      "Batch 0 : training loss = 0.6663060784339905; training acc = 60.0\n",
      "Epoch 10 : Validation loss = 0.664183035492897; Validation acc = 62.5\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6901803016662598; training acc = 52.0\n",
      "Epoch 1 : Validation loss = 0.6846029832959175; Validation acc = 60.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6790838837623596; training acc = 69.0\n",
      "Epoch 2 : Validation loss = 0.680400513112545; Validation acc = 63.5\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6688115000724792; training acc = 71.5\n",
      "Epoch 3 : Validation loss = 0.6717333272099495; Validation acc = 66.0\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.6583234667778015; training acc = 67.0\n",
      "Epoch 4 : Validation loss = 0.6596700772643089; Validation acc = 68.5\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.6397495865821838; training acc = 70.5\n",
      "Epoch 5 : Validation loss = 0.6516828313469887; Validation acc = 64.0\n",
      "Epoch 6:\n",
      "Batch 0 : training loss = 0.6213752627372742; training acc = 74.0\n",
      "Epoch 6 : Validation loss = 0.6321653872728348; Validation acc = 71.5\n",
      "Epoch 7:\n",
      "Batch 0 : training loss = 0.6157695055007935; training acc = 70.0\n",
      "Epoch 7 : Validation loss = 0.6227040886878967; Validation acc = 70.0\n",
      "Epoch 8:\n",
      "Batch 0 : training loss = 0.5690500140190125; training acc = 78.0\n",
      "Epoch 8 : Validation loss = 0.5990501716732979; Validation acc = 73.0\n",
      "Epoch 9:\n",
      "Batch 0 : training loss = 0.5290893316268921; training acc = 81.0\n",
      "Epoch 9 : Validation loss = 0.5794924199581146; Validation acc = 72.5\n",
      "Epoch 10:\n",
      "Batch 0 : training loss = 0.4925704896450043; training acc = 85.5\n",
      "Epoch 10 : Validation loss = 0.5641534253954887; Validation acc = 72.5\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6900970935821533; training acc = 54.0\n",
      "Epoch 1 : Validation loss = 0.7052651196718216; Validation acc = 47.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6523361802101135; training acc = 64.0\n",
      "Epoch 2 : Validation loss = 0.7126775532960892; Validation acc = 54.5\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6915327310562134; training acc = 53.0\n",
      "Epoch 1 : Validation loss = 0.7003732919692993; Validation acc = 48.5\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6771393418312073; training acc = 57.0\n",
      "Epoch 2 : Validation loss = 0.684063658118248; Validation acc = 56.5\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6764721870422363; training acc = 61.0\n",
      "Epoch 3 : Validation loss = 0.6862664595246315; Validation acc = 55.5\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6918588876724243; training acc = 51.0\n",
      "Epoch 1 : Validation loss = 0.6924707069993019; Validation acc = 52.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6540780663490295; training acc = 64.0\n",
      "Epoch 2 : Validation loss = 0.7165683060884476; Validation acc = 56.5\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.7014428973197937; training acc = 50.0\n",
      "Epoch 1 : Validation loss = 0.6815798804163933; Validation acc = 56.5\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.4760914742946625; training acc = 88.0\n",
      "Epoch 2 : Validation loss = 0.8277169317007065; Validation acc = 48.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6939317584037781; training acc = 51.5\n",
      "Epoch 1 : Validation loss = 0.6558442339301109; Validation acc = 57.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6201514601707458; training acc = 61.0\n",
      "Epoch 2 : Validation loss = 0.6183568686246872; Validation acc = 71.5\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.5395764708518982; training acc = 85.5\n",
      "Epoch 3 : Validation loss = 0.5809809863567352; Validation acc = 73.0\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.42441534996032715; training acc = 88.5\n",
      "Epoch 4 : Validation loss = 0.5461190566420555; Validation acc = 74.0\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.3089865744113922; training acc = 97.0\n",
      "Epoch 5 : Validation loss = 0.5671350546181202; Validation acc = 71.5\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6971357464790344; training acc = 45.5\n",
      "Epoch 1 : Validation loss = 0.6829151883721352; Validation acc = 55.5\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6907920241355896; training acc = 43.5\n",
      "Epoch 2 : Validation loss = 0.6722211539745331; Validation acc = 55.5\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6493744850158691; training acc = 50.0\n",
      "Epoch 3 : Validation loss = 0.6618524864315987; Validation acc = 55.5\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.6021234393119812; training acc = 54.0\n",
      "Epoch 4 : Validation loss = 0.6484573855996132; Validation acc = 58.0\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.5433568954467773; training acc = 64.0\n",
      "Epoch 5 : Validation loss = 0.6321501284837723; Validation acc = 61.0\n",
      "Epoch 6:\n",
      "Batch 0 : training loss = 0.4771921634674072; training acc = 86.0\n",
      "Epoch 6 : Validation loss = 0.5971289500594139; Validation acc = 64.5\n",
      "Epoch 7:\n",
      "Batch 0 : training loss = 0.33491000533103943; training acc = 97.0\n",
      "Epoch 7 : Validation loss = 0.5885594226419926; Validation acc = 67.5\n",
      "Epoch 8:\n",
      "Batch 0 : training loss = 0.21377970278263092; training acc = 97.0\n",
      "Epoch 8 : Validation loss = 0.5953385382890701; Validation acc = 68.5\n",
      "Early stopping.\n",
      "RUN COURANT = 1\n",
      "RUN COURANT = 1\n",
      "RUN COURANT = 1\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.7034111022949219; training acc = 46.0\n",
      "Epoch 1 : Validation loss = 0.6881536245346069; Validation acc = 58.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6847326755523682; training acc = 60.5\n",
      "Epoch 2 : Validation loss = 0.687548816204071; Validation acc = 56.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6724920868873596; training acc = 64.5\n",
      "Epoch 3 : Validation loss = 0.6904715001583099; Validation acc = 52.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.7064114212989807; training acc = 45.5\n",
      "Epoch 1 : Validation loss = 0.6955754458904266; Validation acc = 46.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6962524652481079; training acc = 48.5\n",
      "Epoch 2 : Validation loss = 0.6891027092933655; Validation acc = 50.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6896715760231018; training acc = 57.5\n",
      "Epoch 3 : Validation loss = 0.6856549382209778; Validation acc = 54.0\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.6935286521911621; training acc = 50.0\n",
      "Epoch 4 : Validation loss = 0.6839720010757446; Validation acc = 54.0\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.6881901621818542; training acc = 53.0\n",
      "Epoch 5 : Validation loss = 0.6826397180557251; Validation acc = 54.0\n",
      "Epoch 6:\n",
      "Batch 0 : training loss = 0.6856585741043091; training acc = 54.0\n",
      "Epoch 6 : Validation loss = 0.6811802983283997; Validation acc = 54.0\n",
      "Epoch 7:\n",
      "Batch 0 : training loss = 0.6839959621429443; training acc = 53.0\n",
      "Epoch 7 : Validation loss = 0.6795321106910706; Validation acc = 54.0\n",
      "Epoch 8:\n",
      "Batch 0 : training loss = 0.6832584142684937; training acc = 53.5\n",
      "Epoch 8 : Validation loss = 0.67790287733078; Validation acc = 54.0\n",
      "Epoch 9:\n",
      "Batch 0 : training loss = 0.6795138716697693; training acc = 55.0\n",
      "Epoch 9 : Validation loss = 0.676466703414917; Validation acc = 54.0\n",
      "Epoch 10:\n",
      "Batch 0 : training loss = 0.68143630027771; training acc = 53.5\n",
      "Epoch 10 : Validation loss = 0.6752896308898926; Validation acc = 54.0\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6955360174179077; training acc = 49.5\n",
      "Epoch 1 : Validation loss = 0.6875371932983398; Validation acc = 54.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6866097450256348; training acc = 62.0\n",
      "Epoch 2 : Validation loss = 0.6833712756633759; Validation acc = 54.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6824721693992615; training acc = 52.5\n",
      "Epoch 3 : Validation loss = 0.6808685064315796; Validation acc = 54.0\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.6739704012870789; training acc = 53.5\n",
      "Epoch 4 : Validation loss = 0.6784006059169769; Validation acc = 54.0\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.6648086309432983; training acc = 54.5\n",
      "Epoch 5 : Validation loss = 0.6757843792438507; Validation acc = 54.0\n",
      "Epoch 6:\n",
      "Batch 0 : training loss = 0.6690161228179932; training acc = 50.0\n",
      "Epoch 6 : Validation loss = 0.6732378304004669; Validation acc = 54.0\n",
      "Epoch 7:\n",
      "Batch 0 : training loss = 0.6519796252250671; training acc = 61.0\n",
      "Epoch 7 : Validation loss = 0.6707246005535126; Validation acc = 54.0\n",
      "Epoch 8:\n",
      "Batch 0 : training loss = 0.6468725800514221; training acc = 69.5\n",
      "Epoch 8 : Validation loss = 0.6681953966617584; Validation acc = 60.0\n",
      "Epoch 9:\n",
      "Batch 0 : training loss = 0.6375057697296143; training acc = 79.5\n",
      "Epoch 9 : Validation loss = 0.6654028296470642; Validation acc = 68.0\n",
      "Epoch 10:\n",
      "Batch 0 : training loss = 0.6286758184432983; training acc = 85.0\n",
      "Epoch 10 : Validation loss = 0.6625592708587646; Validation acc = 70.0\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6910065412521362; training acc = 53.5\n",
      "Epoch 1 : Validation loss = 0.6987332701683044; Validation acc = 50.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6243087649345398; training acc = 73.5\n",
      "Epoch 2 : Validation loss = 0.7010275423526764; Validation acc = 56.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6931326985359192; training acc = 49.0\n",
      "Epoch 1 : Validation loss = 0.6802371144294739; Validation acc = 56.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6697730422019958; training acc = 62.5\n",
      "Epoch 2 : Validation loss = 0.6775647401809692; Validation acc = 60.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6432244777679443; training acc = 66.5\n",
      "Epoch 3 : Validation loss = 0.671278715133667; Validation acc = 60.0\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.5914609432220459; training acc = 70.5\n",
      "Epoch 4 : Validation loss = 0.6778307557106018; Validation acc = 62.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6916398406028748; training acc = 52.0\n",
      "Epoch 1 : Validation loss = 0.679681807756424; Validation acc = 54.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6809905767440796; training acc = 52.0\n",
      "Epoch 2 : Validation loss = 0.6823203265666962; Validation acc = 58.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6942996382713318; training acc = 55.0\n",
      "Epoch 1 : Validation loss = 0.7143573760986328; Validation acc = 56.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.2994857430458069; training acc = 92.5\n",
      "Epoch 2 : Validation loss = 0.6982877552509308; Validation acc = 56.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.11565746366977692; training acc = 100.0\n",
      "Epoch 3 : Validation loss = 0.6475891172885895; Validation acc = 58.0\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.04252661392092705; training acc = 100.0\n",
      "Epoch 4 : Validation loss = 0.689734011888504; Validation acc = 58.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6954437494277954; training acc = 50.5\n",
      "Epoch 1 : Validation loss = 0.7170107364654541; Validation acc = 46.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.614321768283844; training acc = 56.5\n",
      "Epoch 2 : Validation loss = 0.6469722986221313; Validation acc = 60.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.4986930191516876; training acc = 96.5\n",
      "Epoch 3 : Validation loss = 0.6382170915603638; Validation acc = 56.0\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.4291951060295105; training acc = 94.0\n",
      "Epoch 4 : Validation loss = 0.6228077113628387; Validation acc = 64.0\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.3526192605495453; training acc = 99.0\n",
      "Epoch 5 : Validation loss = 0.5961647033691406; Validation acc = 74.0\n",
      "Epoch 6:\n",
      "Batch 0 : training loss = 0.24895291030406952; training acc = 100.0\n",
      "Epoch 6 : Validation loss = 0.5868515372276306; Validation acc = 70.0\n",
      "Epoch 7:\n",
      "Batch 0 : training loss = 0.19486483931541443; training acc = 100.0\n",
      "Epoch 7 : Validation loss = 0.5660980045795441; Validation acc = 78.0\n",
      "Epoch 8:\n",
      "Batch 0 : training loss = 0.15552017092704773; training acc = 100.0\n",
      "Epoch 8 : Validation loss = 0.5566582977771759; Validation acc = 78.0\n",
      "Epoch 9:\n",
      "Batch 0 : training loss = 0.10469822585582733; training acc = 100.0\n",
      "Epoch 9 : Validation loss = 0.5563360154628754; Validation acc = 72.0\n",
      "Epoch 10:\n",
      "Batch 0 : training loss = 0.08533171564340591; training acc = 100.0\n",
      "Epoch 10 : Validation loss = 0.5275585353374481; Validation acc = 84.0\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.7111154198646545; training acc = 44.5\n",
      "Epoch 1 : Validation loss = 0.82859206199646; Validation acc = 46.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.7422071099281311; training acc = 51.5\n",
      "Epoch 2 : Validation loss = 0.6853969097137451; Validation acc = 54.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6709771156311035; training acc = 50.5\n",
      "Epoch 3 : Validation loss = 0.677530825138092; Validation acc = 54.0\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.6616477370262146; training acc = 52.0\n",
      "Epoch 4 : Validation loss = 0.6723637580871582; Validation acc = 54.0\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.6405166387557983; training acc = 53.0\n",
      "Epoch 5 : Validation loss = 0.6652584671974182; Validation acc = 54.0\n",
      "Epoch 6:\n",
      "Batch 0 : training loss = 0.6053486466407776; training acc = 55.0\n",
      "Epoch 6 : Validation loss = 0.6620640158653259; Validation acc = 54.0\n",
      "Epoch 7:\n",
      "Batch 0 : training loss = 0.6076727509498596; training acc = 53.0\n",
      "Epoch 7 : Validation loss = 0.6561932861804962; Validation acc = 54.0\n",
      "Epoch 8:\n",
      "Batch 0 : training loss = 0.5632076859474182; training acc = 54.5\n",
      "Epoch 8 : Validation loss = 0.6507624685764313; Validation acc = 54.0\n",
      "Epoch 9:\n",
      "Batch 0 : training loss = 0.5479505062103271; training acc = 54.0\n",
      "Epoch 9 : Validation loss = 0.6474922001361847; Validation acc = 54.0\n",
      "Epoch 10:\n",
      "Batch 0 : training loss = 0.5028764605522156; training acc = 58.5\n",
      "Epoch 10 : Validation loss = 0.6423847675323486; Validation acc = 54.0\n",
      "RUN COURANT = 1\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6944037675857544; training acc = 53.0\n",
      "Epoch 1 : Validation loss = 0.6877738237380981; Validation acc = 58.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6937405467033386; training acc = 50.0\n",
      "Epoch 2 : Validation loss = 0.6873449981212616; Validation acc = 56.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6805199980735779; training acc = 55.5\n",
      "Epoch 3 : Validation loss = 0.6869058907032013; Validation acc = 58.0\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.6778413653373718; training acc = 56.0\n",
      "Epoch 4 : Validation loss = 0.6863031983375549; Validation acc = 62.0\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.677956223487854; training acc = 63.5\n",
      "Epoch 5 : Validation loss = 0.6841070055961609; Validation acc = 62.0\n",
      "Epoch 6:\n",
      "Batch 0 : training loss = 0.6736965775489807; training acc = 58.5\n",
      "Epoch 6 : Validation loss = 0.6824405491352081; Validation acc = 62.0\n",
      "Epoch 7:\n",
      "Batch 0 : training loss = 0.6638095378875732; training acc = 64.5\n",
      "Epoch 7 : Validation loss = 0.68046635389328; Validation acc = 62.0\n",
      "Epoch 8:\n",
      "Batch 0 : training loss = 0.6502088904380798; training acc = 69.0\n",
      "Epoch 8 : Validation loss = 0.6788153648376465; Validation acc = 62.0\n",
      "Epoch 9:\n",
      "Batch 0 : training loss = 0.6490010619163513; training acc = 69.5\n",
      "Epoch 9 : Validation loss = 0.6759871542453766; Validation acc = 62.0\n",
      "Epoch 10:\n",
      "Batch 0 : training loss = 0.6370272636413574; training acc = 73.0\n",
      "Epoch 10 : Validation loss = 0.6744234263896942; Validation acc = 70.0\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6920846700668335; training acc = 52.0\n",
      "Epoch 1 : Validation loss = 0.6891679763793945; Validation acc = 54.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6914270520210266; training acc = 52.5\n",
      "Epoch 2 : Validation loss = 0.6870453953742981; Validation acc = 54.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6888828873634338; training acc = 52.0\n",
      "Epoch 3 : Validation loss = 0.6852416694164276; Validation acc = 54.0\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.6876418590545654; training acc = 52.5\n",
      "Epoch 4 : Validation loss = 0.6836113333702087; Validation acc = 54.0\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.6809242963790894; training acc = 56.0\n",
      "Epoch 5 : Validation loss = 0.6820601522922516; Validation acc = 54.0\n",
      "Epoch 6:\n",
      "Batch 0 : training loss = 0.6834686994552612; training acc = 52.5\n",
      "Epoch 6 : Validation loss = 0.6807460188865662; Validation acc = 54.0\n",
      "Epoch 7:\n",
      "Batch 0 : training loss = 0.6843084096908569; training acc = 52.5\n",
      "Epoch 7 : Validation loss = 0.6795856356620789; Validation acc = 54.0\n",
      "Epoch 8:\n",
      "Batch 0 : training loss = 0.6752468347549438; training acc = 57.5\n",
      "Epoch 8 : Validation loss = 0.6782578825950623; Validation acc = 56.0\n",
      "Epoch 9:\n",
      "Batch 0 : training loss = 0.6769530773162842; training acc = 59.0\n",
      "Epoch 9 : Validation loss = 0.676868349313736; Validation acc = 58.0\n",
      "Epoch 10:\n",
      "Batch 0 : training loss = 0.6740940809249878; training acc = 61.0\n",
      "Epoch 10 : Validation loss = 0.6753850877285004; Validation acc = 58.0\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6976481080055237; training acc = 43.5\n",
      "Epoch 1 : Validation loss = 0.6880077421665192; Validation acc = 52.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.687085747718811; training acc = 54.0\n",
      "Epoch 2 : Validation loss = 0.6845434606075287; Validation acc = 54.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6937407851219177; training acc = 45.5\n",
      "Epoch 3 : Validation loss = 0.6825809478759766; Validation acc = 54.0\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.6809332370758057; training acc = 51.0\n",
      "Epoch 4 : Validation loss = 0.6805571615695953; Validation acc = 54.0\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.6782204508781433; training acc = 50.5\n",
      "Epoch 5 : Validation loss = 0.6785585284233093; Validation acc = 54.0\n",
      "Epoch 6:\n",
      "Batch 0 : training loss = 0.6667343974113464; training acc = 55.5\n",
      "Epoch 6 : Validation loss = 0.6764598488807678; Validation acc = 54.0\n",
      "Epoch 7:\n",
      "Batch 0 : training loss = 0.6639063954353333; training acc = 55.0\n",
      "Epoch 7 : Validation loss = 0.6744074821472168; Validation acc = 54.0\n",
      "Epoch 8:\n",
      "Batch 0 : training loss = 0.6575372219085693; training acc = 56.5\n",
      "Epoch 8 : Validation loss = 0.6722588837146759; Validation acc = 58.0\n",
      "Epoch 9:\n",
      "Batch 0 : training loss = 0.6518581509590149; training acc = 62.0\n",
      "Epoch 9 : Validation loss = 0.67013019323349; Validation acc = 58.0\n",
      "Epoch 10:\n",
      "Batch 0 : training loss = 0.6384271383285522; training acc = 72.5\n",
      "Epoch 10 : Validation loss = 0.6677073240280151; Validation acc = 64.0\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6930900812149048; training acc = 50.5\n",
      "Epoch 1 : Validation loss = 0.7008770704269409; Validation acc = 52.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6372240781784058; training acc = 67.5\n",
      "Epoch 2 : Validation loss = 0.6750293374061584; Validation acc = 60.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.5790212750434875; training acc = 77.0\n",
      "Epoch 3 : Validation loss = 0.679178774356842; Validation acc = 58.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6921600103378296; training acc = 53.5\n",
      "Epoch 1 : Validation loss = 0.6825172901153564; Validation acc = 52.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6700567603111267; training acc = 56.0\n",
      "Epoch 2 : Validation loss = 0.689144492149353; Validation acc = 56.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6986867785453796; training acc = 44.0\n",
      "Epoch 1 : Validation loss = 0.6801862716674805; Validation acc = 54.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6769965291023254; training acc = 53.5\n",
      "Epoch 2 : Validation loss = 0.6803061664104462; Validation acc = 64.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.682321310043335; training acc = 57.5\n",
      "Epoch 1 : Validation loss = 1.0934561491012573; Validation acc = 54.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6141599416732788; training acc = 61.5\n",
      "Epoch 2 : Validation loss = 1.1233071088790894; Validation acc = 46.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.7072652578353882; training acc = 45.0\n",
      "Epoch 1 : Validation loss = 0.7962473332881927; Validation acc = 54.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.7350399494171143; training acc = 56.5\n",
      "Epoch 2 : Validation loss = 0.6944644451141357; Validation acc = 46.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.686004102230072; training acc = 57.0\n",
      "Epoch 3 : Validation loss = 0.6949598491191864; Validation acc = 44.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.7390792369842529; training acc = 44.5\n",
      "Epoch 1 : Validation loss = 0.841925710439682; Validation acc = 54.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.8784282207489014; training acc = 49.5\n",
      "Epoch 2 : Validation loss = 0.689429372549057; Validation acc = 56.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.683226466178894; training acc = 50.5\n",
      "Epoch 3 : Validation loss = 0.6916147470474243; Validation acc = 56.0\n",
      "Early stopping.\n",
      "RUN COURANT = 1\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6882935166358948; training acc = 53.0\n",
      "Epoch 1 : Validation loss = 0.6885755360126495; Validation acc = 56.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6832019090652466; training acc = 53.5\n",
      "Epoch 2 : Validation loss = 0.6890456080436707; Validation acc = 60.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.691694974899292; training acc = 54.0\n",
      "Epoch 1 : Validation loss = 0.6880552470684052; Validation acc = 54.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.692504346370697; training acc = 52.0\n",
      "Epoch 2 : Validation loss = 0.6867269575595856; Validation acc = 54.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6881356835365295; training acc = 54.5\n",
      "Epoch 3 : Validation loss = 0.6853139698505402; Validation acc = 54.0\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.6892188787460327; training acc = 52.5\n",
      "Epoch 4 : Validation loss = 0.6840750575065613; Validation acc = 54.0\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.6838037371635437; training acc = 56.5\n",
      "Epoch 5 : Validation loss = 0.6827977299690247; Validation acc = 54.0\n",
      "Epoch 6:\n",
      "Batch 0 : training loss = 0.6906884908676147; training acc = 50.0\n",
      "Epoch 6 : Validation loss = 0.6818290054798126; Validation acc = 54.0\n",
      "Epoch 7:\n",
      "Batch 0 : training loss = 0.6884483098983765; training acc = 51.0\n",
      "Epoch 7 : Validation loss = 0.6808129847049713; Validation acc = 54.0\n",
      "Epoch 8:\n",
      "Batch 0 : training loss = 0.6851572394371033; training acc = 53.0\n",
      "Epoch 8 : Validation loss = 0.6796395480632782; Validation acc = 54.0\n",
      "Epoch 9:\n",
      "Batch 0 : training loss = 0.6843096017837524; training acc = 52.5\n",
      "Epoch 9 : Validation loss = 0.6784561276435852; Validation acc = 54.0\n",
      "Epoch 10:\n",
      "Batch 0 : training loss = 0.6790966987609863; training acc = 58.0\n",
      "Epoch 10 : Validation loss = 0.6770444512367249; Validation acc = 54.0\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6930890083312988; training acc = 51.0\n",
      "Epoch 1 : Validation loss = 0.6911484599113464; Validation acc = 54.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.686024010181427; training acc = 55.5\n",
      "Epoch 2 : Validation loss = 0.688166081905365; Validation acc = 54.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6851727366447449; training acc = 51.0\n",
      "Epoch 3 : Validation loss = 0.6862660944461823; Validation acc = 54.0\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.6752576231956482; training acc = 55.0\n",
      "Epoch 4 : Validation loss = 0.6843337714672089; Validation acc = 54.0\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.6705114841461182; training acc = 55.5\n",
      "Epoch 5 : Validation loss = 0.6824845671653748; Validation acc = 54.0\n",
      "Epoch 6:\n",
      "Batch 0 : training loss = 0.6755619645118713; training acc = 51.5\n",
      "Epoch 6 : Validation loss = 0.680957019329071; Validation acc = 54.0\n",
      "Epoch 7:\n",
      "Batch 0 : training loss = 0.6686483025550842; training acc = 55.5\n",
      "Epoch 7 : Validation loss = 0.6794384717941284; Validation acc = 56.0\n",
      "Epoch 8:\n",
      "Batch 0 : training loss = 0.6578119397163391; training acc = 68.0\n",
      "Epoch 8 : Validation loss = 0.6776314377784729; Validation acc = 60.0\n",
      "Epoch 9:\n",
      "Batch 0 : training loss = 0.6562970876693726; training acc = 67.5\n",
      "Epoch 9 : Validation loss = 0.6758041679859161; Validation acc = 64.0\n",
      "Epoch 10:\n",
      "Batch 0 : training loss = 0.6508843898773193; training acc = 72.5\n",
      "Epoch 10 : Validation loss = 0.6739470660686493; Validation acc = 64.0\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6915209293365479; training acc = 52.5\n",
      "Epoch 1 : Validation loss = 0.7177050113677979; Validation acc = 52.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6361395716667175; training acc = 70.0\n",
      "Epoch 2 : Validation loss = 0.7093665301799774; Validation acc = 52.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.5557708144187927; training acc = 80.0\n",
      "Epoch 3 : Validation loss = 0.7071302533149719; Validation acc = 54.0\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.5321311950683594; training acc = 80.0\n",
      "Epoch 4 : Validation loss = 0.7205953299999237; Validation acc = 60.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6899759769439697; training acc = 54.5\n",
      "Epoch 1 : Validation loss = 0.6833501160144806; Validation acc = 52.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6695110201835632; training acc = 59.5\n",
      "Epoch 2 : Validation loss = 0.6906213462352753; Validation acc = 52.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6919924020767212; training acc = 56.5\n",
      "Epoch 1 : Validation loss = 0.6847932040691376; Validation acc = 54.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6786548495292664; training acc = 54.0\n",
      "Epoch 2 : Validation loss = 0.6907623708248138; Validation acc = 60.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.7397060990333557; training acc = 56.0\n",
      "Epoch 1 : Validation loss = 0.733273059129715; Validation acc = 56.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.46147751808166504; training acc = 81.5\n",
      "Epoch 2 : Validation loss = 0.9648615121841431; Validation acc = 54.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6880948543548584; training acc = 56.0\n",
      "Epoch 1 : Validation loss = 0.6934726238250732; Validation acc = 46.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6182548403739929; training acc = 64.0\n",
      "Epoch 2 : Validation loss = 0.7285826802253723; Validation acc = 46.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.7045019268989563; training acc = 47.5\n",
      "Epoch 1 : Validation loss = 0.7243077754974365; Validation acc = 54.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.7020653486251831; training acc = 51.5\n",
      "Epoch 2 : Validation loss = 0.6996027827262878; Validation acc = 46.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6782374382019043; training acc = 43.0\n",
      "Epoch 3 : Validation loss = 0.6947415173053741; Validation acc = 46.0\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.6438724994659424; training acc = 51.0\n",
      "Epoch 4 : Validation loss = 0.6941871047019958; Validation acc = 42.0\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.6019618511199951; training acc = 54.0\n",
      "Epoch 5 : Validation loss = 0.6957985758781433; Validation acc = 44.0\n",
      "Early stopping.\n",
      "RUN COURANT = 1\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6967386603355408; training acc = 47.0\n",
      "Epoch 1 : Validation loss = 0.6878851354122162; Validation acc = 56.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6873951554298401; training acc = 54.0\n",
      "Epoch 2 : Validation loss = 0.6884357631206512; Validation acc = 56.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6897618174552917; training acc = 54.0\n",
      "Epoch 1 : Validation loss = 0.6880400478839874; Validation acc = 54.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6877353191375732; training acc = 54.5\n",
      "Epoch 2 : Validation loss = 0.6869468688964844; Validation acc = 54.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.69384765625; training acc = 49.5\n",
      "Epoch 3 : Validation loss = 0.6864682137966156; Validation acc = 54.0\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.6888744831085205; training acc = 51.0\n",
      "Epoch 4 : Validation loss = 0.6856975853443146; Validation acc = 54.0\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.6888910531997681; training acc = 50.5\n",
      "Epoch 5 : Validation loss = 0.684766560792923; Validation acc = 54.0\n",
      "Epoch 6:\n",
      "Batch 0 : training loss = 0.6828673481941223; training acc = 56.5\n",
      "Epoch 6 : Validation loss = 0.6835118234157562; Validation acc = 54.0\n",
      "Epoch 7:\n",
      "Batch 0 : training loss = 0.6860200762748718; training acc = 52.0\n",
      "Epoch 7 : Validation loss = 0.6825001537799835; Validation acc = 54.0\n",
      "Epoch 8:\n",
      "Batch 0 : training loss = 0.6800857782363892; training acc = 57.0\n",
      "Epoch 8 : Validation loss = 0.6814047694206238; Validation acc = 54.0\n",
      "Epoch 9:\n",
      "Batch 0 : training loss = 0.6772755980491638; training acc = 56.5\n",
      "Epoch 9 : Validation loss = 0.6804479658603668; Validation acc = 54.0\n",
      "Epoch 10:\n",
      "Batch 0 : training loss = 0.6785099506378174; training acc = 57.5\n",
      "Epoch 10 : Validation loss = 0.6795564293861389; Validation acc = 54.0\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6939375996589661; training acc = 47.5\n",
      "Epoch 1 : Validation loss = 0.6868168413639069; Validation acc = 54.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6861270070075989; training acc = 54.5\n",
      "Epoch 2 : Validation loss = 0.6846482157707214; Validation acc = 54.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6840237379074097; training acc = 54.5\n",
      "Epoch 3 : Validation loss = 0.6830830872058868; Validation acc = 54.0\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.6761242747306824; training acc = 57.5\n",
      "Epoch 4 : Validation loss = 0.6816807389259338; Validation acc = 54.0\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.6813633441925049; training acc = 52.5\n",
      "Epoch 5 : Validation loss = 0.6805377900600433; Validation acc = 54.0\n",
      "Epoch 6:\n",
      "Batch 0 : training loss = 0.6806235313415527; training acc = 51.5\n",
      "Epoch 6 : Validation loss = 0.6796963214874268; Validation acc = 56.0\n",
      "Epoch 7:\n",
      "Batch 0 : training loss = 0.6744840741157532; training acc = 59.0\n",
      "Epoch 7 : Validation loss = 0.6784100532531738; Validation acc = 60.0\n",
      "Epoch 8:\n",
      "Batch 0 : training loss = 0.6698592901229858; training acc = 66.5\n",
      "Epoch 8 : Validation loss = 0.6767656207084656; Validation acc = 60.0\n",
      "Epoch 9:\n",
      "Batch 0 : training loss = 0.662509024143219; training acc = 71.5\n",
      "Epoch 9 : Validation loss = 0.6748048663139343; Validation acc = 60.0\n",
      "Epoch 10:\n",
      "Batch 0 : training loss = 0.6634932160377502; training acc = 66.5\n",
      "Epoch 10 : Validation loss = 0.6730161011219025; Validation acc = 62.0\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6958847045898438; training acc = 46.0\n",
      "Epoch 1 : Validation loss = 0.6900585889816284; Validation acc = 54.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6549318432807922; training acc = 63.5\n",
      "Epoch 2 : Validation loss = 0.6874107122421265; Validation acc = 48.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.5796147584915161; training acc = 75.5\n",
      "Epoch 3 : Validation loss = 0.6978815793991089; Validation acc = 54.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.690508246421814; training acc = 55.0\n",
      "Epoch 1 : Validation loss = 0.6823789179325104; Validation acc = 54.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6769933104515076; training acc = 54.0\n",
      "Epoch 2 : Validation loss = 0.6877231895923615; Validation acc = 56.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6922097206115723; training acc = 51.0\n",
      "Epoch 1 : Validation loss = 0.6803042590618134; Validation acc = 52.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.674344003200531; training acc = 54.0\n",
      "Epoch 2 : Validation loss = 0.6760417222976685; Validation acc = 52.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6561789512634277; training acc = 60.5\n",
      "Epoch 3 : Validation loss = 0.6799774169921875; Validation acc = 54.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.8148383498191833; training acc = 41.5\n",
      "Epoch 1 : Validation loss = 1.6853039264678955; Validation acc = 54.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 1.433050513267517; training acc = 52.0\n",
      "Epoch 2 : Validation loss = 0.9710293710231781; Validation acc = 46.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.7724621295928955; training acc = 48.5\n",
      "Epoch 3 : Validation loss = 1.0915961861610413; Validation acc = 42.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6886357069015503; training acc = 57.5\n",
      "Epoch 1 : Validation loss = 0.7184580266475677; Validation acc = 54.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6931724548339844; training acc = 52.5\n",
      "Epoch 2 : Validation loss = 0.7174650132656097; Validation acc = 46.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6864839196205139; training acc = 46.5\n",
      "Epoch 3 : Validation loss = 0.7047027051448822; Validation acc = 46.0\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.6572476029396057; training acc = 46.5\n",
      "Epoch 4 : Validation loss = 0.7086283564567566; Validation acc = 46.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.7417370676994324; training acc = 50.0\n",
      "Epoch 1 : Validation loss = 0.7556754350662231; Validation acc = 54.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.7274259328842163; training acc = 55.5\n",
      "Epoch 2 : Validation loss = 0.6858656406402588; Validation acc = 66.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6750670671463013; training acc = 73.5\n",
      "Epoch 3 : Validation loss = 0.6963929533958435; Validation acc = 46.0\n",
      "Early stopping.\n",
      "RUN COURANT = 1\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6854618191719055; training acc = 56.0\n",
      "Epoch 1 : Validation loss = 0.689469039440155; Validation acc = 54.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.685428261756897; training acc = 55.5\n",
      "Epoch 2 : Validation loss = 0.6928662955760956; Validation acc = 56.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6958529949188232; training acc = 46.0\n",
      "Epoch 1 : Validation loss = 0.6898645758628845; Validation acc = 56.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6918136477470398; training acc = 52.5\n",
      "Epoch 2 : Validation loss = 0.6875708699226379; Validation acc = 54.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6919439435005188; training acc = 52.0\n",
      "Epoch 3 : Validation loss = 0.6863841712474823; Validation acc = 54.0\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.6918851733207703; training acc = 51.5\n",
      "Epoch 4 : Validation loss = 0.6855540573596954; Validation acc = 54.0\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.6871422529220581; training acc = 53.5\n",
      "Epoch 5 : Validation loss = 0.6847252547740936; Validation acc = 54.0\n",
      "Epoch 6:\n",
      "Batch 0 : training loss = 0.6862525343894958; training acc = 54.0\n",
      "Epoch 6 : Validation loss = 0.6839646100997925; Validation acc = 54.0\n",
      "Epoch 7:\n",
      "Batch 0 : training loss = 0.6873360276222229; training acc = 52.5\n",
      "Epoch 7 : Validation loss = 0.6834453344345093; Validation acc = 54.0\n",
      "Epoch 8:\n",
      "Batch 0 : training loss = 0.6861059665679932; training acc = 54.5\n",
      "Epoch 8 : Validation loss = 0.6829507052898407; Validation acc = 54.0\n",
      "Epoch 9:\n",
      "Batch 0 : training loss = 0.6851489543914795; training acc = 55.0\n",
      "Epoch 9 : Validation loss = 0.6824527382850647; Validation acc = 56.0\n",
      "Epoch 10:\n",
      "Batch 0 : training loss = 0.6865850687026978; training acc = 52.5\n",
      "Epoch 10 : Validation loss = 0.6820854246616364; Validation acc = 60.0\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6948446035385132; training acc = 49.5\n",
      "Epoch 1 : Validation loss = 0.6912552118301392; Validation acc = 54.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6922870874404907; training acc = 50.0\n",
      "Epoch 2 : Validation loss = 0.6891435086727142; Validation acc = 54.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6909184455871582; training acc = 50.5\n",
      "Epoch 3 : Validation loss = 0.6878400444984436; Validation acc = 54.0\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.6902387142181396; training acc = 50.5\n",
      "Epoch 4 : Validation loss = 0.6867846846580505; Validation acc = 54.0\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.6873999238014221; training acc = 51.0\n",
      "Epoch 5 : Validation loss = 0.6857728362083435; Validation acc = 54.0\n",
      "Epoch 6:\n",
      "Batch 0 : training loss = 0.6806398034095764; training acc = 53.0\n",
      "Epoch 6 : Validation loss = 0.6847881972789764; Validation acc = 54.0\n",
      "Epoch 7:\n",
      "Batch 0 : training loss = 0.6767394542694092; training acc = 55.5\n",
      "Epoch 7 : Validation loss = 0.6837680041790009; Validation acc = 54.0\n",
      "Epoch 8:\n",
      "Batch 0 : training loss = 0.6760782599449158; training acc = 54.5\n",
      "Epoch 8 : Validation loss = 0.6828541457653046; Validation acc = 54.0\n",
      "Epoch 9:\n",
      "Batch 0 : training loss = 0.6754142642021179; training acc = 55.5\n",
      "Epoch 9 : Validation loss = 0.6819713115692139; Validation acc = 60.0\n",
      "Epoch 10:\n",
      "Batch 0 : training loss = 0.6696205139160156; training acc = 66.0\n",
      "Epoch 10 : Validation loss = 0.6807510852813721; Validation acc = 60.0\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.7027283310890198; training acc = 41.0\n",
      "Epoch 1 : Validation loss = 0.7091103792190552; Validation acc = 58.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6580491662025452; training acc = 66.5\n",
      "Epoch 2 : Validation loss = 0.6937932968139648; Validation acc = 48.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6320671439170837; training acc = 61.0\n",
      "Epoch 3 : Validation loss = 0.6995232105255127; Validation acc = 44.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6936757564544678; training acc = 47.5\n",
      "Epoch 1 : Validation loss = 0.6764005422592163; Validation acc = 54.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6804022789001465; training acc = 52.0\n",
      "Epoch 2 : Validation loss = 0.6809791028499603; Validation acc = 58.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6906774640083313; training acc = 55.0\n",
      "Epoch 1 : Validation loss = 0.6845860481262207; Validation acc = 52.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6833336353302002; training acc = 52.5\n",
      "Epoch 2 : Validation loss = 0.6889892220497131; Validation acc = 62.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.7403488755226135; training acc = 50.5\n",
      "Epoch 1 : Validation loss = 1.5905265808105469; Validation acc = 56.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 1.5168659687042236; training acc = 51.5\n",
      "Epoch 2 : Validation loss = 1.0321866273880005; Validation acc = 44.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.7812139391899109; training acc = 52.0\n",
      "Epoch 3 : Validation loss = 0.9406875371932983; Validation acc = 42.0\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.546698808670044; training acc = 60.0\n",
      "Epoch 4 : Validation loss = 0.7497757077217102; Validation acc = 40.0\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.41200804710388184; training acc = 78.0\n",
      "Epoch 5 : Validation loss = 0.7180507779121399; Validation acc = 50.0\n",
      "Epoch 6:\n",
      "Batch 0 : training loss = 0.38559454679489136; training acc = 81.0\n",
      "Epoch 6 : Validation loss = 0.7288632988929749; Validation acc = 50.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6999222040176392; training acc = 47.5\n",
      "Epoch 1 : Validation loss = 0.7418004870414734; Validation acc = 54.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6932725310325623; training acc = 56.5\n",
      "Epoch 2 : Validation loss = 0.6914970278739929; Validation acc = 52.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6817700862884521; training acc = 64.5\n",
      "Epoch 3 : Validation loss = 0.6926129758358002; Validation acc = 48.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6935447454452515; training acc = 51.0\n",
      "Epoch 1 : Validation loss = 0.7131003141403198; Validation acc = 46.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6481795310974121; training acc = 49.0\n",
      "Epoch 2 : Validation loss = 0.6873025298118591; Validation acc = 52.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6115581393241882; training acc = 68.0\n",
      "Epoch 3 : Validation loss = 0.6852896809577942; Validation acc = 54.0\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.5594314336776733; training acc = 61.5\n",
      "Epoch 4 : Validation loss = 0.6582907736301422; Validation acc = 54.0\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.5046112537384033; training acc = 92.0\n",
      "Epoch 5 : Validation loss = 0.6784921586513519; Validation acc = 50.0\n",
      "Early stopping.\n",
      "RUN COURANT = 1\n",
      "RUN COURANT = 1\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6921787858009338; training acc = 54.0\n",
      "Epoch 1 : Validation loss = 0.6966791599988937; Validation acc = 59.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6823457479476929; training acc = 61.0\n",
      "Epoch 2 : Validation loss = 0.6955595016479492; Validation acc = 61.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6741883754730225; training acc = 67.0\n",
      "Epoch 3 : Validation loss = 0.6891043186187744; Validation acc = 63.0\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.6616706252098083; training acc = 70.0\n",
      "Epoch 4 : Validation loss = 0.6818535625934601; Validation acc = 63.0\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.6474301815032959; training acc = 74.5\n",
      "Epoch 5 : Validation loss = 0.67464180290699; Validation acc = 63.0\n",
      "Epoch 6:\n",
      "Batch 0 : training loss = 0.6363842487335205; training acc = 76.5\n",
      "Epoch 6 : Validation loss = 0.6691635996103287; Validation acc = 65.0\n",
      "Epoch 7:\n",
      "Batch 0 : training loss = 0.6246521472930908; training acc = 79.0\n",
      "Epoch 7 : Validation loss = 0.6635604798793793; Validation acc = 66.0\n",
      "Epoch 8:\n",
      "Batch 0 : training loss = 0.6069074869155884; training acc = 77.5\n",
      "Epoch 8 : Validation loss = 0.6561187952756882; Validation acc = 67.0\n",
      "Epoch 9:\n",
      "Batch 0 : training loss = 0.5885005593299866; training acc = 81.5\n",
      "Epoch 9 : Validation loss = 0.648690938949585; Validation acc = 67.0\n",
      "Epoch 10:\n",
      "Batch 0 : training loss = 0.5676193237304688; training acc = 84.5\n",
      "Epoch 10 : Validation loss = 0.6412062495946884; Validation acc = 68.0\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6904201507568359; training acc = 52.5\n",
      "Epoch 1 : Validation loss = 0.6899695098400116; Validation acc = 51.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6886645555496216; training acc = 55.0\n",
      "Epoch 2 : Validation loss = 0.6849813908338547; Validation acc = 72.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6850066184997559; training acc = 61.5\n",
      "Epoch 3 : Validation loss = 0.6818571537733078; Validation acc = 68.0\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.681628942489624; training acc = 62.5\n",
      "Epoch 4 : Validation loss = 0.679735854268074; Validation acc = 72.0\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.678813099861145; training acc = 62.0\n",
      "Epoch 5 : Validation loss = 0.6777771711349487; Validation acc = 67.0\n",
      "Epoch 6:\n",
      "Batch 0 : training loss = 0.6699517965316772; training acc = 72.5\n",
      "Epoch 6 : Validation loss = 0.6763416230678558; Validation acc = 59.0\n",
      "Epoch 7:\n",
      "Batch 0 : training loss = 0.6656638383865356; training acc = 71.5\n",
      "Epoch 7 : Validation loss = 0.6741117537021637; Validation acc = 59.0\n",
      "Epoch 8:\n",
      "Batch 0 : training loss = 0.6662760376930237; training acc = 69.5\n",
      "Epoch 8 : Validation loss = 0.6714548170566559; Validation acc = 64.0\n",
      "Epoch 9:\n",
      "Batch 0 : training loss = 0.6700347661972046; training acc = 66.5\n",
      "Epoch 9 : Validation loss = 0.6680947691202164; Validation acc = 70.0\n",
      "Epoch 10:\n",
      "Batch 0 : training loss = 0.6611968874931335; training acc = 67.5\n",
      "Epoch 10 : Validation loss = 0.666018009185791; Validation acc = 67.0\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6977455615997314; training acc = 49.0\n",
      "Epoch 1 : Validation loss = 0.6917605698108673; Validation acc = 48.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6872341632843018; training acc = 52.0\n",
      "Epoch 2 : Validation loss = 0.6851691752672195; Validation acc = 61.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6757870316505432; training acc = 77.5\n",
      "Epoch 3 : Validation loss = 0.6798960119485855; Validation acc = 66.0\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.6639390587806702; training acc = 84.0\n",
      "Epoch 4 : Validation loss = 0.6752386689186096; Validation acc = 64.0\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.6460927724838257; training acc = 85.5\n",
      "Epoch 5 : Validation loss = 0.6700171232223511; Validation acc = 65.0\n",
      "Epoch 6:\n",
      "Batch 0 : training loss = 0.6364912986755371; training acc = 86.0\n",
      "Epoch 6 : Validation loss = 0.664167732000351; Validation acc = 65.0\n",
      "Epoch 7:\n",
      "Batch 0 : training loss = 0.6074201464653015; training acc = 90.5\n",
      "Epoch 7 : Validation loss = 0.6585519909858704; Validation acc = 65.0\n",
      "Epoch 8:\n",
      "Batch 0 : training loss = 0.5978589653968811; training acc = 85.0\n",
      "Epoch 8 : Validation loss = 0.6509071886539459; Validation acc = 69.0\n",
      "Epoch 9:\n",
      "Batch 0 : training loss = 0.5767791867256165; training acc = 87.5\n",
      "Epoch 9 : Validation loss = 0.6431785076856613; Validation acc = 68.0\n",
      "Epoch 10:\n",
      "Batch 0 : training loss = 0.5353689193725586; training acc = 89.0\n",
      "Epoch 10 : Validation loss = 0.6349939405918121; Validation acc = 69.0\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6950770616531372; training acc = 45.0\n",
      "Epoch 1 : Validation loss = 0.7063275128602982; Validation acc = 46.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6514120697975159; training acc = 69.0\n",
      "Epoch 2 : Validation loss = 0.705785408616066; Validation acc = 50.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.5881483554840088; training acc = 75.0\n",
      "Epoch 3 : Validation loss = 0.7403691709041595; Validation acc = 53.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6929051280021667; training acc = 52.5\n",
      "Epoch 1 : Validation loss = 0.6776302456855774; Validation acc = 55.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6466546654701233; training acc = 64.5\n",
      "Epoch 2 : Validation loss = 0.6512523591518402; Validation acc = 61.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6084726452827454; training acc = 67.0\n",
      "Epoch 3 : Validation loss = 0.6626777648925781; Validation acc = 64.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6874670386314392; training acc = 57.5\n",
      "Epoch 1 : Validation loss = 0.6914998888969421; Validation acc = 52.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6764341592788696; training acc = 60.5\n",
      "Epoch 2 : Validation loss = 0.6903341710567474; Validation acc = 55.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6421153545379639; training acc = 69.0\n",
      "Epoch 3 : Validation loss = 0.6879088133573532; Validation acc = 55.0\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.5445107221603394; training acc = 77.5\n",
      "Epoch 4 : Validation loss = 0.6870896518230438; Validation acc = 57.0\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.5725266933441162; training acc = 72.0\n",
      "Epoch 5 : Validation loss = 0.6948482841253281; Validation acc = 54.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.8373100161552429; training acc = 45.5\n",
      "Epoch 1 : Validation loss = 1.0296139866113663; Validation acc = 47.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.610879123210907; training acc = 63.0\n",
      "Epoch 2 : Validation loss = 0.9224462509155273; Validation acc = 52.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.3575102984905243; training acc = 77.0\n",
      "Epoch 3 : Validation loss = 0.7580210864543915; Validation acc = 51.0\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.13204538822174072; training acc = 100.0\n",
      "Epoch 4 : Validation loss = 0.7544562816619873; Validation acc = 48.0\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.06647452712059021; training acc = 100.0\n",
      "Epoch 5 : Validation loss = 0.793068528175354; Validation acc = 55.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.7011637091636658; training acc = 50.0\n",
      "Epoch 1 : Validation loss = 0.735672190785408; Validation acc = 53.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.7317286133766174; training acc = 51.0\n",
      "Epoch 2 : Validation loss = 0.6932424604892731; Validation acc = 50.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6624293327331543; training acc = 71.0\n",
      "Epoch 3 : Validation loss = 0.6843347251415253; Validation acc = 65.0\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.6523678302764893; training acc = 72.0\n",
      "Epoch 4 : Validation loss = 0.6676856875419617; Validation acc = 57.0\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.6114414930343628; training acc = 55.5\n",
      "Epoch 5 : Validation loss = 0.6631302684545517; Validation acc = 60.0\n",
      "Epoch 6:\n",
      "Batch 0 : training loss = 0.5893959999084473; training acc = 66.5\n",
      "Epoch 6 : Validation loss = 0.6512164324522018; Validation acc = 58.0\n",
      "Epoch 7:\n",
      "Batch 0 : training loss = 0.5360724329948425; training acc = 66.5\n",
      "Epoch 7 : Validation loss = 0.6525558531284332; Validation acc = 62.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6946102380752563; training acc = 50.5\n",
      "Epoch 1 : Validation loss = 0.6641756147146225; Validation acc = 61.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.5790828466415405; training acc = 81.0\n",
      "Epoch 2 : Validation loss = 0.6294130384922028; Validation acc = 72.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.4868296682834625; training acc = 92.0\n",
      "Epoch 3 : Validation loss = 0.587317556142807; Validation acc = 77.0\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.37600648403167725; training acc = 96.5\n",
      "Epoch 4 : Validation loss = 0.5658356249332428; Validation acc = 75.0\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.2763809263706207; training acc = 99.0\n",
      "Epoch 5 : Validation loss = 0.5292936637997627; Validation acc = 79.0\n",
      "Epoch 6:\n",
      "Batch 0 : training loss = 0.17411935329437256; training acc = 100.0\n",
      "Epoch 6 : Validation loss = 0.5024723932147026; Validation acc = 81.0\n",
      "Epoch 7:\n",
      "Batch 0 : training loss = 0.09095722436904907; training acc = 100.0\n",
      "Epoch 7 : Validation loss = 0.48505280911922455; Validation acc = 81.0\n",
      "Epoch 8:\n",
      "Batch 0 : training loss = 0.04805651679635048; training acc = 100.0\n",
      "Epoch 8 : Validation loss = 0.4754292666912079; Validation acc = 84.0\n",
      "Epoch 9:\n",
      "Batch 0 : training loss = 0.028591139242053032; training acc = 100.0\n",
      "Epoch 9 : Validation loss = 0.4802875444293022; Validation acc = 80.0\n",
      "Early stopping.\n",
      "RUN COURANT = 1\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6957753896713257; training acc = 49.5\n",
      "Epoch 1 : Validation loss = 0.6998730003833771; Validation acc = 51.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.685329258441925; training acc = 62.0\n",
      "Epoch 2 : Validation loss = 0.6933248937129974; Validation acc = 57.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6760842800140381; training acc = 60.5\n",
      "Epoch 3 : Validation loss = 0.6886348575353622; Validation acc = 61.0\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.658954381942749; training acc = 72.0\n",
      "Epoch 4 : Validation loss = 0.6835249811410904; Validation acc = 60.0\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.654094398021698; training acc = 73.0\n",
      "Epoch 5 : Validation loss = 0.6799556463956833; Validation acc = 58.0\n",
      "Epoch 6:\n",
      "Batch 0 : training loss = 0.6461238265037537; training acc = 74.5\n",
      "Epoch 6 : Validation loss = 0.6771958768367767; Validation acc = 60.0\n",
      "Epoch 7:\n",
      "Batch 0 : training loss = 0.6440808176994324; training acc = 75.0\n",
      "Epoch 7 : Validation loss = 0.6727447062730789; Validation acc = 62.0\n",
      "Epoch 8:\n",
      "Batch 0 : training loss = 0.616885781288147; training acc = 80.5\n",
      "Epoch 8 : Validation loss = 0.6699767410755157; Validation acc = 62.0\n",
      "Epoch 9:\n",
      "Batch 0 : training loss = 0.609856367111206; training acc = 83.0\n",
      "Epoch 9 : Validation loss = 0.6635544300079346; Validation acc = 64.0\n",
      "Epoch 10:\n",
      "Batch 0 : training loss = 0.6147393584251404; training acc = 76.0\n",
      "Epoch 10 : Validation loss = 0.6573801785707474; Validation acc = 63.0\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.706472635269165; training acc = 46.5\n",
      "Epoch 1 : Validation loss = 0.6934667974710464; Validation acc = 49.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6918991208076477; training acc = 53.5\n",
      "Epoch 2 : Validation loss = 0.6925994157791138; Validation acc = 49.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6880481243133545; training acc = 56.0\n",
      "Epoch 3 : Validation loss = 0.6898097842931747; Validation acc = 52.0\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.6850547790527344; training acc = 55.0\n",
      "Epoch 4 : Validation loss = 0.6856400221586227; Validation acc = 60.0\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.681225061416626; training acc = 68.5\n",
      "Epoch 5 : Validation loss = 0.6820899993181229; Validation acc = 67.0\n",
      "Epoch 6:\n",
      "Batch 0 : training loss = 0.6788293719291687; training acc = 69.0\n",
      "Epoch 6 : Validation loss = 0.6798419505357742; Validation acc = 66.0\n",
      "Epoch 7:\n",
      "Batch 0 : training loss = 0.6764768362045288; training acc = 64.5\n",
      "Epoch 7 : Validation loss = 0.6770927906036377; Validation acc = 70.0\n",
      "Epoch 8:\n",
      "Batch 0 : training loss = 0.6750044822692871; training acc = 70.0\n",
      "Epoch 8 : Validation loss = 0.6755859106779099; Validation acc = 64.0\n",
      "Epoch 9:\n",
      "Batch 0 : training loss = 0.6682956218719482; training acc = 73.0\n",
      "Epoch 9 : Validation loss = 0.6739189028739929; Validation acc = 62.0\n",
      "Epoch 10:\n",
      "Batch 0 : training loss = 0.6710142493247986; training acc = 63.0\n",
      "Epoch 10 : Validation loss = 0.6719121038913727; Validation acc = 61.0\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6975328326225281; training acc = 44.0\n",
      "Epoch 1 : Validation loss = 0.6876577734947205; Validation acc = 58.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6858456134796143; training acc = 55.5\n",
      "Epoch 2 : Validation loss = 0.6845138520002365; Validation acc = 67.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.67791348695755; training acc = 82.0\n",
      "Epoch 3 : Validation loss = 0.6803494691848755; Validation acc = 65.0\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.6676197052001953; training acc = 75.5\n",
      "Epoch 4 : Validation loss = 0.6754313260316849; Validation acc = 64.0\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.6563018560409546; training acc = 81.0\n",
      "Epoch 5 : Validation loss = 0.6701089590787888; Validation acc = 66.0\n",
      "Epoch 6:\n",
      "Batch 0 : training loss = 0.6366302371025085; training acc = 84.0\n",
      "Epoch 6 : Validation loss = 0.6634353548288345; Validation acc = 69.0\n",
      "Epoch 7:\n",
      "Batch 0 : training loss = 0.6329678893089294; training acc = 79.5\n",
      "Epoch 7 : Validation loss = 0.6564965844154358; Validation acc = 70.0\n",
      "Epoch 8:\n",
      "Batch 0 : training loss = 0.6115981936454773; training acc = 80.5\n",
      "Epoch 8 : Validation loss = 0.6503586173057556; Validation acc = 68.0\n",
      "Epoch 9:\n",
      "Batch 0 : training loss = 0.6021897792816162; training acc = 81.0\n",
      "Epoch 9 : Validation loss = 0.6445638090372086; Validation acc = 66.0\n",
      "Epoch 10:\n",
      "Batch 0 : training loss = 0.5784624814987183; training acc = 84.5\n",
      "Epoch 10 : Validation loss = 0.6352469772100449; Validation acc = 70.0\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6996062994003296; training acc = 43.5\n",
      "Epoch 1 : Validation loss = 0.7000875622034073; Validation acc = 51.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6454833745956421; training acc = 67.0\n",
      "Epoch 2 : Validation loss = 0.7084665596485138; Validation acc = 48.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6919806599617004; training acc = 53.0\n",
      "Epoch 1 : Validation loss = 0.6963906586170197; Validation acc = 52.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6811981201171875; training acc = 50.5\n",
      "Epoch 2 : Validation loss = 0.680936798453331; Validation acc = 55.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6616772413253784; training acc = 61.5\n",
      "Epoch 3 : Validation loss = 0.666955977678299; Validation acc = 59.0\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.5838960409164429; training acc = 72.0\n",
      "Epoch 4 : Validation loss = 0.6961036920547485; Validation acc = 54.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6940348744392395; training acc = 46.5\n",
      "Epoch 1 : Validation loss = 0.7004454731941223; Validation acc = 51.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.686969518661499; training acc = 50.5\n",
      "Epoch 2 : Validation loss = 0.6846534311771393; Validation acc = 53.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6439276337623596; training acc = 66.0\n",
      "Epoch 3 : Validation loss = 0.6918399184942245; Validation acc = 58.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6998206377029419; training acc = 49.5\n",
      "Epoch 1 : Validation loss = 0.6759287267923355; Validation acc = 58.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.3202359080314636; training acc = 99.5\n",
      "Epoch 2 : Validation loss = 0.6741004437208176; Validation acc = 61.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.15379934012889862; training acc = 100.0\n",
      "Epoch 3 : Validation loss = 0.6731239408254623; Validation acc = 59.0\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.06212148815393448; training acc = 100.0\n",
      "Epoch 4 : Validation loss = 0.674648642539978; Validation acc = 59.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.7218883037567139; training acc = 48.0\n",
      "Epoch 1 : Validation loss = 0.6962191462516785; Validation acc = 47.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6921511888504028; training acc = 48.0\n",
      "Epoch 2 : Validation loss = 0.6969207525253296; Validation acc = 47.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.69794100522995; training acc = 51.5\n",
      "Epoch 1 : Validation loss = 0.7331732660531998; Validation acc = 47.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6971511840820312; training acc = 47.0\n",
      "Epoch 2 : Validation loss = 0.6917755156755447; Validation acc = 50.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6543093919754028; training acc = 53.0\n",
      "Epoch 3 : Validation loss = 0.6728024035692215; Validation acc = 57.0\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.5948968529701233; training acc = 82.5\n",
      "Epoch 4 : Validation loss = 0.6601992696523666; Validation acc = 61.0\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.5218878388404846; training acc = 82.5\n",
      "Epoch 5 : Validation loss = 0.6456342190504074; Validation acc = 63.0\n",
      "Epoch 6:\n",
      "Batch 0 : training loss = 0.4074840843677521; training acc = 93.5\n",
      "Epoch 6 : Validation loss = 0.6271412223577499; Validation acc = 69.0\n",
      "Epoch 7:\n",
      "Batch 0 : training loss = 0.3086724579334259; training acc = 97.5\n",
      "Epoch 7 : Validation loss = 0.6200115010142326; Validation acc = 70.0\n",
      "Epoch 8:\n",
      "Batch 0 : training loss = 0.22931984066963196; training acc = 98.5\n",
      "Epoch 8 : Validation loss = 0.6176801100373268; Validation acc = 69.0\n",
      "Epoch 9:\n",
      "Batch 0 : training loss = 0.1356181651353836; training acc = 99.5\n",
      "Epoch 9 : Validation loss = 0.5970721915364265; Validation acc = 73.0\n",
      "Epoch 10:\n",
      "Batch 0 : training loss = 0.08923768252134323; training acc = 100.0\n",
      "Epoch 10 : Validation loss = 0.6281706541776657; Validation acc = 71.0\n",
      "Early stopping.\n",
      "RUN COURANT = 1\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6925097703933716; training acc = 53.5\n",
      "Epoch 1 : Validation loss = 0.6889345347881317; Validation acc = 58.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6884540319442749; training acc = 54.0\n",
      "Epoch 2 : Validation loss = 0.6971911787986755; Validation acc = 57.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6925545334815979; training acc = 55.0\n",
      "Epoch 1 : Validation loss = 0.6913598030805588; Validation acc = 57.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6893365979194641; training acc = 60.5\n",
      "Epoch 2 : Validation loss = 0.6876765340566635; Validation acc = 61.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6855762004852295; training acc = 68.0\n",
      "Epoch 3 : Validation loss = 0.6857333928346634; Validation acc = 62.0\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.6827467083930969; training acc = 67.5\n",
      "Epoch 4 : Validation loss = 0.6824989169836044; Validation acc = 62.0\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.6785137057304382; training acc = 70.0\n",
      "Epoch 5 : Validation loss = 0.6804636269807816; Validation acc = 63.0\n",
      "Epoch 6:\n",
      "Batch 0 : training loss = 0.6788244843482971; training acc = 65.5\n",
      "Epoch 6 : Validation loss = 0.6781354993581772; Validation acc = 64.0\n",
      "Epoch 7:\n",
      "Batch 0 : training loss = 0.6711539626121521; training acc = 67.5\n",
      "Epoch 7 : Validation loss = 0.6753034889698029; Validation acc = 67.0\n",
      "Epoch 8:\n",
      "Batch 0 : training loss = 0.6680597066879272; training acc = 69.5\n",
      "Epoch 8 : Validation loss = 0.6741913408041; Validation acc = 63.0\n",
      "Epoch 9:\n",
      "Batch 0 : training loss = 0.6675793528556824; training acc = 70.0\n",
      "Epoch 9 : Validation loss = 0.6729086637496948; Validation acc = 59.0\n",
      "Epoch 10:\n",
      "Batch 0 : training loss = 0.6681134104728699; training acc = 63.0\n",
      "Epoch 10 : Validation loss = 0.6704582720994949; Validation acc = 62.0\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6860318779945374; training acc = 59.0\n",
      "Epoch 1 : Validation loss = 0.6966959834098816; Validation acc = 47.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6833442449569702; training acc = 54.0\n",
      "Epoch 2 : Validation loss = 0.6865791827440262; Validation acc = 67.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6780040860176086; training acc = 79.5\n",
      "Epoch 3 : Validation loss = 0.6810894459486008; Validation acc = 55.0\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.6701385974884033; training acc = 61.0\n",
      "Epoch 4 : Validation loss = 0.6775602847337723; Validation acc = 58.0\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.6668242812156677; training acc = 67.0\n",
      "Epoch 5 : Validation loss = 0.6750318706035614; Validation acc = 71.0\n",
      "Epoch 6:\n",
      "Batch 0 : training loss = 0.6505683660507202; training acc = 81.0\n",
      "Epoch 6 : Validation loss = 0.6726413369178772; Validation acc = 63.0\n",
      "Epoch 7:\n",
      "Batch 0 : training loss = 0.6548364758491516; training acc = 72.0\n",
      "Epoch 7 : Validation loss = 0.6675830781459808; Validation acc = 64.0\n",
      "Epoch 8:\n",
      "Batch 0 : training loss = 0.6381999850273132; training acc = 76.5\n",
      "Epoch 8 : Validation loss = 0.6609523743391037; Validation acc = 69.0\n",
      "Epoch 9:\n",
      "Batch 0 : training loss = 0.6252272725105286; training acc = 80.5\n",
      "Epoch 9 : Validation loss = 0.6530417203903198; Validation acc = 69.0\n",
      "Epoch 10:\n",
      "Batch 0 : training loss = 0.6062518954277039; training acc = 78.5\n",
      "Epoch 10 : Validation loss = 0.6461661905050278; Validation acc = 70.0\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6984001994132996; training acc = 47.0\n",
      "Epoch 1 : Validation loss = 0.7058139145374298; Validation acc = 44.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6392497420310974; training acc = 72.0\n",
      "Epoch 2 : Validation loss = 0.7091941237449646; Validation acc = 47.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6947087049484253; training acc = 46.5\n",
      "Epoch 1 : Validation loss = 0.6883023977279663; Validation acc = 52.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6801508069038391; training acc = 55.0\n",
      "Epoch 2 : Validation loss = 0.6857741922140121; Validation acc = 52.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.676236093044281; training acc = 59.5\n",
      "Epoch 3 : Validation loss = 0.6868464201688766; Validation acc = 56.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6922259330749512; training acc = 54.0\n",
      "Epoch 1 : Validation loss = 0.7014805674552917; Validation acc = 48.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6590006947517395; training acc = 59.0\n",
      "Epoch 2 : Validation loss = 0.68296779692173; Validation acc = 54.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6699025630950928; training acc = 57.5\n",
      "Epoch 3 : Validation loss = 0.688155323266983; Validation acc = 56.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.7346855998039246; training acc = 49.0\n",
      "Epoch 1 : Validation loss = 0.8294159471988678; Validation acc = 57.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.5308676362037659; training acc = 65.0\n",
      "Epoch 2 : Validation loss = 0.6862687915563583; Validation acc = 49.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.25511834025382996; training acc = 99.0\n",
      "Epoch 3 : Validation loss = 0.7001968622207642; Validation acc = 58.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6956683993339539; training acc = 49.0\n",
      "Epoch 1 : Validation loss = 0.6872742176055908; Validation acc = 48.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6249631643295288; training acc = 61.5\n",
      "Epoch 2 : Validation loss = 0.6311306208372116; Validation acc = 72.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.5295238494873047; training acc = 90.0\n",
      "Epoch 3 : Validation loss = 0.6050272881984711; Validation acc = 73.0\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.44595614075660706; training acc = 95.0\n",
      "Epoch 4 : Validation loss = 0.5833429396152496; Validation acc = 76.0\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.34968897700309753; training acc = 99.5\n",
      "Epoch 5 : Validation loss = 0.5760667324066162; Validation acc = 68.0\n",
      "Epoch 6:\n",
      "Batch 0 : training loss = 0.27824297547340393; training acc = 99.0\n",
      "Epoch 6 : Validation loss = 0.5435676276683807; Validation acc = 77.0\n",
      "Epoch 7:\n",
      "Batch 0 : training loss = 0.18391454219818115; training acc = 100.0\n",
      "Epoch 7 : Validation loss = 0.5523181706666946; Validation acc = 77.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6926764845848083; training acc = 52.5\n",
      "Epoch 1 : Validation loss = 0.6558792144060135; Validation acc = 57.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.5950585007667542; training acc = 69.5\n",
      "Epoch 2 : Validation loss = 0.6449813842773438; Validation acc = 60.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.5196114778518677; training acc = 87.0\n",
      "Epoch 3 : Validation loss = 0.5998594462871552; Validation acc = 75.0\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.42682403326034546; training acc = 94.5\n",
      "Epoch 4 : Validation loss = 0.5739792585372925; Validation acc = 75.0\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.31442588567733765; training acc = 97.0\n",
      "Epoch 5 : Validation loss = 0.5601483434438705; Validation acc = 72.0\n",
      "Epoch 6:\n",
      "Batch 0 : training loss = 0.21805940568447113; training acc = 100.0\n",
      "Epoch 6 : Validation loss = 0.5465105548501015; Validation acc = 73.0\n",
      "Epoch 7:\n",
      "Batch 0 : training loss = 0.16094601154327393; training acc = 100.0\n",
      "Epoch 7 : Validation loss = 0.5430222675204277; Validation acc = 72.0\n",
      "Epoch 8:\n",
      "Batch 0 : training loss = 0.09880062937736511; training acc = 100.0\n",
      "Epoch 8 : Validation loss = 0.5219096913933754; Validation acc = 76.0\n",
      "Epoch 9:\n",
      "Batch 0 : training loss = 0.06088745966553688; training acc = 100.0\n",
      "Epoch 9 : Validation loss = 0.5237301215529442; Validation acc = 71.0\n",
      "Early stopping.\n",
      "RUN COURANT = 1\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6947408318519592; training acc = 48.0\n",
      "Epoch 1 : Validation loss = 0.6975966095924377; Validation acc = 43.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.687705934047699; training acc = 59.0\n",
      "Epoch 2 : Validation loss = 0.6971530914306641; Validation acc = 58.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6834421753883362; training acc = 65.5\n",
      "Epoch 3 : Validation loss = 0.6957151144742966; Validation acc = 56.0\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.6795153021812439; training acc = 66.0\n",
      "Epoch 4 : Validation loss = 0.69278684258461; Validation acc = 57.0\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.6680654883384705; training acc = 68.5\n",
      "Epoch 5 : Validation loss = 0.6889995783567429; Validation acc = 59.0\n",
      "Epoch 6:\n",
      "Batch 0 : training loss = 0.6625239849090576; training acc = 69.5\n",
      "Epoch 6 : Validation loss = 0.6851021200418472; Validation acc = 58.0\n",
      "Epoch 7:\n",
      "Batch 0 : training loss = 0.6617217063903809; training acc = 68.0\n",
      "Epoch 7 : Validation loss = 0.6812239587306976; Validation acc = 55.0\n",
      "Epoch 8:\n",
      "Batch 0 : training loss = 0.6404810547828674; training acc = 75.5\n",
      "Epoch 8 : Validation loss = 0.6768205612897873; Validation acc = 59.0\n",
      "Epoch 9:\n",
      "Batch 0 : training loss = 0.6402274966239929; training acc = 73.0\n",
      "Epoch 9 : Validation loss = 0.6709178388118744; Validation acc = 62.0\n",
      "Epoch 10:\n",
      "Batch 0 : training loss = 0.6374792456626892; training acc = 70.5\n",
      "Epoch 10 : Validation loss = 0.6679719239473343; Validation acc = 59.0\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6925172209739685; training acc = 49.5\n",
      "Epoch 1 : Validation loss = 0.6922912448644638; Validation acc = 52.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6904428005218506; training acc = 56.0\n",
      "Epoch 2 : Validation loss = 0.6934113800525665; Validation acc = 49.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6926054358482361; training acc = 48.5\n",
      "Epoch 1 : Validation loss = 0.6861994713544846; Validation acc = 62.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6845588684082031; training acc = 61.5\n",
      "Epoch 2 : Validation loss = 0.6849480718374252; Validation acc = 58.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6757474541664124; training acc = 68.5\n",
      "Epoch 3 : Validation loss = 0.6825190037488937; Validation acc = 55.0\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.6733382940292358; training acc = 63.5\n",
      "Epoch 4 : Validation loss = 0.6755444407463074; Validation acc = 68.0\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.6651411652565002; training acc = 70.5\n",
      "Epoch 5 : Validation loss = 0.6695936620235443; Validation acc = 66.0\n",
      "Epoch 6:\n",
      "Batch 0 : training loss = 0.6518450975418091; training acc = 74.5\n",
      "Epoch 6 : Validation loss = 0.6650370359420776; Validation acc = 69.0\n",
      "Epoch 7:\n",
      "Batch 0 : training loss = 0.6450679302215576; training acc = 72.5\n",
      "Epoch 7 : Validation loss = 0.6605985313653946; Validation acc = 68.0\n",
      "Epoch 8:\n",
      "Batch 0 : training loss = 0.6349027752876282; training acc = 72.5\n",
      "Epoch 8 : Validation loss = 0.6570050716400146; Validation acc = 65.0\n",
      "Epoch 9:\n",
      "Batch 0 : training loss = 0.6311066746711731; training acc = 69.5\n",
      "Epoch 9 : Validation loss = 0.6501554250717163; Validation acc = 67.0\n",
      "Epoch 10:\n",
      "Batch 0 : training loss = 0.6093616485595703; training acc = 75.5\n",
      "Epoch 10 : Validation loss = 0.6434201747179031; Validation acc = 69.0\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6998835802078247; training acc = 45.0\n",
      "Epoch 1 : Validation loss = 0.7060502171516418; Validation acc = 47.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6500772833824158; training acc = 60.5\n",
      "Epoch 2 : Validation loss = 0.7081688940525055; Validation acc = 51.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6930939555168152; training acc = 49.0\n",
      "Epoch 1 : Validation loss = 0.68336421251297; Validation acc = 52.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6741936206817627; training acc = 59.0\n",
      "Epoch 2 : Validation loss = 0.6846460700035095; Validation acc = 53.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6913396716117859; training acc = 55.5\n",
      "Epoch 1 : Validation loss = 0.6931290924549103; Validation acc = 49.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6719270348548889; training acc = 59.0\n",
      "Epoch 2 : Validation loss = 0.6949348002672195; Validation acc = 52.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.7033620476722717; training acc = 48.0\n",
      "Epoch 1 : Validation loss = 1.2052402347326279; Validation acc = 47.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.915385365486145; training acc = 47.0\n",
      "Epoch 2 : Validation loss = 1.0524134188890457; Validation acc = 52.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.594508171081543; training acc = 59.0\n",
      "Epoch 3 : Validation loss = 0.7786676585674286; Validation acc = 48.0\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.20729589462280273; training acc = 97.0\n",
      "Epoch 4 : Validation loss = 0.7585874944925308; Validation acc = 53.0\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.11205019056797028; training acc = 100.0\n",
      "Epoch 5 : Validation loss = 0.8963071405887604; Validation acc = 52.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.7012561559677124; training acc = 50.5\n",
      "Epoch 1 : Validation loss = 0.7351019233465195; Validation acc = 47.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6933426856994629; training acc = 49.0\n",
      "Epoch 2 : Validation loss = 0.6879701465368271; Validation acc = 51.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6563664078712463; training acc = 52.0\n",
      "Epoch 3 : Validation loss = 0.6849285513162613; Validation acc = 53.0\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.611603319644928; training acc = 61.0\n",
      "Epoch 4 : Validation loss = 0.691482737660408; Validation acc = 51.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6988301277160645; training acc = 52.0\n",
      "Epoch 1 : Validation loss = 0.7615544348955154; Validation acc = 47.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.7168799042701721; training acc = 51.0\n",
      "Epoch 2 : Validation loss = 0.701903909444809; Validation acc = 46.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6694383025169373; training acc = 53.0\n",
      "Epoch 3 : Validation loss = 0.7073950916528702; Validation acc = 46.0\n",
      "Early stopping.\n",
      "RUN COURANT = 1\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6958062052726746; training acc = 50.5\n",
      "Epoch 1 : Validation loss = 0.6896028071641922; Validation acc = 56.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6904844045639038; training acc = 54.0\n",
      "Epoch 2 : Validation loss = 0.6928715258836746; Validation acc = 53.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6929141283035278; training acc = 54.0\n",
      "Epoch 1 : Validation loss = 0.6946711242198944; Validation acc = 47.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6941536068916321; training acc = 49.0\n",
      "Epoch 2 : Validation loss = 0.690705344080925; Validation acc = 55.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6913142204284668; training acc = 56.5\n",
      "Epoch 3 : Validation loss = 0.6882605403661728; Validation acc = 57.0\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.690106987953186; training acc = 51.0\n",
      "Epoch 4 : Validation loss = 0.6874358206987381; Validation acc = 57.0\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.6854707598686218; training acc = 64.0\n",
      "Epoch 5 : Validation loss = 0.6876664906740189; Validation acc = 58.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.686025083065033; training acc = 58.0\n",
      "Epoch 1 : Validation loss = 0.6884752810001373; Validation acc = 53.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6887921094894409; training acc = 51.5\n",
      "Epoch 2 : Validation loss = 0.6909992694854736; Validation acc = 52.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.7038044929504395; training acc = 43.0\n",
      "Epoch 1 : Validation loss = 0.7068844735622406; Validation acc = 47.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6601349115371704; training acc = 62.5\n",
      "Epoch 2 : Validation loss = 0.7218816131353378; Validation acc = 48.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6920623779296875; training acc = 52.0\n",
      "Epoch 1 : Validation loss = 0.715749517083168; Validation acc = 47.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.7226046919822693; training acc = 47.0\n",
      "Epoch 2 : Validation loss = 0.6912070661783218; Validation acc = 53.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.666471540927887; training acc = 59.5\n",
      "Epoch 3 : Validation loss = 0.6956156194210052; Validation acc = 53.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6921038031578064; training acc = 53.0\n",
      "Epoch 1 : Validation loss = 0.692374587059021; Validation acc = 53.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6687535643577576; training acc = 59.5\n",
      "Epoch 2 : Validation loss = 0.6929133981466293; Validation acc = 54.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.7111396789550781; training acc = 46.0\n",
      "Epoch 1 : Validation loss = 0.8160713016986847; Validation acc = 49.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.5322055816650391; training acc = 84.5\n",
      "Epoch 2 : Validation loss = 0.7248540967702866; Validation acc = 55.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.3584597706794739; training acc = 94.0\n",
      "Epoch 3 : Validation loss = 0.8081130534410477; Validation acc = 53.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6912787556648254; training acc = 52.0\n",
      "Epoch 1 : Validation loss = 0.7589003592729568; Validation acc = 53.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.7461201548576355; training acc = 48.0\n",
      "Epoch 2 : Validation loss = 0.7225148528814316; Validation acc = 47.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6001266241073608; training acc = 57.0\n",
      "Epoch 3 : Validation loss = 0.6524230241775513; Validation acc = 57.0\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.5032047033309937; training acc = 75.0\n",
      "Epoch 4 : Validation loss = 0.6840682327747345; Validation acc = 55.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.69513338804245; training acc = 50.0\n",
      "Epoch 1 : Validation loss = 0.6758147031068802; Validation acc = 57.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6113905906677246; training acc = 78.0\n",
      "Epoch 2 : Validation loss = 0.6580173969268799; Validation acc = 63.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.5727567076683044; training acc = 89.0\n",
      "Epoch 3 : Validation loss = 0.6338828951120377; Validation acc = 68.0\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.5014195442199707; training acc = 89.5\n",
      "Epoch 4 : Validation loss = 0.6233424693346024; Validation acc = 68.0\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.425977885723114; training acc = 94.0\n",
      "Epoch 5 : Validation loss = 0.6040809005498886; Validation acc = 73.0\n",
      "Epoch 6:\n",
      "Batch 0 : training loss = 0.33419108390808105; training acc = 98.0\n",
      "Epoch 6 : Validation loss = 0.5972432047128677; Validation acc = 72.0\n",
      "Epoch 7:\n",
      "Batch 0 : training loss = 0.3006094992160797; training acc = 97.5\n",
      "Epoch 7 : Validation loss = 0.5751781165599823; Validation acc = 70.0\n",
      "Epoch 8:\n",
      "Batch 0 : training loss = 0.22001895308494568; training acc = 99.0\n",
      "Epoch 8 : Validation loss = 0.5860168188810349; Validation acc = 70.0\n",
      "Early stopping.\n",
      "RUN COURANT = 1\n",
      "RUN COURANT = 1\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6899837255477905; training acc = 56.0\n",
      "Epoch 1 : Validation loss = 0.686622828245163; Validation acc = 57.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6809037923812866; training acc = 63.5\n",
      "Epoch 2 : Validation loss = 0.6813108548521996; Validation acc = 57.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6592662334442139; training acc = 67.5\n",
      "Epoch 3 : Validation loss = 0.6756501421332359; Validation acc = 60.0\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.6441073417663574; training acc = 73.5\n",
      "Epoch 4 : Validation loss = 0.6674796044826508; Validation acc = 62.0\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.6204771995544434; training acc = 75.5\n",
      "Epoch 5 : Validation loss = 0.651056632399559; Validation acc = 63.5\n",
      "Epoch 6:\n",
      "Batch 0 : training loss = 0.5759111642837524; training acc = 80.5\n",
      "Epoch 6 : Validation loss = 0.6381785348057747; Validation acc = 66.0\n",
      "Epoch 7:\n",
      "Batch 0 : training loss = 0.5727140307426453; training acc = 78.5\n",
      "Epoch 7 : Validation loss = 0.6258470043540001; Validation acc = 66.5\n",
      "Epoch 8:\n",
      "Batch 0 : training loss = 0.5218797922134399; training acc = 81.0\n",
      "Epoch 8 : Validation loss = 0.6070542633533478; Validation acc = 68.5\n",
      "Epoch 9:\n",
      "Batch 0 : training loss = 0.48315051198005676; training acc = 84.0\n",
      "Epoch 9 : Validation loss = 0.5928604304790497; Validation acc = 72.5\n",
      "Epoch 10:\n",
      "Batch 0 : training loss = 0.43982434272766113; training acc = 90.5\n",
      "Epoch 10 : Validation loss = 0.5729115381836891; Validation acc = 73.5\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6942103505134583; training acc = 51.0\n",
      "Epoch 1 : Validation loss = 0.6931833028793335; Validation acc = 45.5\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6901950240135193; training acc = 52.5\n",
      "Epoch 2 : Validation loss = 0.6867878884077072; Validation acc = 57.5\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6809499263763428; training acc = 66.0\n",
      "Epoch 3 : Validation loss = 0.6812649369239807; Validation acc = 63.0\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.6810534000396729; training acc = 62.5\n",
      "Epoch 4 : Validation loss = 0.6755525097250938; Validation acc = 65.5\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.6712433695793152; training acc = 67.0\n",
      "Epoch 5 : Validation loss = 0.6736686676740646; Validation acc = 62.5\n",
      "Epoch 6:\n",
      "Batch 0 : training loss = 0.6693198680877686; training acc = 63.5\n",
      "Epoch 6 : Validation loss = 0.6671798080205917; Validation acc = 66.0\n",
      "Epoch 7:\n",
      "Batch 0 : training loss = 0.6663621664047241; training acc = 64.5\n",
      "Epoch 7 : Validation loss = 0.6631670743227005; Validation acc = 66.0\n",
      "Epoch 8:\n",
      "Batch 0 : training loss = 0.6484168767929077; training acc = 74.0\n",
      "Epoch 8 : Validation loss = 0.6608254015445709; Validation acc = 63.5\n",
      "Epoch 9:\n",
      "Batch 0 : training loss = 0.6528271436691284; training acc = 68.5\n",
      "Epoch 9 : Validation loss = 0.661372222006321; Validation acc = 62.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.694614052772522; training acc = 49.0\n",
      "Epoch 1 : Validation loss = 0.6835387647151947; Validation acc = 65.5\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6767071485519409; training acc = 72.5\n",
      "Epoch 2 : Validation loss = 0.6768555268645287; Validation acc = 63.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6640796065330505; training acc = 74.0\n",
      "Epoch 3 : Validation loss = 0.6619503200054169; Validation acc = 71.5\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.6414721012115479; training acc = 77.0\n",
      "Epoch 4 : Validation loss = 0.6502743810415268; Validation acc = 70.0\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.6125626564025879; training acc = 82.5\n",
      "Epoch 5 : Validation loss = 0.6341190487146378; Validation acc = 71.5\n",
      "Epoch 6:\n",
      "Batch 0 : training loss = 0.5700716972351074; training acc = 84.0\n",
      "Epoch 6 : Validation loss = 0.6164206713438034; Validation acc = 73.0\n",
      "Epoch 7:\n",
      "Batch 0 : training loss = 0.5420724749565125; training acc = 86.5\n",
      "Epoch 7 : Validation loss = 0.5968184545636177; Validation acc = 73.0\n",
      "Epoch 8:\n",
      "Batch 0 : training loss = 0.4756004214286804; training acc = 89.0\n",
      "Epoch 8 : Validation loss = 0.5720736235380173; Validation acc = 74.5\n",
      "Epoch 9:\n",
      "Batch 0 : training loss = 0.4051448702812195; training acc = 95.0\n",
      "Epoch 9 : Validation loss = 0.550491351634264; Validation acc = 74.5\n",
      "Epoch 10:\n",
      "Batch 0 : training loss = 0.3691640794277191; training acc = 93.0\n",
      "Epoch 10 : Validation loss = 0.5304008573293686; Validation acc = 76.5\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6954533457756042; training acc = 50.0\n",
      "Epoch 1 : Validation loss = 0.7009148076176643; Validation acc = 53.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6426084637641907; training acc = 72.0\n",
      "Epoch 2 : Validation loss = 0.6862797811627388; Validation acc = 58.5\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.5267001390457153; training acc = 80.5\n",
      "Epoch 3 : Validation loss = 0.7109656855463982; Validation acc = 54.5\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6912561058998108; training acc = 55.0\n",
      "Epoch 1 : Validation loss = 0.6820816323161125; Validation acc = 58.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6747716665267944; training acc = 58.5\n",
      "Epoch 2 : Validation loss = 0.9768910929560661; Validation acc = 56.5\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6927011013031006; training acc = 48.0\n",
      "Epoch 1 : Validation loss = 0.6835292056202888; Validation acc = 58.5\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6732665300369263; training acc = 63.5\n",
      "Epoch 2 : Validation loss = 0.6808489561080933; Validation acc = 58.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6152538061141968; training acc = 69.0\n",
      "Epoch 3 : Validation loss = 0.6600857824087143; Validation acc = 60.5\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.5876976251602173; training acc = 73.5\n",
      "Epoch 4 : Validation loss = 0.6839458495378494; Validation acc = 56.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.704510509967804; training acc = 51.0\n",
      "Epoch 1 : Validation loss = 0.7879231795668602; Validation acc = 49.5\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.4080239534378052; training acc = 78.5\n",
      "Epoch 2 : Validation loss = 0.7148943245410919; Validation acc = 57.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.1443999856710434; training acc = 99.5\n",
      "Epoch 3 : Validation loss = 0.6497855708003044; Validation acc = 59.5\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.056021083146333694; training acc = 100.0\n",
      "Epoch 4 : Validation loss = 0.6665986925363541; Validation acc = 60.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6924563050270081; training acc = 51.5\n",
      "Epoch 1 : Validation loss = 0.6561589986085892; Validation acc = 59.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.5776599645614624; training acc = 77.0\n",
      "Epoch 2 : Validation loss = 0.6004863083362579; Validation acc = 71.5\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.46827980875968933; training acc = 83.5\n",
      "Epoch 3 : Validation loss = 0.5588636733591557; Validation acc = 73.0\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.3524858355522156; training acc = 92.0\n",
      "Epoch 4 : Validation loss = 0.5326299704611301; Validation acc = 75.0\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.26114925742149353; training acc = 96.0\n",
      "Epoch 5 : Validation loss = 0.5167908370494843; Validation acc = 76.0\n",
      "Epoch 6:\n",
      "Batch 0 : training loss = 0.14956533908843994; training acc = 99.5\n",
      "Epoch 6 : Validation loss = 0.5160569436848164; Validation acc = 75.5\n",
      "Epoch 7:\n",
      "Batch 0 : training loss = 0.08502350747585297; training acc = 100.0\n",
      "Epoch 7 : Validation loss = 0.5209300443530083; Validation acc = 76.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6937617659568787; training acc = 50.5\n",
      "Epoch 1 : Validation loss = 0.6499492824077606; Validation acc = 57.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6119037866592407; training acc = 61.0\n",
      "Epoch 2 : Validation loss = 0.605976901948452; Validation acc = 68.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.5015648007392883; training acc = 81.0\n",
      "Epoch 3 : Validation loss = 0.563718743622303; Validation acc = 77.0\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.33973178267478943; training acc = 93.0\n",
      "Epoch 4 : Validation loss = 0.5377260893583298; Validation acc = 76.5\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.2264610230922699; training acc = 94.5\n",
      "Epoch 5 : Validation loss = 0.522343747317791; Validation acc = 77.0\n",
      "Epoch 6:\n",
      "Batch 0 : training loss = 0.11037701368331909; training acc = 99.0\n",
      "Epoch 6 : Validation loss = 0.47584864497184753; Validation acc = 82.0\n",
      "Epoch 7:\n",
      "Batch 0 : training loss = 0.04175581410527229; training acc = 100.0\n",
      "Epoch 7 : Validation loss = 0.47968441620469093; Validation acc = 81.0\n",
      "Early stopping.\n",
      "RUN COURANT = 1\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6976960897445679; training acc = 45.0\n",
      "Epoch 1 : Validation loss = 0.6837095841765404; Validation acc = 58.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.675341784954071; training acc = 61.5\n",
      "Epoch 2 : Validation loss = 0.6842513829469681; Validation acc = 59.5\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.692840576171875; training acc = 49.0\n",
      "Epoch 1 : Validation loss = 0.6901321113109589; Validation acc = 55.5\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6857556700706482; training acc = 63.5\n",
      "Epoch 2 : Validation loss = 0.6809253394603729; Validation acc = 61.5\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6764394640922546; training acc = 64.0\n",
      "Epoch 3 : Validation loss = 0.68061563372612; Validation acc = 60.0\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.6772953867912292; training acc = 61.0\n",
      "Epoch 4 : Validation loss = 0.6817203015089035; Validation acc = 58.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6953427791595459; training acc = 44.0\n",
      "Epoch 1 : Validation loss = 0.6851270347833633; Validation acc = 64.5\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6829164028167725; training acc = 71.0\n",
      "Epoch 2 : Validation loss = 0.675790086388588; Validation acc = 66.5\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6708766222000122; training acc = 69.5\n",
      "Epoch 3 : Validation loss = 0.6722435802221298; Validation acc = 64.5\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.6462655067443848; training acc = 75.0\n",
      "Epoch 4 : Validation loss = 0.6545481011271477; Validation acc = 71.0\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.6273905634880066; training acc = 76.5\n",
      "Epoch 5 : Validation loss = 0.6390670984983444; Validation acc = 71.0\n",
      "Epoch 6:\n",
      "Batch 0 : training loss = 0.580234169960022; training acc = 80.5\n",
      "Epoch 6 : Validation loss = 0.6204956769943237; Validation acc = 74.0\n",
      "Epoch 7:\n",
      "Batch 0 : training loss = 0.5541620850563049; training acc = 82.0\n",
      "Epoch 7 : Validation loss = 0.6035706028342247; Validation acc = 75.0\n",
      "Epoch 8:\n",
      "Batch 0 : training loss = 0.4946986734867096; training acc = 88.5\n",
      "Epoch 8 : Validation loss = 0.5749889239668846; Validation acc = 75.0\n",
      "Epoch 9:\n",
      "Batch 0 : training loss = 0.439400315284729; training acc = 92.5\n",
      "Epoch 9 : Validation loss = 0.5576756000518799; Validation acc = 75.0\n",
      "Epoch 10:\n",
      "Batch 0 : training loss = 0.4322325587272644; training acc = 88.5\n",
      "Epoch 10 : Validation loss = 0.5308306738734245; Validation acc = 77.5\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.7000471353530884; training acc = 47.5\n",
      "Epoch 1 : Validation loss = 0.6953279599547386; Validation acc = 52.5\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6400348544120789; training acc = 68.5\n",
      "Epoch 2 : Validation loss = 0.7056486755609512; Validation acc = 55.5\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6919664144515991; training acc = 53.0\n",
      "Epoch 1 : Validation loss = 0.686480738222599; Validation acc = 55.5\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6776106357574463; training acc = 62.5\n",
      "Epoch 2 : Validation loss = 0.6820960193872452; Validation acc = 58.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.655657172203064; training acc = 62.5\n",
      "Epoch 3 : Validation loss = 0.6781098991632462; Validation acc = 56.0\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.675780713558197; training acc = 51.5\n",
      "Epoch 4 : Validation loss = 0.6952090486884117; Validation acc = 53.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6997091770172119; training acc = 47.0\n",
      "Epoch 1 : Validation loss = 0.6832050234079361; Validation acc = 58.5\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6763421893119812; training acc = 60.0\n",
      "Epoch 2 : Validation loss = 0.6829726845026016; Validation acc = 53.5\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6425788998603821; training acc = 66.0\n",
      "Epoch 3 : Validation loss = 0.6722013801336288; Validation acc = 59.5\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.656149685382843; training acc = 58.5\n",
      "Epoch 4 : Validation loss = 0.660218708217144; Validation acc = 63.0\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.5130406022071838; training acc = 72.5\n",
      "Epoch 5 : Validation loss = 0.6909747757017612; Validation acc = 56.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.969496488571167; training acc = 49.0\n",
      "Epoch 1 : Validation loss = 0.7376938983798027; Validation acc = 57.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.416351318359375; training acc = 81.0\n",
      "Epoch 2 : Validation loss = 0.6969687417149544; Validation acc = 57.5\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.19543540477752686; training acc = 99.0\n",
      "Epoch 3 : Validation loss = 0.6616509854793549; Validation acc = 60.0\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.09355200827121735; training acc = 100.0\n",
      "Epoch 4 : Validation loss = 0.6508700549602509; Validation acc = 67.0\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.040113143622875214; training acc = 100.0\n",
      "Epoch 5 : Validation loss = 0.6555681526660919; Validation acc = 67.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.7059255242347717; training acc = 46.5\n",
      "Epoch 1 : Validation loss = 0.6913019940257072; Validation acc = 57.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6858537793159485; training acc = 61.5\n",
      "Epoch 2 : Validation loss = 0.6903438419103622; Validation acc = 47.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.677934467792511; training acc = 60.5\n",
      "Epoch 3 : Validation loss = 0.6856351867318153; Validation acc = 56.5\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.6648668050765991; training acc = 68.5\n",
      "Epoch 4 : Validation loss = 0.6810402646660805; Validation acc = 49.5\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.6330119371414185; training acc = 62.5\n",
      "Epoch 5 : Validation loss = 0.6590967699885368; Validation acc = 61.0\n",
      "Epoch 6:\n",
      "Batch 0 : training loss = 0.584881067276001; training acc = 80.0\n",
      "Epoch 6 : Validation loss = 0.6391321793198586; Validation acc = 62.5\n",
      "Epoch 7:\n",
      "Batch 0 : training loss = 0.5013381838798523; training acc = 86.0\n",
      "Epoch 7 : Validation loss = 0.6145576238632202; Validation acc = 66.5\n",
      "Epoch 8:\n",
      "Batch 0 : training loss = 0.4257267117500305; training acc = 87.5\n",
      "Epoch 8 : Validation loss = 0.5935194939374924; Validation acc = 69.5\n",
      "Epoch 9:\n",
      "Batch 0 : training loss = 0.33416229486465454; training acc = 93.0\n",
      "Epoch 9 : Validation loss = 0.5502712354063988; Validation acc = 75.0\n",
      "Epoch 10:\n",
      "Batch 0 : training loss = 0.24078860878944397; training acc = 97.5\n",
      "Epoch 10 : Validation loss = 0.5536599978804588; Validation acc = 73.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.7197249531745911; training acc = 45.5\n",
      "Epoch 1 : Validation loss = 0.6945096552371979; Validation acc = 45.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6897091865539551; training acc = 55.5\n",
      "Epoch 2 : Validation loss = 0.6955989524722099; Validation acc = 45.0\n",
      "Early stopping.\n",
      "RUN COURANT = 1\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.697115421295166; training acc = 51.5\n",
      "Epoch 1 : Validation loss = 0.6838994920253754; Validation acc = 59.5\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6756359338760376; training acc = 61.5\n",
      "Epoch 2 : Validation loss = 0.6789373755455017; Validation acc = 64.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6681121587753296; training acc = 69.5\n",
      "Epoch 3 : Validation loss = 0.6748646050691605; Validation acc = 61.5\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.651297926902771; training acc = 69.5\n",
      "Epoch 4 : Validation loss = 0.6609405800700188; Validation acc = 63.5\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.6460129022598267; training acc = 70.0\n",
      "Epoch 5 : Validation loss = 0.6540660560131073; Validation acc = 65.5\n",
      "Epoch 6:\n",
      "Batch 0 : training loss = 0.6218466758728027; training acc = 75.0\n",
      "Epoch 6 : Validation loss = 0.6396175026893616; Validation acc = 70.5\n",
      "Epoch 7:\n",
      "Batch 0 : training loss = 0.6112587451934814; training acc = 76.0\n",
      "Epoch 7 : Validation loss = 0.6287546679377556; Validation acc = 70.5\n",
      "Epoch 8:\n",
      "Batch 0 : training loss = 0.5733243823051453; training acc = 80.0\n",
      "Epoch 8 : Validation loss = 0.6119869723916054; Validation acc = 73.0\n",
      "Epoch 9:\n",
      "Batch 0 : training loss = 0.5417974591255188; training acc = 84.5\n",
      "Epoch 9 : Validation loss = 0.5973352789878845; Validation acc = 74.5\n",
      "Epoch 10:\n",
      "Batch 0 : training loss = 0.5137214660644531; training acc = 85.5\n",
      "Epoch 10 : Validation loss = 0.5789599418640137; Validation acc = 76.0\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6939402222633362; training acc = 49.0\n",
      "Epoch 1 : Validation loss = 0.6879211813211441; Validation acc = 64.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.689260721206665; training acc = 59.5\n",
      "Epoch 2 : Validation loss = 0.687860406935215; Validation acc = 55.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6847406029701233; training acc = 57.5\n",
      "Epoch 3 : Validation loss = 0.6804918497800827; Validation acc = 65.5\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.6747697591781616; training acc = 71.0\n",
      "Epoch 4 : Validation loss = 0.6769405379891396; Validation acc = 65.5\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.6770867705345154; training acc = 66.0\n",
      "Epoch 5 : Validation loss = 0.6763759255409241; Validation acc = 61.5\n",
      "Epoch 6:\n",
      "Batch 0 : training loss = 0.6646739840507507; training acc = 64.0\n",
      "Epoch 6 : Validation loss = 0.6701792329549789; Validation acc = 65.5\n",
      "Epoch 7:\n",
      "Batch 0 : training loss = 0.6684790253639221; training acc = 62.5\n",
      "Epoch 7 : Validation loss = 0.6652617156505585; Validation acc = 67.0\n",
      "Epoch 8:\n",
      "Batch 0 : training loss = 0.6578868627548218; training acc = 68.5\n",
      "Epoch 8 : Validation loss = 0.6648142263293266; Validation acc = 64.0\n",
      "Epoch 9:\n",
      "Batch 0 : training loss = 0.6713293194770813; training acc = 61.5\n",
      "Epoch 9 : Validation loss = 0.6642093509435654; Validation acc = 64.0\n",
      "Epoch 10:\n",
      "Batch 0 : training loss = 0.6673111915588379; training acc = 62.0\n",
      "Epoch 10 : Validation loss = 0.6558443009853363; Validation acc = 71.0\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6915501952171326; training acc = 59.0\n",
      "Epoch 1 : Validation loss = 0.6854066029191017; Validation acc = 61.5\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6776493787765503; training acc = 69.5\n",
      "Epoch 2 : Validation loss = 0.6753892749547958; Validation acc = 67.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6617597937583923; training acc = 77.0\n",
      "Epoch 3 : Validation loss = 0.6638148054480553; Validation acc = 69.0\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.6495063304901123; training acc = 72.5\n",
      "Epoch 4 : Validation loss = 0.6540042012929916; Validation acc = 68.0\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.6192273497581482; training acc = 81.0\n",
      "Epoch 5 : Validation loss = 0.6374666765332222; Validation acc = 71.0\n",
      "Epoch 6:\n",
      "Batch 0 : training loss = 0.6013246774673462; training acc = 78.0\n",
      "Epoch 6 : Validation loss = 0.6235201880335808; Validation acc = 69.5\n",
      "Epoch 7:\n",
      "Batch 0 : training loss = 0.5696275234222412; training acc = 81.0\n",
      "Epoch 7 : Validation loss = 0.5971492007374763; Validation acc = 74.0\n",
      "Epoch 8:\n",
      "Batch 0 : training loss = 0.5291776061058044; training acc = 82.0\n",
      "Epoch 8 : Validation loss = 0.5799767002463341; Validation acc = 76.5\n",
      "Epoch 9:\n",
      "Batch 0 : training loss = 0.4761751890182495; training acc = 87.0\n",
      "Epoch 9 : Validation loss = 0.5566944181919098; Validation acc = 77.0\n",
      "Epoch 10:\n",
      "Batch 0 : training loss = 0.45456305146217346; training acc = 88.0\n",
      "Epoch 10 : Validation loss = 0.534577239304781; Validation acc = 75.5\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6934501528739929; training acc = 50.5\n",
      "Epoch 1 : Validation loss = 0.6940451115369797; Validation acc = 52.5\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6443119049072266; training acc = 69.0\n",
      "Epoch 2 : Validation loss = 0.6826724410057068; Validation acc = 53.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.5766711235046387; training acc = 75.0\n",
      "Epoch 3 : Validation loss = 0.7086393684148788; Validation acc = 54.5\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.699332594871521; training acc = 45.5\n",
      "Epoch 1 : Validation loss = 0.6973493695259094; Validation acc = 46.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6704041361808777; training acc = 57.0\n",
      "Epoch 2 : Validation loss = 0.6642445623874664; Validation acc = 63.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.653320848941803; training acc = 59.0\n",
      "Epoch 3 : Validation loss = 0.6941764578223228; Validation acc = 51.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6929418444633484; training acc = 54.0\n",
      "Epoch 1 : Validation loss = 0.6915666610002518; Validation acc = 49.5\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6640205383300781; training acc = 62.0\n",
      "Epoch 2 : Validation loss = 0.6777432933449745; Validation acc = 56.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6460056304931641; training acc = 58.5\n",
      "Epoch 3 : Validation loss = 0.684879869222641; Validation acc = 55.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.7365393042564392; training acc = 49.0\n",
      "Epoch 1 : Validation loss = 0.7802593111991882; Validation acc = 49.5\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.45282432436943054; training acc = 77.0\n",
      "Epoch 2 : Validation loss = 0.7968001589179039; Validation acc = 51.5\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6931778788566589; training acc = 52.0\n",
      "Epoch 1 : Validation loss = 0.6364885494112968; Validation acc = 65.5\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.5881845951080322; training acc = 72.0\n",
      "Epoch 2 : Validation loss = 0.5935347601771355; Validation acc = 73.5\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.4612213969230652; training acc = 90.5\n",
      "Epoch 3 : Validation loss = 0.5554437004029751; Validation acc = 75.0\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.33183687925338745; training acc = 93.0\n",
      "Epoch 4 : Validation loss = 0.5547971948981285; Validation acc = 70.5\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.2746835947036743; training acc = 95.5\n",
      "Epoch 5 : Validation loss = 0.5443060733377934; Validation acc = 73.0\n",
      "Epoch 6:\n",
      "Batch 0 : training loss = 0.14703993499279022; training acc = 100.0\n",
      "Epoch 6 : Validation loss = 0.5290812663733959; Validation acc = 75.5\n",
      "Epoch 7:\n",
      "Batch 0 : training loss = 0.0906931459903717; training acc = 100.0\n",
      "Epoch 7 : Validation loss = 0.5406909435987473; Validation acc = 75.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6948143243789673; training acc = 49.5\n",
      "Epoch 1 : Validation loss = 0.6989076435565948; Validation acc = 44.5\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6830624938011169; training acc = 53.5\n",
      "Epoch 2 : Validation loss = 0.7020903080701828; Validation acc = 45.0\n",
      "Early stopping.\n",
      "RUN COURANT = 1\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6962515115737915; training acc = 48.5\n",
      "Epoch 1 : Validation loss = 0.6881773620843887; Validation acc = 59.5\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6877605319023132; training acc = 62.5\n",
      "Epoch 2 : Validation loss = 0.68602604418993; Validation acc = 56.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6729485988616943; training acc = 65.5\n",
      "Epoch 3 : Validation loss = 0.6760140508413315; Validation acc = 64.0\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.6645420789718628; training acc = 66.5\n",
      "Epoch 4 : Validation loss = 0.6669878885149956; Validation acc = 64.5\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.6447945237159729; training acc = 71.5\n",
      "Epoch 5 : Validation loss = 0.6580532714724541; Validation acc = 66.0\n",
      "Epoch 6:\n",
      "Batch 0 : training loss = 0.6294533014297485; training acc = 72.5\n",
      "Epoch 6 : Validation loss = 0.6483415961265564; Validation acc = 67.0\n",
      "Epoch 7:\n",
      "Batch 0 : training loss = 0.6214160323143005; training acc = 74.0\n",
      "Epoch 7 : Validation loss = 0.6369002759456635; Validation acc = 68.5\n",
      "Epoch 8:\n",
      "Batch 0 : training loss = 0.5785425305366516; training acc = 81.0\n",
      "Epoch 8 : Validation loss = 0.622778408229351; Validation acc = 70.0\n",
      "Epoch 9:\n",
      "Batch 0 : training loss = 0.5658830404281616; training acc = 77.5\n",
      "Epoch 9 : Validation loss = 0.60533407330513; Validation acc = 70.5\n",
      "Epoch 10:\n",
      "Batch 0 : training loss = 0.5362406373023987; training acc = 82.0\n",
      "Epoch 10 : Validation loss = 0.5912216901779175; Validation acc = 71.5\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.7028924822807312; training acc = 45.5\n",
      "Epoch 1 : Validation loss = 0.6903090253472328; Validation acc = 54.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.689812421798706; training acc = 58.0\n",
      "Epoch 2 : Validation loss = 0.6887452751398087; Validation acc = 54.5\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6860331892967224; training acc = 57.5\n",
      "Epoch 3 : Validation loss = 0.6844522207975388; Validation acc = 61.0\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.6819934844970703; training acc = 64.0\n",
      "Epoch 4 : Validation loss = 0.6781711205840111; Validation acc = 65.5\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.680524468421936; training acc = 65.5\n",
      "Epoch 5 : Validation loss = 0.6741016134619713; Validation acc = 63.0\n",
      "Epoch 6:\n",
      "Batch 0 : training loss = 0.6713793277740479; training acc = 68.0\n",
      "Epoch 6 : Validation loss = 0.6747239828109741; Validation acc = 62.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6928108334541321; training acc = 49.5\n",
      "Epoch 1 : Validation loss = 0.6876181066036224; Validation acc = 58.5\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6827993988990784; training acc = 64.5\n",
      "Epoch 2 : Validation loss = 0.6766119301319122; Validation acc = 69.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6722211241722107; training acc = 67.0\n",
      "Epoch 3 : Validation loss = 0.6710779219865799; Validation acc = 63.0\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.6494510173797607; training acc = 71.0\n",
      "Epoch 4 : Validation loss = 0.6558852419257164; Validation acc = 69.0\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.6304819583892822; training acc = 72.5\n",
      "Epoch 5 : Validation loss = 0.6431428417563438; Validation acc = 70.5\n",
      "Epoch 6:\n",
      "Batch 0 : training loss = 0.5945342779159546; training acc = 77.5\n",
      "Epoch 6 : Validation loss = 0.6267010867595673; Validation acc = 72.0\n",
      "Epoch 7:\n",
      "Batch 0 : training loss = 0.5789385437965393; training acc = 78.0\n",
      "Epoch 7 : Validation loss = 0.6059878915548325; Validation acc = 74.0\n",
      "Epoch 8:\n",
      "Batch 0 : training loss = 0.5563311576843262; training acc = 79.0\n",
      "Epoch 8 : Validation loss = 0.5871719047427177; Validation acc = 75.0\n",
      "Epoch 9:\n",
      "Batch 0 : training loss = 0.4948415458202362; training acc = 85.0\n",
      "Epoch 9 : Validation loss = 0.567066565155983; Validation acc = 75.5\n",
      "Epoch 10:\n",
      "Batch 0 : training loss = 0.45525118708610535; training acc = 86.0\n",
      "Epoch 10 : Validation loss = 0.5438857302069664; Validation acc = 74.5\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6968718767166138; training acc = 49.0\n",
      "Epoch 1 : Validation loss = 0.7054242864251137; Validation acc = 45.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6629040241241455; training acc = 63.5\n",
      "Epoch 2 : Validation loss = 0.7018470391631126; Validation acc = 54.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.5878332257270813; training acc = 74.0\n",
      "Epoch 3 : Validation loss = 0.7160704731941223; Validation acc = 56.5\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6898482441902161; training acc = 54.0\n",
      "Epoch 1 : Validation loss = 0.6582267209887505; Validation acc = 64.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6521760821342468; training acc = 61.5\n",
      "Epoch 2 : Validation loss = 0.6821721792221069; Validation acc = 56.5\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6953656673431396; training acc = 47.0\n",
      "Epoch 1 : Validation loss = 0.6847478672862053; Validation acc = 55.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6679527163505554; training acc = 67.5\n",
      "Epoch 2 : Validation loss = 0.7699763774871826; Validation acc = 46.5\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.7822507619857788; training acc = 49.0\n",
      "Epoch 1 : Validation loss = 1.0866828933358192; Validation acc = 45.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6443619728088379; training acc = 59.0\n",
      "Epoch 2 : Validation loss = 0.7190273925662041; Validation acc = 55.5\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.2757745385169983; training acc = 95.0\n",
      "Epoch 3 : Validation loss = 0.7372829467058182; Validation acc = 57.5\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.694614052772522; training acc = 45.0\n",
      "Epoch 1 : Validation loss = 0.7173998132348061; Validation acc = 44.5\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6712139844894409; training acc = 49.5\n",
      "Epoch 2 : Validation loss = 0.6533719524741173; Validation acc = 58.5\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.5983134508132935; training acc = 72.5\n",
      "Epoch 3 : Validation loss = 0.6015759631991386; Validation acc = 73.5\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.4940982162952423; training acc = 86.0\n",
      "Epoch 4 : Validation loss = 0.5935339033603668; Validation acc = 72.0\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.3957364559173584; training acc = 90.5\n",
      "Epoch 5 : Validation loss = 0.5504959858953953; Validation acc = 75.0\n",
      "Epoch 6:\n",
      "Batch 0 : training loss = 0.28830084204673767; training acc = 98.0\n",
      "Epoch 6 : Validation loss = 0.5351351723074913; Validation acc = 76.5\n",
      "Epoch 7:\n",
      "Batch 0 : training loss = 0.19745483994483948; training acc = 99.0\n",
      "Epoch 7 : Validation loss = 0.532112680375576; Validation acc = 76.5\n",
      "Epoch 8:\n",
      "Batch 0 : training loss = 0.12455664575099945; training acc = 100.0\n",
      "Epoch 8 : Validation loss = 0.5337134413421154; Validation acc = 77.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6958822011947632; training acc = 47.5\n",
      "Epoch 1 : Validation loss = 0.7301570549607277; Validation acc = 44.5\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6482275128364563; training acc = 53.5\n",
      "Epoch 2 : Validation loss = 0.6267266646027565; Validation acc = 72.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.5083506107330322; training acc = 89.0\n",
      "Epoch 3 : Validation loss = 0.5805667862296104; Validation acc = 71.5\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.38197556138038635; training acc = 92.0\n",
      "Epoch 4 : Validation loss = 0.5487686805427074; Validation acc = 73.0\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.24781660735607147; training acc = 96.5\n",
      "Epoch 5 : Validation loss = 0.49874279275536537; Validation acc = 78.0\n",
      "Epoch 6:\n",
      "Batch 0 : training loss = 0.14348125457763672; training acc = 99.0\n",
      "Epoch 6 : Validation loss = 0.49611661955714226; Validation acc = 78.5\n",
      "Epoch 7:\n",
      "Batch 0 : training loss = 0.06928496062755585; training acc = 100.0\n",
      "Epoch 7 : Validation loss = 0.5056807734072208; Validation acc = 78.5\n",
      "Early stopping.\n",
      "RUN COURANT = 1\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6894405484199524; training acc = 51.5\n",
      "Epoch 1 : Validation loss = 0.6939922496676445; Validation acc = 47.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6868153214454651; training acc = 56.5\n",
      "Epoch 2 : Validation loss = 0.6860769018530846; Validation acc = 55.5\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6749588847160339; training acc = 65.5\n",
      "Epoch 3 : Validation loss = 0.6790899708867073; Validation acc = 58.5\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.662138044834137; training acc = 69.5\n",
      "Epoch 4 : Validation loss = 0.6743071600794792; Validation acc = 60.0\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.6511008739471436; training acc = 73.5\n",
      "Epoch 5 : Validation loss = 0.6668566167354584; Validation acc = 62.0\n",
      "Epoch 6:\n",
      "Batch 0 : training loss = 0.6458653807640076; training acc = 69.0\n",
      "Epoch 6 : Validation loss = 0.6602214872837067; Validation acc = 63.5\n",
      "Epoch 7:\n",
      "Batch 0 : training loss = 0.6395948529243469; training acc = 69.0\n",
      "Epoch 7 : Validation loss = 0.6548132449388504; Validation acc = 61.5\n",
      "Epoch 8:\n",
      "Batch 0 : training loss = 0.613755464553833; training acc = 74.5\n",
      "Epoch 8 : Validation loss = 0.6406603157520294; Validation acc = 65.5\n",
      "Epoch 9:\n",
      "Batch 0 : training loss = 0.5946351289749146; training acc = 75.5\n",
      "Epoch 9 : Validation loss = 0.6319839358329773; Validation acc = 66.5\n",
      "Epoch 10:\n",
      "Batch 0 : training loss = 0.5853464603424072; training acc = 74.0\n",
      "Epoch 10 : Validation loss = 0.6196222230792046; Validation acc = 67.5\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.694140613079071; training acc = 48.5\n",
      "Epoch 1 : Validation loss = 0.6908493489027023; Validation acc = 57.5\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6895142197608948; training acc = 61.0\n",
      "Epoch 2 : Validation loss = 0.6917093619704247; Validation acc = 51.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6926053762435913; training acc = 49.5\n",
      "Epoch 1 : Validation loss = 0.6902008131146431; Validation acc = 52.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6794905066490173; training acc = 63.5\n",
      "Epoch 2 : Validation loss = 0.6767437979578972; Validation acc = 66.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6743133664131165; training acc = 60.0\n",
      "Epoch 3 : Validation loss = 0.6704486533999443; Validation acc = 64.0\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.6647568345069885; training acc = 68.0\n",
      "Epoch 4 : Validation loss = 0.6628058478236198; Validation acc = 63.0\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.6329978108406067; training acc = 75.0\n",
      "Epoch 5 : Validation loss = 0.6458432525396347; Validation acc = 69.5\n",
      "Epoch 6:\n",
      "Batch 0 : training loss = 0.619957447052002; training acc = 74.5\n",
      "Epoch 6 : Validation loss = 0.634557232260704; Validation acc = 66.5\n",
      "Epoch 7:\n",
      "Batch 0 : training loss = 0.584933340549469; training acc = 77.5\n",
      "Epoch 7 : Validation loss = 0.6129466891288757; Validation acc = 69.5\n",
      "Epoch 8:\n",
      "Batch 0 : training loss = 0.5517796277999878; training acc = 80.0\n",
      "Epoch 8 : Validation loss = 0.6033612862229347; Validation acc = 71.0\n",
      "Epoch 9:\n",
      "Batch 0 : training loss = 0.5450467467308044; training acc = 77.5\n",
      "Epoch 9 : Validation loss = 0.5746959522366524; Validation acc = 72.0\n",
      "Epoch 10:\n",
      "Batch 0 : training loss = 0.5005119442939758; training acc = 84.5\n",
      "Epoch 10 : Validation loss = 0.5624461099505424; Validation acc = 74.5\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6877160668373108; training acc = 57.0\n",
      "Epoch 1 : Validation loss = 0.7165173888206482; Validation acc = 49.5\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6634831428527832; training acc = 63.5\n",
      "Epoch 2 : Validation loss = 0.7108020782470703; Validation acc = 52.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6273202896118164; training acc = 70.0\n",
      "Epoch 3 : Validation loss = 0.712538406252861; Validation acc = 57.5\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6937628388404846; training acc = 49.0\n",
      "Epoch 1 : Validation loss = 0.6810679957270622; Validation acc = 57.5\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6792411804199219; training acc = 57.0\n",
      "Epoch 2 : Validation loss = 0.6768512055277824; Validation acc = 57.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6549980640411377; training acc = 63.0\n",
      "Epoch 3 : Validation loss = 1.3301869556307793; Validation acc = 51.5\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6925528645515442; training acc = 50.5\n",
      "Epoch 1 : Validation loss = 0.6877755224704742; Validation acc = 55.5\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6646745204925537; training acc = 67.5\n",
      "Epoch 2 : Validation loss = 0.68697839230299; Validation acc = 54.5\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6583831310272217; training acc = 61.5\n",
      "Epoch 3 : Validation loss = 0.6824184134602547; Validation acc = 55.0\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.5742378830909729; training acc = 71.5\n",
      "Epoch 4 : Validation loss = 0.7062338143587112; Validation acc = 52.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.9258702993392944; training acc = 51.0\n",
      "Epoch 1 : Validation loss = 0.7452985569834709; Validation acc = 58.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.5530081391334534; training acc = 73.0\n",
      "Epoch 2 : Validation loss = 0.7398069649934769; Validation acc = 53.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.38504669070243835; training acc = 87.0\n",
      "Epoch 3 : Validation loss = 0.6928853988647461; Validation acc = 53.5\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.19877448678016663; training acc = 98.0\n",
      "Epoch 4 : Validation loss = 0.6967804953455925; Validation acc = 58.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.685575544834137; training acc = 56.5\n",
      "Epoch 1 : Validation loss = 0.6699510142207146; Validation acc = 59.5\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6196069717407227; training acc = 73.5\n",
      "Epoch 2 : Validation loss = 0.6335951909422874; Validation acc = 67.5\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.54183030128479; training acc = 77.5\n",
      "Epoch 3 : Validation loss = 0.6032743379473686; Validation acc = 69.5\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.41638484597206116; training acc = 90.5\n",
      "Epoch 4 : Validation loss = 0.6037386655807495; Validation acc = 67.5\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.7397889494895935; training acc = 48.0\n",
      "Epoch 1 : Validation loss = 0.6929641887545586; Validation acc = 55.5\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6830812096595764; training acc = 51.5\n",
      "Epoch 2 : Validation loss = 0.6946191862225533; Validation acc = 55.5\n",
      "Early stopping.\n",
      "RUN COURANT = 2\n",
      "RUN COURANT = 2\n",
      "RUN COURANT = 2\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6887570023536682; training acc = 58.0\n",
      "Epoch 1 : Validation loss = 0.6956364214420319; Validation acc = 54.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.693936288356781; training acc = 53.0\n",
      "Epoch 2 : Validation loss = 0.6935489773750305; Validation acc = 54.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6802769303321838; training acc = 55.5\n",
      "Epoch 3 : Validation loss = 0.6932820379734039; Validation acc = 52.0\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.6705629825592041; training acc = 57.0\n",
      "Epoch 4 : Validation loss = 0.6925699710845947; Validation acc = 58.0\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.6695666313171387; training acc = 56.5\n",
      "Epoch 5 : Validation loss = 0.6913921236991882; Validation acc = 50.0\n",
      "Epoch 6:\n",
      "Batch 0 : training loss = 0.6586483716964722; training acc = 68.5\n",
      "Epoch 6 : Validation loss = 0.6895310580730438; Validation acc = 58.0\n",
      "Epoch 7:\n",
      "Batch 0 : training loss = 0.6594005823135376; training acc = 65.0\n",
      "Epoch 7 : Validation loss = 0.6875917017459869; Validation acc = 58.0\n",
      "Epoch 8:\n",
      "Batch 0 : training loss = 0.6451833844184875; training acc = 70.5\n",
      "Epoch 8 : Validation loss = 0.6857119798660278; Validation acc = 62.0\n",
      "Epoch 9:\n",
      "Batch 0 : training loss = 0.6308323740959167; training acc = 79.0\n",
      "Epoch 9 : Validation loss = 0.683551162481308; Validation acc = 62.0\n",
      "Epoch 10:\n",
      "Batch 0 : training loss = 0.6302106976509094; training acc = 83.0\n",
      "Epoch 10 : Validation loss = 0.6808350384235382; Validation acc = 58.0\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6966736316680908; training acc = 48.0\n",
      "Epoch 1 : Validation loss = 0.6949343383312225; Validation acc = 48.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6916928887367249; training acc = 52.0\n",
      "Epoch 2 : Validation loss = 0.6909880638122559; Validation acc = 54.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6880537271499634; training acc = 54.0\n",
      "Epoch 3 : Validation loss = 0.6887742578983307; Validation acc = 54.0\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.6823146939277649; training acc = 56.0\n",
      "Epoch 4 : Validation loss = 0.6872963011264801; Validation acc = 54.0\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.6800851225852966; training acc = 56.0\n",
      "Epoch 5 : Validation loss = 0.6856985688209534; Validation acc = 54.0\n",
      "Epoch 6:\n",
      "Batch 0 : training loss = 0.6779335737228394; training acc = 56.0\n",
      "Epoch 6 : Validation loss = 0.6840079724788666; Validation acc = 54.0\n",
      "Epoch 7:\n",
      "Batch 0 : training loss = 0.6841046810150146; training acc = 52.5\n",
      "Epoch 7 : Validation loss = 0.6824992001056671; Validation acc = 54.0\n",
      "Epoch 8:\n",
      "Batch 0 : training loss = 0.6812747120857239; training acc = 53.5\n",
      "Epoch 8 : Validation loss = 0.6812390685081482; Validation acc = 54.0\n",
      "Epoch 9:\n",
      "Batch 0 : training loss = 0.6831450462341309; training acc = 50.0\n",
      "Epoch 9 : Validation loss = 0.6803140044212341; Validation acc = 58.0\n",
      "Epoch 10:\n",
      "Batch 0 : training loss = 0.6771789789199829; training acc = 56.5\n",
      "Epoch 10 : Validation loss = 0.6791687309741974; Validation acc = 60.0\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6956765055656433; training acc = 49.5\n",
      "Epoch 1 : Validation loss = 0.691581517457962; Validation acc = 60.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6911665201187134; training acc = 54.0\n",
      "Epoch 2 : Validation loss = 0.6880729794502258; Validation acc = 54.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6831513047218323; training acc = 52.5\n",
      "Epoch 3 : Validation loss = 0.6849280595779419; Validation acc = 54.0\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.6764317154884338; training acc = 52.0\n",
      "Epoch 4 : Validation loss = 0.6822867095470428; Validation acc = 54.0\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.668530285358429; training acc = 54.0\n",
      "Epoch 5 : Validation loss = 0.6799496412277222; Validation acc = 54.0\n",
      "Epoch 6:\n",
      "Batch 0 : training loss = 0.6669996380805969; training acc = 50.5\n",
      "Epoch 6 : Validation loss = 0.6775568723678589; Validation acc = 54.0\n",
      "Epoch 7:\n",
      "Batch 0 : training loss = 0.6548417806625366; training acc = 53.5\n",
      "Epoch 7 : Validation loss = 0.6751046776771545; Validation acc = 54.0\n",
      "Epoch 8:\n",
      "Batch 0 : training loss = 0.639615535736084; training acc = 62.0\n",
      "Epoch 8 : Validation loss = 0.6725948452949524; Validation acc = 54.0\n",
      "Epoch 9:\n",
      "Batch 0 : training loss = 0.6437451839447021; training acc = 63.0\n",
      "Epoch 9 : Validation loss = 0.6702292561531067; Validation acc = 60.0\n",
      "Epoch 10:\n",
      "Batch 0 : training loss = 0.6264969706535339; training acc = 81.5\n",
      "Epoch 10 : Validation loss = 0.6676847636699677; Validation acc = 68.0\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6969889998435974; training acc = 48.0\n",
      "Epoch 1 : Validation loss = 0.7156282961368561; Validation acc = 54.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6315367817878723; training acc = 73.5\n",
      "Epoch 2 : Validation loss = 0.6898697912693024; Validation acc = 50.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.5755933523178101; training acc = 82.5\n",
      "Epoch 3 : Validation loss = 0.708299845457077; Validation acc = 50.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6946570873260498; training acc = 47.5\n",
      "Epoch 1 : Validation loss = 0.6751928329467773; Validation acc = 54.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6658806800842285; training acc = 57.5\n",
      "Epoch 2 : Validation loss = 0.6790524423122406; Validation acc = 54.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6944973468780518; training acc = 46.0\n",
      "Epoch 1 : Validation loss = 0.6799625754356384; Validation acc = 52.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.674609363079071; training acc = 53.5\n",
      "Epoch 2 : Validation loss = 0.6836723387241364; Validation acc = 58.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.7024471759796143; training acc = 44.5\n",
      "Epoch 1 : Validation loss = 0.6832671165466309; Validation acc = 52.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.3510650396347046; training acc = 86.5\n",
      "Epoch 2 : Validation loss = 0.6583899259567261; Validation acc = 68.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.14253924787044525; training acc = 100.0\n",
      "Epoch 3 : Validation loss = 0.66254922747612; Validation acc = 62.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.7316924929618835; training acc = 41.5\n",
      "Epoch 1 : Validation loss = 0.8352614343166351; Validation acc = 54.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.7989240288734436; training acc = 54.5\n",
      "Epoch 2 : Validation loss = 0.6976563930511475; Validation acc = 46.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6832156181335449; training acc = 54.0\n",
      "Epoch 3 : Validation loss = 0.6996155977249146; Validation acc = 46.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6942502856254578; training acc = 48.5\n",
      "Epoch 1 : Validation loss = 0.6592416167259216; Validation acc = 68.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.5661725401878357; training acc = 86.0\n",
      "Epoch 2 : Validation loss = 0.6833433508872986; Validation acc = 50.0\n",
      "Early stopping.\n",
      "RUN COURANT = 2\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.7117440104484558; training acc = 43.0\n",
      "Epoch 1 : Validation loss = 0.7031466066837311; Validation acc = 50.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6870399713516235; training acc = 52.5\n",
      "Epoch 2 : Validation loss = 0.6944379806518555; Validation acc = 48.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6723396182060242; training acc = 61.0\n",
      "Epoch 3 : Validation loss = 0.6925047636032104; Validation acc = 52.0\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.6714456677436829; training acc = 59.5\n",
      "Epoch 4 : Validation loss = 0.690814882516861; Validation acc = 54.0\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.6683248281478882; training acc = 59.0\n",
      "Epoch 5 : Validation loss = 0.6887542903423309; Validation acc = 54.0\n",
      "Epoch 6:\n",
      "Batch 0 : training loss = 0.6725377440452576; training acc = 54.0\n",
      "Epoch 6 : Validation loss = 0.6867119371891022; Validation acc = 54.0\n",
      "Epoch 7:\n",
      "Batch 0 : training loss = 0.6775746941566467; training acc = 51.0\n",
      "Epoch 7 : Validation loss = 0.684429943561554; Validation acc = 52.0\n",
      "Epoch 8:\n",
      "Batch 0 : training loss = 0.6504785418510437; training acc = 62.0\n",
      "Epoch 8 : Validation loss = 0.682646632194519; Validation acc = 54.0\n",
      "Epoch 9:\n",
      "Batch 0 : training loss = 0.6524137854576111; training acc = 62.0\n",
      "Epoch 9 : Validation loss = 0.6814081966876984; Validation acc = 58.0\n",
      "Epoch 10:\n",
      "Batch 0 : training loss = 0.6482203006744385; training acc = 74.0\n",
      "Epoch 10 : Validation loss = 0.6795384585857391; Validation acc = 62.0\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6856318712234497; training acc = 59.0\n",
      "Epoch 1 : Validation loss = 0.6890809834003448; Validation acc = 54.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6900269985198975; training acc = 51.5\n",
      "Epoch 2 : Validation loss = 0.6879745721817017; Validation acc = 54.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6889888644218445; training acc = 51.5\n",
      "Epoch 3 : Validation loss = 0.6868478059768677; Validation acc = 54.0\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.6835965514183044; training acc = 55.5\n",
      "Epoch 4 : Validation loss = 0.6854842305183411; Validation acc = 54.0\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.6811228394508362; training acc = 55.5\n",
      "Epoch 5 : Validation loss = 0.6841170489788055; Validation acc = 54.0\n",
      "Epoch 6:\n",
      "Batch 0 : training loss = 0.6804916858673096; training acc = 57.0\n",
      "Epoch 6 : Validation loss = 0.6827603578567505; Validation acc = 54.0\n",
      "Epoch 7:\n",
      "Batch 0 : training loss = 0.685252845287323; training acc = 49.5\n",
      "Epoch 7 : Validation loss = 0.6816618740558624; Validation acc = 54.0\n",
      "Epoch 8:\n",
      "Batch 0 : training loss = 0.6811648607254028; training acc = 53.5\n",
      "Epoch 8 : Validation loss = 0.6803441941738129; Validation acc = 54.0\n",
      "Epoch 9:\n",
      "Batch 0 : training loss = 0.682529628276825; training acc = 51.5\n",
      "Epoch 9 : Validation loss = 0.6791276931762695; Validation acc = 54.0\n",
      "Epoch 10:\n",
      "Batch 0 : training loss = 0.6775891780853271; training acc = 57.0\n",
      "Epoch 10 : Validation loss = 0.6777562201023102; Validation acc = 56.0\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6967723965644836; training acc = 43.5\n",
      "Epoch 1 : Validation loss = 0.6911083161830902; Validation acc = 54.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6894383430480957; training acc = 53.0\n",
      "Epoch 2 : Validation loss = 0.6879286766052246; Validation acc = 54.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.684599757194519; training acc = 53.5\n",
      "Epoch 3 : Validation loss = 0.68555748462677; Validation acc = 54.0\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.6821115612983704; training acc = 52.5\n",
      "Epoch 4 : Validation loss = 0.6833449602127075; Validation acc = 54.0\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.6760216355323792; training acc = 53.0\n",
      "Epoch 5 : Validation loss = 0.6813400685787201; Validation acc = 54.0\n",
      "Epoch 6:\n",
      "Batch 0 : training loss = 0.6737825274467468; training acc = 51.5\n",
      "Epoch 6 : Validation loss = 0.6794962882995605; Validation acc = 56.0\n",
      "Epoch 7:\n",
      "Batch 0 : training loss = 0.6656619310379028; training acc = 57.0\n",
      "Epoch 7 : Validation loss = 0.6774672865867615; Validation acc = 60.0\n",
      "Epoch 8:\n",
      "Batch 0 : training loss = 0.6588603854179382; training acc = 70.0\n",
      "Epoch 8 : Validation loss = 0.6750056445598602; Validation acc = 64.0\n",
      "Epoch 9:\n",
      "Batch 0 : training loss = 0.6548380851745605; training acc = 69.5\n",
      "Epoch 9 : Validation loss = 0.6724340617656708; Validation acc = 68.0\n",
      "Epoch 10:\n",
      "Batch 0 : training loss = 0.6439394950866699; training acc = 77.0\n",
      "Epoch 10 : Validation loss = 0.6694382131099701; Validation acc = 66.0\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6933200359344482; training acc = 48.5\n",
      "Epoch 1 : Validation loss = 0.6978372037410736; Validation acc = 44.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6318833827972412; training acc = 72.0\n",
      "Epoch 2 : Validation loss = 0.6900445818901062; Validation acc = 46.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.5688503384590149; training acc = 81.0\n",
      "Epoch 3 : Validation loss = 0.6977288126945496; Validation acc = 56.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6959896683692932; training acc = 47.0\n",
      "Epoch 1 : Validation loss = 0.6806744933128357; Validation acc = 52.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6673547625541687; training acc = 56.0\n",
      "Epoch 2 : Validation loss = 0.6844877600669861; Validation acc = 62.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6903896927833557; training acc = 53.0\n",
      "Epoch 1 : Validation loss = 0.6831432580947876; Validation acc = 52.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6707583665847778; training acc = 56.5\n",
      "Epoch 2 : Validation loss = 0.6905677318572998; Validation acc = 58.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.7043189406394958; training acc = 47.0\n",
      "Epoch 1 : Validation loss = 0.9761230647563934; Validation acc = 46.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6082577109336853; training acc = 59.5\n",
      "Epoch 2 : Validation loss = 0.7573156952857971; Validation acc = 54.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.2273867428302765; training acc = 99.0\n",
      "Epoch 3 : Validation loss = 0.8596341013908386; Validation acc = 54.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6860054135322571; training acc = 56.5\n",
      "Epoch 1 : Validation loss = 0.8362008631229401; Validation acc = 54.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.7445438504219055; training acc = 53.5\n",
      "Epoch 2 : Validation loss = 0.7866520881652832; Validation acc = 46.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6177922487258911; training acc = 51.0\n",
      "Epoch 3 : Validation loss = 0.6505179107189178; Validation acc = 54.0\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.45478343963623047; training acc = 72.5\n",
      "Epoch 4 : Validation loss = 0.6197059154510498; Validation acc = 58.0\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.3793666958808899; training acc = 95.0\n",
      "Epoch 5 : Validation loss = 0.6587879657745361; Validation acc = 52.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.7586015462875366; training acc = 42.0\n",
      "Epoch 1 : Validation loss = 0.8452161848545074; Validation acc = 54.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.789355993270874; training acc = 56.5\n",
      "Epoch 2 : Validation loss = 0.6918015480041504; Validation acc = 48.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6746269464492798; training acc = 66.5\n",
      "Epoch 3 : Validation loss = 0.6980718076229095; Validation acc = 46.0\n",
      "Early stopping.\n",
      "RUN COURANT = 2\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6948585510253906; training acc = 47.0\n",
      "Epoch 1 : Validation loss = 0.6931130886077881; Validation acc = 54.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6846975088119507; training acc = 59.5\n",
      "Epoch 2 : Validation loss = 0.6926394999027252; Validation acc = 56.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6794659495353699; training acc = 57.0\n",
      "Epoch 3 : Validation loss = 0.6935115456581116; Validation acc = 54.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.7049469947814941; training acc = 44.5\n",
      "Epoch 1 : Validation loss = 0.6954885721206665; Validation acc = 48.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6962288022041321; training acc = 42.0\n",
      "Epoch 2 : Validation loss = 0.6910720765590668; Validation acc = 54.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6912642121315002; training acc = 54.5\n",
      "Epoch 3 : Validation loss = 0.6889221370220184; Validation acc = 54.0\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.6861088275909424; training acc = 56.5\n",
      "Epoch 4 : Validation loss = 0.6877216100692749; Validation acc = 54.0\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.6844171285629272; training acc = 57.0\n",
      "Epoch 5 : Validation loss = 0.68672114610672; Validation acc = 54.0\n",
      "Epoch 6:\n",
      "Batch 0 : training loss = 0.6914560198783875; training acc = 52.0\n",
      "Epoch 6 : Validation loss = 0.6855436563491821; Validation acc = 54.0\n",
      "Epoch 7:\n",
      "Batch 0 : training loss = 0.6842172741889954; training acc = 55.0\n",
      "Epoch 7 : Validation loss = 0.6843931376934052; Validation acc = 54.0\n",
      "Epoch 8:\n",
      "Batch 0 : training loss = 0.6857444047927856; training acc = 54.5\n",
      "Epoch 8 : Validation loss = 0.6833856403827667; Validation acc = 54.0\n",
      "Epoch 9:\n",
      "Batch 0 : training loss = 0.6830439567565918; training acc = 54.5\n",
      "Epoch 9 : Validation loss = 0.6825446486473083; Validation acc = 54.0\n",
      "Epoch 10:\n",
      "Batch 0 : training loss = 0.6822722554206848; training acc = 54.0\n",
      "Epoch 10 : Validation loss = 0.6818313002586365; Validation acc = 54.0\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6906471848487854; training acc = 55.0\n",
      "Epoch 1 : Validation loss = 0.6886367797851562; Validation acc = 54.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6867768168449402; training acc = 53.0\n",
      "Epoch 2 : Validation loss = 0.6867047250270844; Validation acc = 54.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6829774379730225; training acc = 52.5\n",
      "Epoch 3 : Validation loss = 0.6850331127643585; Validation acc = 54.0\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.6818231344223022; training acc = 52.5\n",
      "Epoch 4 : Validation loss = 0.6831685304641724; Validation acc = 54.0\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.6755725145339966; training acc = 56.0\n",
      "Epoch 5 : Validation loss = 0.6810756325721741; Validation acc = 54.0\n",
      "Epoch 6:\n",
      "Batch 0 : training loss = 0.668965756893158; training acc = 64.0\n",
      "Epoch 6 : Validation loss = 0.6787814199924469; Validation acc = 56.0\n",
      "Epoch 7:\n",
      "Batch 0 : training loss = 0.6686023473739624; training acc = 60.0\n",
      "Epoch 7 : Validation loss = 0.6765972375869751; Validation acc = 58.0\n",
      "Epoch 8:\n",
      "Batch 0 : training loss = 0.6542271971702576; training acc = 66.0\n",
      "Epoch 8 : Validation loss = 0.6742123067378998; Validation acc = 56.0\n",
      "Epoch 9:\n",
      "Batch 0 : training loss = 0.6499925255775452; training acc = 63.5\n",
      "Epoch 9 : Validation loss = 0.6721626222133636; Validation acc = 60.0\n",
      "Epoch 10:\n",
      "Batch 0 : training loss = 0.6466469764709473; training acc = 69.0\n",
      "Epoch 10 : Validation loss = 0.670165628194809; Validation acc = 60.0\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6893659830093384; training acc = 52.5\n",
      "Epoch 1 : Validation loss = 0.6891635954380035; Validation acc = 58.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6292740106582642; training acc = 73.0\n",
      "Epoch 2 : Validation loss = 0.6876265406608582; Validation acc = 62.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.5687825083732605; training acc = 73.5\n",
      "Epoch 3 : Validation loss = 0.7029474377632141; Validation acc = 58.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6910021305084229; training acc = 52.0\n",
      "Epoch 1 : Validation loss = 0.6870360970497131; Validation acc = 52.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6690438985824585; training acc = 57.5\n",
      "Epoch 2 : Validation loss = 0.6940926313400269; Validation acc = 54.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6935474872589111; training acc = 51.5\n",
      "Epoch 1 : Validation loss = 0.6818990409374237; Validation acc = 54.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6639248728752136; training acc = 57.0\n",
      "Epoch 2 : Validation loss = 0.682004451751709; Validation acc = 60.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.704374372959137; training acc = 49.5\n",
      "Epoch 1 : Validation loss = 0.7436544597148895; Validation acc = 48.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.5047428607940674; training acc = 69.5\n",
      "Epoch 2 : Validation loss = 0.6869335472583771; Validation acc = 48.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.2670105993747711; training acc = 100.0\n",
      "Epoch 3 : Validation loss = 0.8252863883972168; Validation acc = 56.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.715251088142395; training acc = 42.0\n",
      "Epoch 1 : Validation loss = 0.829084038734436; Validation acc = 54.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.8660123348236084; training acc = 49.5\n",
      "Epoch 2 : Validation loss = 0.6929104030132294; Validation acc = 46.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6902776956558228; training acc = 73.0\n",
      "Epoch 3 : Validation loss = 0.6932728588581085; Validation acc = 44.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.7018587589263916; training acc = 48.0\n",
      "Epoch 1 : Validation loss = 0.7403886318206787; Validation acc = 54.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6812811493873596; training acc = 57.0\n",
      "Epoch 2 : Validation loss = 0.6959498822689056; Validation acc = 46.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6727548837661743; training acc = 52.0\n",
      "Epoch 3 : Validation loss = 0.6959157586097717; Validation acc = 46.0\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.6523230075836182; training acc = 50.5\n",
      "Epoch 4 : Validation loss = 0.689967930316925; Validation acc = 40.0\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.6346960663795471; training acc = 48.0\n",
      "Epoch 5 : Validation loss = 0.6863180696964264; Validation acc = 44.0\n",
      "Epoch 6:\n",
      "Batch 0 : training loss = 0.5935601592063904; training acc = 53.0\n",
      "Epoch 6 : Validation loss = 0.6894667148590088; Validation acc = 44.0\n",
      "Early stopping.\n",
      "RUN COURANT = 2\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6967721581459045; training acc = 51.0\n",
      "Epoch 1 : Validation loss = 0.6895205676555634; Validation acc = 54.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6904541850090027; training acc = 54.0\n",
      "Epoch 2 : Validation loss = 0.691325843334198; Validation acc = 54.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.7006475925445557; training acc = 45.5\n",
      "Epoch 1 : Validation loss = 0.6934937536716461; Validation acc = 44.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6935956478118896; training acc = 48.0\n",
      "Epoch 2 : Validation loss = 0.6903304159641266; Validation acc = 54.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6930250525474548; training acc = 52.0\n",
      "Epoch 3 : Validation loss = 0.6888492107391357; Validation acc = 54.0\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.6903175115585327; training acc = 53.0\n",
      "Epoch 4 : Validation loss = 0.687855452299118; Validation acc = 54.0\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.694057822227478; training acc = 50.5\n",
      "Epoch 5 : Validation loss = 0.6868839859962463; Validation acc = 54.0\n",
      "Epoch 6:\n",
      "Batch 0 : training loss = 0.6890869140625; training acc = 52.0\n",
      "Epoch 6 : Validation loss = 0.685886800289154; Validation acc = 54.0\n",
      "Epoch 7:\n",
      "Batch 0 : training loss = 0.6916343569755554; training acc = 50.0\n",
      "Epoch 7 : Validation loss = 0.685087114572525; Validation acc = 54.0\n",
      "Epoch 8:\n",
      "Batch 0 : training loss = 0.6859594583511353; training acc = 54.0\n",
      "Epoch 8 : Validation loss = 0.6843965351581573; Validation acc = 54.0\n",
      "Epoch 9:\n",
      "Batch 0 : training loss = 0.6821409463882446; training acc = 54.5\n",
      "Epoch 9 : Validation loss = 0.6836815476417542; Validation acc = 54.0\n",
      "Epoch 10:\n",
      "Batch 0 : training loss = 0.683566153049469; training acc = 54.0\n",
      "Epoch 10 : Validation loss = 0.6830238699913025; Validation acc = 54.0\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.7064855694770813; training acc = 40.5\n",
      "Epoch 1 : Validation loss = 0.6911127865314484; Validation acc = 56.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6917696595191956; training acc = 53.5\n",
      "Epoch 2 : Validation loss = 0.6876681447029114; Validation acc = 56.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.685781717300415; training acc = 58.0\n",
      "Epoch 3 : Validation loss = 0.6852630972862244; Validation acc = 54.0\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.6822988986968994; training acc = 54.0\n",
      "Epoch 4 : Validation loss = 0.6838902235031128; Validation acc = 54.0\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.6782128810882568; training acc = 55.0\n",
      "Epoch 5 : Validation loss = 0.682651162147522; Validation acc = 54.0\n",
      "Epoch 6:\n",
      "Batch 0 : training loss = 0.6753823161125183; training acc = 55.5\n",
      "Epoch 6 : Validation loss = 0.6813449859619141; Validation acc = 54.0\n",
      "Epoch 7:\n",
      "Batch 0 : training loss = 0.6724295616149902; training acc = 56.5\n",
      "Epoch 7 : Validation loss = 0.6800254881381989; Validation acc = 54.0\n",
      "Epoch 8:\n",
      "Batch 0 : training loss = 0.676849365234375; training acc = 51.0\n",
      "Epoch 8 : Validation loss = 0.6787368357181549; Validation acc = 54.0\n",
      "Epoch 9:\n",
      "Batch 0 : training loss = 0.6697824001312256; training acc = 55.5\n",
      "Epoch 9 : Validation loss = 0.6775465607643127; Validation acc = 56.0\n",
      "Epoch 10:\n",
      "Batch 0 : training loss = 0.6686881184577942; training acc = 56.0\n",
      "Epoch 10 : Validation loss = 0.6764591932296753; Validation acc = 62.0\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6954549551010132; training acc = 50.5\n",
      "Epoch 1 : Validation loss = 0.701559990644455; Validation acc = 56.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6170833706855774; training acc = 70.5\n",
      "Epoch 2 : Validation loss = 0.6823274195194244; Validation acc = 58.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.5749109387397766; training acc = 75.5\n",
      "Epoch 3 : Validation loss = 0.6906437277793884; Validation acc = 56.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.693092405796051; training acc = 51.0\n",
      "Epoch 1 : Validation loss = 0.6794817745685577; Validation acc = 54.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6762235164642334; training acc = 55.0\n",
      "Epoch 2 : Validation loss = 0.6858175098896027; Validation acc = 56.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6901743412017822; training acc = 57.5\n",
      "Epoch 1 : Validation loss = 0.6823711395263672; Validation acc = 52.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6639401316642761; training acc = 67.0\n",
      "Epoch 2 : Validation loss = 0.6840296387672424; Validation acc = 58.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.8486676812171936; training acc = 54.0\n",
      "Epoch 1 : Validation loss = 1.7156550288200378; Validation acc = 46.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 1.3280587196350098; training acc = 51.5\n",
      "Epoch 2 : Validation loss = 1.2766260206699371; Validation acc = 54.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.9031308889389038; training acc = 53.5\n",
      "Epoch 3 : Validation loss = 0.7436203360557556; Validation acc = 56.0\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.3647556006908417; training acc = 87.0\n",
      "Epoch 4 : Validation loss = 0.7735980451107025; Validation acc = 40.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6907522082328796; training acc = 52.5\n",
      "Epoch 1 : Validation loss = 0.9946906864643097; Validation acc = 46.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.9032537937164307; training acc = 46.5\n",
      "Epoch 2 : Validation loss = 0.8467901647090912; Validation acc = 54.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.7015238404273987; training acc = 55.0\n",
      "Epoch 3 : Validation loss = 0.6515884399414062; Validation acc = 68.0\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.4783502519130707; training acc = 98.5\n",
      "Epoch 4 : Validation loss = 0.7436706721782684; Validation acc = 46.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.7313060760498047; training acc = 48.0\n",
      "Epoch 1 : Validation loss = 0.8087925314903259; Validation acc = 54.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.7993381023406982; training acc = 53.0\n",
      "Epoch 2 : Validation loss = 0.6919175088405609; Validation acc = 48.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6871166229248047; training acc = 63.5\n",
      "Epoch 3 : Validation loss = 0.6937425434589386; Validation acc = 46.0\n",
      "Early stopping.\n",
      "RUN COURANT = 2\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.701826810836792; training acc = 49.0\n",
      "Epoch 1 : Validation loss = 0.6986913681030273; Validation acc = 58.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6949260830879211; training acc = 50.5\n",
      "Epoch 2 : Validation loss = 0.6925605237483978; Validation acc = 54.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6909793615341187; training acc = 50.0\n",
      "Epoch 3 : Validation loss = 0.6901208758354187; Validation acc = 54.0\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.6845868825912476; training acc = 53.0\n",
      "Epoch 4 : Validation loss = 0.6879640519618988; Validation acc = 54.0\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.6886417865753174; training acc = 51.5\n",
      "Epoch 5 : Validation loss = 0.6868938505649567; Validation acc = 54.0\n",
      "Epoch 6:\n",
      "Batch 0 : training loss = 0.6776627898216248; training acc = 54.0\n",
      "Epoch 6 : Validation loss = 0.6872981786727905; Validation acc = 56.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6934207081794739; training acc = 49.5\n",
      "Epoch 1 : Validation loss = 0.6935071349143982; Validation acc = 44.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6936538219451904; training acc = 46.5\n",
      "Epoch 2 : Validation loss = 0.6900841891765594; Validation acc = 54.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6886601448059082; training acc = 57.0\n",
      "Epoch 3 : Validation loss = 0.6882923245429993; Validation acc = 54.0\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.6879768371582031; training acc = 55.0\n",
      "Epoch 4 : Validation loss = 0.6874659359455109; Validation acc = 54.0\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.6871575117111206; training acc = 54.0\n",
      "Epoch 5 : Validation loss = 0.6868011057376862; Validation acc = 54.0\n",
      "Epoch 6:\n",
      "Batch 0 : training loss = 0.6897451281547546; training acc = 52.5\n",
      "Epoch 6 : Validation loss = 0.6860764920711517; Validation acc = 54.0\n",
      "Epoch 7:\n",
      "Batch 0 : training loss = 0.6853299140930176; training acc = 54.5\n",
      "Epoch 7 : Validation loss = 0.6853653192520142; Validation acc = 54.0\n",
      "Epoch 8:\n",
      "Batch 0 : training loss = 0.6806697249412537; training acc = 57.0\n",
      "Epoch 8 : Validation loss = 0.6847136914730072; Validation acc = 54.0\n",
      "Epoch 9:\n",
      "Batch 0 : training loss = 0.683147132396698; training acc = 54.5\n",
      "Epoch 9 : Validation loss = 0.684198409318924; Validation acc = 54.0\n",
      "Epoch 10:\n",
      "Batch 0 : training loss = 0.6809802055358887; training acc = 56.0\n",
      "Epoch 10 : Validation loss = 0.6837577819824219; Validation acc = 54.0\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.7016063928604126; training acc = 45.0\n",
      "Epoch 1 : Validation loss = 0.6909901201725006; Validation acc = 60.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6915698051452637; training acc = 56.5\n",
      "Epoch 2 : Validation loss = 0.6875115931034088; Validation acc = 54.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6882606744766235; training acc = 53.5\n",
      "Epoch 3 : Validation loss = 0.6861518025398254; Validation acc = 54.0\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.6869022846221924; training acc = 53.0\n",
      "Epoch 4 : Validation loss = 0.6851265132427216; Validation acc = 54.0\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.6911998987197876; training acc = 50.0\n",
      "Epoch 5 : Validation loss = 0.6839359700679779; Validation acc = 54.0\n",
      "Epoch 6:\n",
      "Batch 0 : training loss = 0.678265392780304; training acc = 55.5\n",
      "Epoch 6 : Validation loss = 0.6827868819236755; Validation acc = 54.0\n",
      "Epoch 7:\n",
      "Batch 0 : training loss = 0.6800852417945862; training acc = 53.0\n",
      "Epoch 7 : Validation loss = 0.6817574203014374; Validation acc = 54.0\n",
      "Epoch 8:\n",
      "Batch 0 : training loss = 0.6829461455345154; training acc = 48.5\n",
      "Epoch 8 : Validation loss = 0.681049257516861; Validation acc = 54.0\n",
      "Epoch 9:\n",
      "Batch 0 : training loss = 0.6795307993888855; training acc = 52.0\n",
      "Epoch 9 : Validation loss = 0.6803904473781586; Validation acc = 60.0\n",
      "Epoch 10:\n",
      "Batch 0 : training loss = 0.6729885339736938; training acc = 64.5\n",
      "Epoch 10 : Validation loss = 0.6790169179439545; Validation acc = 60.0\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6975977420806885; training acc = 48.5\n",
      "Epoch 1 : Validation loss = 0.6948884129524231; Validation acc = 54.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.64329993724823; training acc = 65.0\n",
      "Epoch 2 : Validation loss = 0.6981422901153564; Validation acc = 52.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6935102939605713; training acc = 49.5\n",
      "Epoch 1 : Validation loss = 0.6804949939250946; Validation acc = 54.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6785810589790344; training acc = 56.5\n",
      "Epoch 2 : Validation loss = 0.6816992163658142; Validation acc = 56.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6944352984428406; training acc = 49.5\n",
      "Epoch 1 : Validation loss = 0.6806899607181549; Validation acc = 52.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6828283667564392; training acc = 51.5\n",
      "Epoch 2 : Validation loss = 0.6817631125450134; Validation acc = 64.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.7046366930007935; training acc = 45.5\n",
      "Epoch 1 : Validation loss = 0.7074352204799652; Validation acc = 54.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.5481507182121277; training acc = 78.0\n",
      "Epoch 2 : Validation loss = 1.127014696598053; Validation acc = 44.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6935665607452393; training acc = 55.5\n",
      "Epoch 1 : Validation loss = 0.6978461146354675; Validation acc = 46.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6505933403968811; training acc = 52.5\n",
      "Epoch 2 : Validation loss = 0.7085385620594025; Validation acc = 54.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6923233866691589; training acc = 52.0\n",
      "Epoch 1 : Validation loss = 0.7194357514381409; Validation acc = 54.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6431284546852112; training acc = 56.5\n",
      "Epoch 2 : Validation loss = 0.6855253875255585; Validation acc = 54.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6343298554420471; training acc = 50.5\n",
      "Epoch 3 : Validation loss = 0.6953365504741669; Validation acc = 46.0\n",
      "Early stopping.\n",
      "RUN COURANT = 2\n",
      "RUN COURANT = 2\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6952053308486938; training acc = 47.5\n",
      "Epoch 1 : Validation loss = 0.6943301111459732; Validation acc = 52.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6849128603935242; training acc = 56.0\n",
      "Epoch 2 : Validation loss = 0.6944531500339508; Validation acc = 56.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6951309442520142; training acc = 48.5\n",
      "Epoch 1 : Validation loss = 0.6914643049240112; Validation acc = 58.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6897149682044983; training acc = 61.5\n",
      "Epoch 2 : Validation loss = 0.6886597573757172; Validation acc = 65.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.687174916267395; training acc = 66.0\n",
      "Epoch 3 : Validation loss = 0.6857274919748306; Validation acc = 69.0\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.683167040348053; training acc = 67.5\n",
      "Epoch 4 : Validation loss = 0.6827153265476227; Validation acc = 68.0\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.6812623739242554; training acc = 66.0\n",
      "Epoch 5 : Validation loss = 0.6802340298891068; Validation acc = 63.0\n",
      "Epoch 6:\n",
      "Batch 0 : training loss = 0.6739485859870911; training acc = 69.5\n",
      "Epoch 6 : Validation loss = 0.6778991967439651; Validation acc = 62.0\n",
      "Epoch 7:\n",
      "Batch 0 : training loss = 0.6718906164169312; training acc = 70.0\n",
      "Epoch 7 : Validation loss = 0.6747913658618927; Validation acc = 66.0\n",
      "Epoch 8:\n",
      "Batch 0 : training loss = 0.6673626899719238; training acc = 67.0\n",
      "Epoch 8 : Validation loss = 0.672202542424202; Validation acc = 67.0\n",
      "Epoch 9:\n",
      "Batch 0 : training loss = 0.666328489780426; training acc = 66.5\n",
      "Epoch 9 : Validation loss = 0.6695908457040787; Validation acc = 66.0\n",
      "Epoch 10:\n",
      "Batch 0 : training loss = 0.662356972694397; training acc = 66.5\n",
      "Epoch 10 : Validation loss = 0.6670822948217392; Validation acc = 68.0\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.694446325302124; training acc = 46.5\n",
      "Epoch 1 : Validation loss = 0.686829999089241; Validation acc = 57.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6816964149475098; training acc = 72.0\n",
      "Epoch 2 : Validation loss = 0.6815152317285538; Validation acc = 63.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6697180867195129; training acc = 77.5\n",
      "Epoch 3 : Validation loss = 0.6766719073057175; Validation acc = 64.0\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.6619823575019836; training acc = 76.5\n",
      "Epoch 4 : Validation loss = 0.6710885167121887; Validation acc = 68.0\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.6409739851951599; training acc = 84.5\n",
      "Epoch 5 : Validation loss = 0.6665007323026657; Validation acc = 62.0\n",
      "Epoch 6:\n",
      "Batch 0 : training loss = 0.636354386806488; training acc = 79.5\n",
      "Epoch 6 : Validation loss = 0.6601826548576355; Validation acc = 61.0\n",
      "Epoch 7:\n",
      "Batch 0 : training loss = 0.6079410314559937; training acc = 82.5\n",
      "Epoch 7 : Validation loss = 0.6518569588661194; Validation acc = 67.0\n",
      "Epoch 8:\n",
      "Batch 0 : training loss = 0.5878549814224243; training acc = 86.0\n",
      "Epoch 8 : Validation loss = 0.6438699066638947; Validation acc = 68.0\n",
      "Epoch 9:\n",
      "Batch 0 : training loss = 0.5578761100769043; training acc = 88.5\n",
      "Epoch 9 : Validation loss = 0.6349231153726578; Validation acc = 72.0\n",
      "Epoch 10:\n",
      "Batch 0 : training loss = 0.5348512530326843; training acc = 87.5\n",
      "Epoch 10 : Validation loss = 0.6266153901815414; Validation acc = 69.0\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6971124410629272; training acc = 46.5\n",
      "Epoch 1 : Validation loss = 0.7044034004211426; Validation acc = 54.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6415477991104126; training acc = 73.0\n",
      "Epoch 2 : Validation loss = 0.7042694538831711; Validation acc = 51.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.5552428960800171; training acc = 80.5\n",
      "Epoch 3 : Validation loss = 0.7262099385261536; Validation acc = 56.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6938607096672058; training acc = 47.0\n",
      "Epoch 1 : Validation loss = 0.6983689069747925; Validation acc = 49.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6722294092178345; training acc = 57.0\n",
      "Epoch 2 : Validation loss = 0.6772209256887436; Validation acc = 56.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6419879198074341; training acc = 70.0\n",
      "Epoch 3 : Validation loss = 0.6897410899400711; Validation acc = 52.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6932234168052673; training acc = 48.5\n",
      "Epoch 1 : Validation loss = 0.698051929473877; Validation acc = 47.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6549742817878723; training acc = 59.0\n",
      "Epoch 2 : Validation loss = 0.6740726381540298; Validation acc = 54.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.5995090007781982; training acc = 70.5\n",
      "Epoch 3 : Validation loss = 0.6746287643909454; Validation acc = 59.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.807503879070282; training acc = 48.0\n",
      "Epoch 1 : Validation loss = 0.8850662559270859; Validation acc = 47.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.5386312007904053; training acc = 60.5\n",
      "Epoch 2 : Validation loss = 0.8275135457515717; Validation acc = 54.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.26020151376724243; training acc = 93.5\n",
      "Epoch 3 : Validation loss = 0.7505695670843124; Validation acc = 47.0\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.1356203705072403; training acc = 99.5\n",
      "Epoch 4 : Validation loss = 0.6860506683588028; Validation acc = 56.0\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.053454384207725525; training acc = 100.0\n",
      "Epoch 5 : Validation loss = 0.7662899494171143; Validation acc = 57.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6954324245452881; training acc = 47.0\n",
      "Epoch 1 : Validation loss = 0.7206521779298782; Validation acc = 47.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6413315534591675; training acc = 52.0\n",
      "Epoch 2 : Validation loss = 0.6354499906301498; Validation acc = 64.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.5504190325737; training acc = 76.5\n",
      "Epoch 3 : Validation loss = 0.6376968175172806; Validation acc = 64.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.693611204624176; training acc = 50.0\n",
      "Epoch 1 : Validation loss = 0.7889973968267441; Validation acc = 53.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6962008476257324; training acc = 52.0\n",
      "Epoch 2 : Validation loss = 0.7470566034317017; Validation acc = 47.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6266626119613647; training acc = 55.0\n",
      "Epoch 3 : Validation loss = 0.6167988330125809; Validation acc = 59.0\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.4017014801502228; training acc = 87.5\n",
      "Epoch 4 : Validation loss = 0.6073503345251083; Validation acc = 63.0\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.29827889800071716; training acc = 94.0\n",
      "Epoch 5 : Validation loss = 0.5439489409327507; Validation acc = 73.0\n",
      "Epoch 6:\n",
      "Batch 0 : training loss = 0.19035933911800385; training acc = 99.5\n",
      "Epoch 6 : Validation loss = 0.5293437615036964; Validation acc = 78.0\n",
      "Epoch 7:\n",
      "Batch 0 : training loss = 0.11412642151117325; training acc = 100.0\n",
      "Epoch 7 : Validation loss = 0.49640797823667526; Validation acc = 78.0\n",
      "Epoch 8:\n",
      "Batch 0 : training loss = 0.06703051924705505; training acc = 100.0\n",
      "Epoch 8 : Validation loss = 0.49365732073783875; Validation acc = 79.0\n",
      "Epoch 9:\n",
      "Batch 0 : training loss = 0.043797459453344345; training acc = 100.0\n",
      "Epoch 9 : Validation loss = 0.48828061670064926; Validation acc = 81.0\n",
      "Epoch 10:\n",
      "Batch 0 : training loss = 0.02396915853023529; training acc = 100.0\n",
      "Epoch 10 : Validation loss = 0.4731508865952492; Validation acc = 80.0\n",
      "RUN COURANT = 2\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6923272609710693; training acc = 52.5\n",
      "Epoch 1 : Validation loss = 0.7003752887248993; Validation acc = 55.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6838977932929993; training acc = 60.5\n",
      "Epoch 2 : Validation loss = 0.6928239911794662; Validation acc = 60.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6752480864524841; training acc = 68.0\n",
      "Epoch 3 : Validation loss = 0.6871270686388016; Validation acc = 58.0\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.6635028123855591; training acc = 77.5\n",
      "Epoch 4 : Validation loss = 0.6842347532510757; Validation acc = 57.0\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.6582738757133484; training acc = 73.5\n",
      "Epoch 5 : Validation loss = 0.6810357868671417; Validation acc = 58.0\n",
      "Epoch 6:\n",
      "Batch 0 : training loss = 0.6477875709533691; training acc = 76.0\n",
      "Epoch 6 : Validation loss = 0.676007091999054; Validation acc = 63.0\n",
      "Epoch 7:\n",
      "Batch 0 : training loss = 0.6352702975273132; training acc = 77.5\n",
      "Epoch 7 : Validation loss = 0.6720030754804611; Validation acc = 64.0\n",
      "Epoch 8:\n",
      "Batch 0 : training loss = 0.6258878111839294; training acc = 76.0\n",
      "Epoch 8 : Validation loss = 0.6645130813121796; Validation acc = 65.0\n",
      "Epoch 9:\n",
      "Batch 0 : training loss = 0.6006753444671631; training acc = 79.5\n",
      "Epoch 9 : Validation loss = 0.6587312519550323; Validation acc = 66.0\n",
      "Epoch 10:\n",
      "Batch 0 : training loss = 0.5933499932289124; training acc = 79.5\n",
      "Epoch 10 : Validation loss = 0.653842493891716; Validation acc = 60.0\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6941814422607422; training acc = 49.5\n",
      "Epoch 1 : Validation loss = 0.6905287355184555; Validation acc = 54.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6892861723899841; training acc = 55.0\n",
      "Epoch 2 : Validation loss = 0.6878812164068222; Validation acc = 57.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6885550022125244; training acc = 55.0\n",
      "Epoch 3 : Validation loss = 0.6854811161756516; Validation acc = 65.0\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.6866689920425415; training acc = 60.0\n",
      "Epoch 4 : Validation loss = 0.6840327829122543; Validation acc = 63.0\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.6801085472106934; training acc = 67.5\n",
      "Epoch 5 : Validation loss = 0.683167114853859; Validation acc = 58.0\n",
      "Epoch 6:\n",
      "Batch 0 : training loss = 0.6741572022438049; training acc = 65.5\n",
      "Epoch 6 : Validation loss = 0.6802023947238922; Validation acc = 60.0\n",
      "Epoch 7:\n",
      "Batch 0 : training loss = 0.6728933453559875; training acc = 65.0\n",
      "Epoch 7 : Validation loss = 0.6772107481956482; Validation acc = 63.0\n",
      "Epoch 8:\n",
      "Batch 0 : training loss = 0.6720497012138367; training acc = 64.0\n",
      "Epoch 8 : Validation loss = 0.6747780740261078; Validation acc = 64.0\n",
      "Epoch 9:\n",
      "Batch 0 : training loss = 0.6703588962554932; training acc = 64.0\n",
      "Epoch 9 : Validation loss = 0.6724920272827148; Validation acc = 67.0\n",
      "Epoch 10:\n",
      "Batch 0 : training loss = 0.6701769232749939; training acc = 64.5\n",
      "Epoch 10 : Validation loss = 0.6715126782655716; Validation acc = 62.0\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6907116174697876; training acc = 58.5\n",
      "Epoch 1 : Validation loss = 0.6902842372655869; Validation acc = 51.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6806450486183167; training acc = 62.5\n",
      "Epoch 2 : Validation loss = 0.6827221810817719; Validation acc = 64.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6761224865913391; training acc = 71.5\n",
      "Epoch 3 : Validation loss = 0.6780312955379486; Validation acc = 66.0\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.669443666934967; training acc = 75.5\n",
      "Epoch 4 : Validation loss = 0.6729847490787506; Validation acc = 64.0\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.652019739151001; training acc = 79.0\n",
      "Epoch 5 : Validation loss = 0.6684190183877945; Validation acc = 69.0\n",
      "Epoch 6:\n",
      "Batch 0 : training loss = 0.6485492587089539; training acc = 76.5\n",
      "Epoch 6 : Validation loss = 0.6649987548589706; Validation acc = 64.0\n",
      "Epoch 7:\n",
      "Batch 0 : training loss = 0.6305757761001587; training acc = 78.5\n",
      "Epoch 7 : Validation loss = 0.6610057651996613; Validation acc = 66.0\n",
      "Epoch 8:\n",
      "Batch 0 : training loss = 0.6179690957069397; training acc = 79.5\n",
      "Epoch 8 : Validation loss = 0.6523133516311646; Validation acc = 67.0\n",
      "Epoch 9:\n",
      "Batch 0 : training loss = 0.6016669273376465; training acc = 82.5\n",
      "Epoch 9 : Validation loss = 0.6439608037471771; Validation acc = 71.0\n",
      "Epoch 10:\n",
      "Batch 0 : training loss = 0.5731019377708435; training acc = 83.5\n",
      "Epoch 10 : Validation loss = 0.635856881737709; Validation acc = 72.0\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6970754265785217; training acc = 47.0\n",
      "Epoch 1 : Validation loss = 0.7061883956193924; Validation acc = 51.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.643333911895752; training acc = 68.0\n",
      "Epoch 2 : Validation loss = 0.7151904553174973; Validation acc = 53.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6938376426696777; training acc = 46.0\n",
      "Epoch 1 : Validation loss = 0.6850556582212448; Validation acc = 55.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6853251457214355; training acc = 56.5\n",
      "Epoch 2 : Validation loss = 0.6800889670848846; Validation acc = 56.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6417289972305298; training acc = 72.5\n",
      "Epoch 3 : Validation loss = 0.6718617677688599; Validation acc = 55.0\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.5988146066665649; training acc = 68.0\n",
      "Epoch 4 : Validation loss = 0.6902274787425995; Validation acc = 54.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.695416271686554; training acc = 45.0\n",
      "Epoch 1 : Validation loss = 0.6906538158655167; Validation acc = 49.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.660247266292572; training acc = 67.0\n",
      "Epoch 2 : Validation loss = 0.6759556978940964; Validation acc = 55.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6277207136154175; training acc = 64.0\n",
      "Epoch 3 : Validation loss = 0.6844349056482315; Validation acc = 54.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6916854381561279; training acc = 53.0\n",
      "Epoch 1 : Validation loss = 0.7486088424921036; Validation acc = 49.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.4546825885772705; training acc = 70.5\n",
      "Epoch 2 : Validation loss = 0.6728812605142593; Validation acc = 62.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.22205330431461334; training acc = 99.5\n",
      "Epoch 3 : Validation loss = 0.6688327044248581; Validation acc = 62.0\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.09928974509239197; training acc = 100.0\n",
      "Epoch 4 : Validation loss = 0.7022527754306793; Validation acc = 60.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.7571052312850952; training acc = 43.5\n",
      "Epoch 1 : Validation loss = 0.693298727273941; Validation acc = 47.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.688600480556488; training acc = 56.0\n",
      "Epoch 2 : Validation loss = 0.6933050751686096; Validation acc = 48.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.68798828125; training acc = 56.0\n",
      "Epoch 1 : Validation loss = 0.8730628490447998; Validation acc = 47.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.8353418111801147; training acc = 47.0\n",
      "Epoch 2 : Validation loss = 0.6913412660360336; Validation acc = 57.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.659751832485199; training acc = 76.5\n",
      "Epoch 3 : Validation loss = 0.7009310871362686; Validation acc = 46.0\n",
      "Early stopping.\n",
      "RUN COURANT = 2\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6920599937438965; training acc = 51.0\n",
      "Epoch 1 : Validation loss = 0.6891152858734131; Validation acc = 58.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.686665415763855; training acc = 52.5\n",
      "Epoch 2 : Validation loss = 0.6909785121679306; Validation acc = 63.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6923571825027466; training acc = 50.5\n",
      "Epoch 1 : Validation loss = 0.6904201060533524; Validation acc = 56.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6892651319503784; training acc = 54.0\n",
      "Epoch 2 : Validation loss = 0.6857058107852936; Validation acc = 60.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6859809160232544; training acc = 58.0\n",
      "Epoch 3 : Validation loss = 0.6844898462295532; Validation acc = 59.0\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.6808534860610962; training acc = 68.5\n",
      "Epoch 4 : Validation loss = 0.6828379929065704; Validation acc = 63.0\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.6770469546318054; training acc = 70.5\n",
      "Epoch 5 : Validation loss = 0.6814761012792587; Validation acc = 61.0\n",
      "Epoch 6:\n",
      "Batch 0 : training loss = 0.6773678064346313; training acc = 64.5\n",
      "Epoch 6 : Validation loss = 0.6786399334669113; Validation acc = 62.0\n",
      "Epoch 7:\n",
      "Batch 0 : training loss = 0.6756843328475952; training acc = 65.5\n",
      "Epoch 7 : Validation loss = 0.6753244549036026; Validation acc = 66.0\n",
      "Epoch 8:\n",
      "Batch 0 : training loss = 0.6729409694671631; training acc = 65.5\n",
      "Epoch 8 : Validation loss = 0.6735603511333466; Validation acc = 65.0\n",
      "Epoch 9:\n",
      "Batch 0 : training loss = 0.6759939789772034; training acc = 62.5\n",
      "Epoch 9 : Validation loss = 0.6721076667308807; Validation acc = 67.0\n",
      "Epoch 10:\n",
      "Batch 0 : training loss = 0.671785295009613; training acc = 61.0\n",
      "Epoch 10 : Validation loss = 0.670455127954483; Validation acc = 67.0\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6947181820869446; training acc = 48.5\n",
      "Epoch 1 : Validation loss = 0.6912473291158676; Validation acc = 50.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6867273449897766; training acc = 61.5\n",
      "Epoch 2 : Validation loss = 0.6858378052711487; Validation acc = 61.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6785708665847778; training acc = 71.0\n",
      "Epoch 3 : Validation loss = 0.680388554930687; Validation acc = 64.0\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.6716600060462952; training acc = 68.5\n",
      "Epoch 4 : Validation loss = 0.6768424212932587; Validation acc = 66.0\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.6562262773513794; training acc = 77.5\n",
      "Epoch 5 : Validation loss = 0.6727822422981262; Validation acc = 68.0\n",
      "Epoch 6:\n",
      "Batch 0 : training loss = 0.6525589823722839; training acc = 78.0\n",
      "Epoch 6 : Validation loss = 0.6687299609184265; Validation acc = 64.0\n",
      "Epoch 7:\n",
      "Batch 0 : training loss = 0.6427288055419922; training acc = 75.5\n",
      "Epoch 7 : Validation loss = 0.6627217531204224; Validation acc = 66.0\n",
      "Epoch 8:\n",
      "Batch 0 : training loss = 0.6285271644592285; training acc = 77.5\n",
      "Epoch 8 : Validation loss = 0.654875636100769; Validation acc = 70.0\n",
      "Epoch 9:\n",
      "Batch 0 : training loss = 0.611561119556427; training acc = 78.5\n",
      "Epoch 9 : Validation loss = 0.6480670124292374; Validation acc = 70.0\n",
      "Epoch 10:\n",
      "Batch 0 : training loss = 0.5870815515518188; training acc = 84.5\n",
      "Epoch 10 : Validation loss = 0.6415545791387558; Validation acc = 68.0\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6960699558258057; training acc = 48.5\n",
      "Epoch 1 : Validation loss = 0.7081891000270844; Validation acc = 45.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6234473586082458; training acc = 73.0\n",
      "Epoch 2 : Validation loss = 0.7266829758882523; Validation acc = 45.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6940624117851257; training acc = 48.0\n",
      "Epoch 1 : Validation loss = 0.6864763647317886; Validation acc = 51.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6725181341171265; training acc = 61.0\n",
      "Epoch 2 : Validation loss = 0.6919907182455063; Validation acc = 56.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6925879120826721; training acc = 51.5\n",
      "Epoch 1 : Validation loss = 0.6877790093421936; Validation acc = 55.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6735288500785828; training acc = 56.5\n",
      "Epoch 2 : Validation loss = 0.6901426613330841; Validation acc = 55.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.8207451105117798; training acc = 52.5\n",
      "Epoch 1 : Validation loss = 1.0590888410806656; Validation acc = 53.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.767662525177002; training acc = 54.5\n",
      "Epoch 2 : Validation loss = 1.0096698254346848; Validation acc = 48.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.44513487815856934; training acc = 72.0\n",
      "Epoch 3 : Validation loss = 0.7533752024173737; Validation acc = 54.0\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.2427213042974472; training acc = 95.0\n",
      "Epoch 4 : Validation loss = 0.7053947150707245; Validation acc = 53.0\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.10460127145051956; training acc = 100.0\n",
      "Epoch 5 : Validation loss = 0.9238155335187912; Validation acc = 50.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6900461316108704; training acc = 52.0\n",
      "Epoch 1 : Validation loss = 0.6477765589952469; Validation acc = 63.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.5511981248855591; training acc = 87.0\n",
      "Epoch 2 : Validation loss = 0.614028811454773; Validation acc = 68.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.423196405172348; training acc = 95.0\n",
      "Epoch 3 : Validation loss = 0.5971199199557304; Validation acc = 70.0\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.36981773376464844; training acc = 93.0\n",
      "Epoch 4 : Validation loss = 0.5782788470387459; Validation acc = 75.0\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.25303831696510315; training acc = 99.0\n",
      "Epoch 5 : Validation loss = 0.5729206576943398; Validation acc = 70.0\n",
      "Epoch 6:\n",
      "Batch 0 : training loss = 0.1755649596452713; training acc = 99.5\n",
      "Epoch 6 : Validation loss = 0.5369524955749512; Validation acc = 77.0\n",
      "Epoch 7:\n",
      "Batch 0 : training loss = 0.11127031594514847; training acc = 100.0\n",
      "Epoch 7 : Validation loss = 0.5333837792277336; Validation acc = 79.0\n",
      "Epoch 8:\n",
      "Batch 0 : training loss = 0.07892078161239624; training acc = 100.0\n",
      "Epoch 8 : Validation loss = 0.5411751568317413; Validation acc = 73.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.7112163305282593; training acc = 51.5\n",
      "Epoch 1 : Validation loss = 0.6934444457292557; Validation acc = 49.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6896594762802124; training acc = 52.5\n",
      "Epoch 2 : Validation loss = 0.6943647265434265; Validation acc = 44.0\n",
      "Early stopping.\n",
      "RUN COURANT = 2\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6987144351005554; training acc = 45.5\n",
      "Epoch 1 : Validation loss = 0.7005756497383118; Validation acc = 52.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6857834458351135; training acc = 52.0\n",
      "Epoch 2 : Validation loss = 0.7017767876386642; Validation acc = 56.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6918939352035522; training acc = 57.5\n",
      "Epoch 1 : Validation loss = 0.6920033544301987; Validation acc = 49.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6878959536552429; training acc = 56.5\n",
      "Epoch 2 : Validation loss = 0.6874745935201645; Validation acc = 60.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6863684058189392; training acc = 62.5\n",
      "Epoch 3 : Validation loss = 0.6862746030092239; Validation acc = 58.0\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.6848811507225037; training acc = 61.0\n",
      "Epoch 4 : Validation loss = 0.685060054063797; Validation acc = 57.0\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.6778014898300171; training acc = 69.0\n",
      "Epoch 5 : Validation loss = 0.6835291087627411; Validation acc = 57.0\n",
      "Epoch 6:\n",
      "Batch 0 : training loss = 0.6760894656181335; training acc = 67.0\n",
      "Epoch 6 : Validation loss = 0.681670755147934; Validation acc = 57.0\n",
      "Epoch 7:\n",
      "Batch 0 : training loss = 0.6815863251686096; training acc = 62.0\n",
      "Epoch 7 : Validation loss = 0.6804597824811935; Validation acc = 56.0\n",
      "Epoch 8:\n",
      "Batch 0 : training loss = 0.6719210743904114; training acc = 62.0\n",
      "Epoch 8 : Validation loss = 0.677421435713768; Validation acc = 63.0\n",
      "Epoch 9:\n",
      "Batch 0 : training loss = 0.6755984425544739; training acc = 62.5\n",
      "Epoch 9 : Validation loss = 0.6756207346916199; Validation acc = 63.0\n",
      "Epoch 10:\n",
      "Batch 0 : training loss = 0.6683408617973328; training acc = 65.5\n",
      "Epoch 10 : Validation loss = 0.6743984073400497; Validation acc = 63.0\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6925594210624695; training acc = 55.0\n",
      "Epoch 1 : Validation loss = 0.6902282387018204; Validation acc = 54.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6879115104675293; training acc = 57.5\n",
      "Epoch 2 : Validation loss = 0.6837475299835205; Validation acc = 62.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6809018850326538; training acc = 64.0\n",
      "Epoch 3 : Validation loss = 0.6799757778644562; Validation acc = 64.0\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.6726600527763367; training acc = 66.5\n",
      "Epoch 4 : Validation loss = 0.676448404788971; Validation acc = 66.0\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.6680474877357483; training acc = 71.0\n",
      "Epoch 5 : Validation loss = 0.6740406006574631; Validation acc = 60.0\n",
      "Epoch 6:\n",
      "Batch 0 : training loss = 0.6625165343284607; training acc = 66.0\n",
      "Epoch 6 : Validation loss = 0.6683186888694763; Validation acc = 67.0\n",
      "Epoch 7:\n",
      "Batch 0 : training loss = 0.6534374356269836; training acc = 65.5\n",
      "Epoch 7 : Validation loss = 0.6620524674654007; Validation acc = 67.0\n",
      "Epoch 8:\n",
      "Batch 0 : training loss = 0.6321947574615479; training acc = 73.0\n",
      "Epoch 8 : Validation loss = 0.6567134857177734; Validation acc = 68.0\n",
      "Epoch 9:\n",
      "Batch 0 : training loss = 0.6179825663566589; training acc = 76.0\n",
      "Epoch 9 : Validation loss = 0.6515053808689117; Validation acc = 66.0\n",
      "Epoch 10:\n",
      "Batch 0 : training loss = 0.6091547012329102; training acc = 76.0\n",
      "Epoch 10 : Validation loss = 0.6453573554754257; Validation acc = 67.0\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6934673190116882; training acc = 54.0\n",
      "Epoch 1 : Validation loss = 0.6980677545070648; Validation acc = 51.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6429600715637207; training acc = 69.5\n",
      "Epoch 2 : Validation loss = 0.7057590186595917; Validation acc = 51.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6936714053153992; training acc = 50.5\n",
      "Epoch 1 : Validation loss = 0.6956227570772171; Validation acc = 49.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.668220043182373; training acc = 65.0\n",
      "Epoch 2 : Validation loss = 0.6900415122509003; Validation acc = 57.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.655213475227356; training acc = 67.0\n",
      "Epoch 3 : Validation loss = 0.721057116985321; Validation acc = 52.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6949298977851868; training acc = 46.5\n",
      "Epoch 1 : Validation loss = 0.6927827596664429; Validation acc = 50.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.676462709903717; training acc = 60.0\n",
      "Epoch 2 : Validation loss = 0.6904957741498947; Validation acc = 57.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6598474383354187; training acc = 66.5\n",
      "Epoch 3 : Validation loss = 0.7025676965713501; Validation acc = 53.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.7460203766822815; training acc = 43.0\n",
      "Epoch 1 : Validation loss = 1.5383423864841461; Validation acc = 47.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 1.1323884725570679; training acc = 54.0\n",
      "Epoch 2 : Validation loss = 1.0944569557905197; Validation acc = 53.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6614305377006531; training acc = 57.5\n",
      "Epoch 3 : Validation loss = 0.683706745505333; Validation acc = 57.0\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.23527193069458008; training acc = 98.5\n",
      "Epoch 4 : Validation loss = 0.7841366827487946; Validation acc = 49.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6949120163917542; training acc = 49.0\n",
      "Epoch 1 : Validation loss = 0.7373535335063934; Validation acc = 47.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6624884009361267; training acc = 54.0\n",
      "Epoch 2 : Validation loss = 0.6934055984020233; Validation acc = 47.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6798335313796997; training acc = 53.5\n",
      "Epoch 3 : Validation loss = 0.6856898218393326; Validation acc = 52.0\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.6631761789321899; training acc = 68.5\n",
      "Epoch 4 : Validation loss = 0.6760169714689255; Validation acc = 70.0\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.641201913356781; training acc = 78.0\n",
      "Epoch 5 : Validation loss = 0.6672616451978683; Validation acc = 59.0\n",
      "Epoch 6:\n",
      "Batch 0 : training loss = 0.5836219787597656; training acc = 82.5\n",
      "Epoch 6 : Validation loss = 0.6464108228683472; Validation acc = 70.0\n",
      "Epoch 7:\n",
      "Batch 0 : training loss = 0.5412802696228027; training acc = 84.0\n",
      "Epoch 7 : Validation loss = 0.6407889872789383; Validation acc = 65.0\n",
      "Epoch 8:\n",
      "Batch 0 : training loss = 0.45285704731941223; training acc = 92.5\n",
      "Epoch 8 : Validation loss = 0.6160994470119476; Validation acc = 69.0\n",
      "Epoch 9:\n",
      "Batch 0 : training loss = 0.3872261941432953; training acc = 95.0\n",
      "Epoch 9 : Validation loss = 0.6033272594213486; Validation acc = 70.0\n",
      "Epoch 10:\n",
      "Batch 0 : training loss = 0.3196970224380493; training acc = 95.5\n",
      "Epoch 10 : Validation loss = 0.6023210436105728; Validation acc = 71.0\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.7037631869316101; training acc = 48.5\n",
      "Epoch 1 : Validation loss = 0.71622733771801; Validation acc = 47.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6827382445335388; training acc = 54.5\n",
      "Epoch 2 : Validation loss = 0.700313538312912; Validation acc = 47.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6674015522003174; training acc = 56.0\n",
      "Epoch 3 : Validation loss = 0.7054947465658188; Validation acc = 46.0\n",
      "Early stopping.\n",
      "RUN COURANT = 2\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6949222087860107; training acc = 47.5\n",
      "Epoch 1 : Validation loss = 0.6955507546663284; Validation acc = 54.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6816641092300415; training acc = 59.0\n",
      "Epoch 2 : Validation loss = 0.6946846097707748; Validation acc = 57.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6785091161727905; training acc = 64.0\n",
      "Epoch 3 : Validation loss = 0.6907527446746826; Validation acc = 58.0\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.6630682349205017; training acc = 64.0\n",
      "Epoch 4 : Validation loss = 0.687716007232666; Validation acc = 61.0\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.6622652411460876; training acc = 68.5\n",
      "Epoch 5 : Validation loss = 0.6830811053514481; Validation acc = 60.0\n",
      "Epoch 6:\n",
      "Batch 0 : training loss = 0.6565957069396973; training acc = 72.5\n",
      "Epoch 6 : Validation loss = 0.6798594892024994; Validation acc = 62.0\n",
      "Epoch 7:\n",
      "Batch 0 : training loss = 0.6631436944007874; training acc = 64.5\n",
      "Epoch 7 : Validation loss = 0.6771025210618973; Validation acc = 64.0\n",
      "Epoch 8:\n",
      "Batch 0 : training loss = 0.6459284424781799; training acc = 71.5\n",
      "Epoch 8 : Validation loss = 0.6725124418735504; Validation acc = 62.0\n",
      "Epoch 9:\n",
      "Batch 0 : training loss = 0.6468383073806763; training acc = 71.0\n",
      "Epoch 9 : Validation loss = 0.6700459420681; Validation acc = 64.0\n",
      "Epoch 10:\n",
      "Batch 0 : training loss = 0.6246697306632996; training acc = 74.0\n",
      "Epoch 10 : Validation loss = 0.6663558930158615; Validation acc = 64.0\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.7035806775093079; training acc = 45.0\n",
      "Epoch 1 : Validation loss = 0.6912860125303268; Validation acc = 61.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.692007839679718; training acc = 53.5\n",
      "Epoch 2 : Validation loss = 0.689404085278511; Validation acc = 57.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6903274655342102; training acc = 55.5\n",
      "Epoch 3 : Validation loss = 0.6886267960071564; Validation acc = 60.0\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.6888878345489502; training acc = 61.5\n",
      "Epoch 4 : Validation loss = 0.6887108683586121; Validation acc = 57.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.69292151927948; training acc = 51.5\n",
      "Epoch 1 : Validation loss = 0.6886544674634933; Validation acc = 57.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6846216320991516; training acc = 67.5\n",
      "Epoch 2 : Validation loss = 0.6846005916595459; Validation acc = 53.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6914960741996765; training acc = 44.5\n",
      "Epoch 3 : Validation loss = 0.6831104904413223; Validation acc = 61.0\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.6770313382148743; training acc = 67.5\n",
      "Epoch 4 : Validation loss = 0.6818301975727081; Validation acc = 60.0\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.6736446619033813; training acc = 66.0\n",
      "Epoch 5 : Validation loss = 0.6801636070013046; Validation acc = 54.0\n",
      "Epoch 6:\n",
      "Batch 0 : training loss = 0.6695286631584167; training acc = 67.0\n",
      "Epoch 6 : Validation loss = 0.6760780811309814; Validation acc = 60.0\n",
      "Epoch 7:\n",
      "Batch 0 : training loss = 0.6607334613800049; training acc = 72.5\n",
      "Epoch 7 : Validation loss = 0.6718285083770752; Validation acc = 63.0\n",
      "Epoch 8:\n",
      "Batch 0 : training loss = 0.6559115052223206; training acc = 66.0\n",
      "Epoch 8 : Validation loss = 0.6664236485958099; Validation acc = 66.0\n",
      "Epoch 9:\n",
      "Batch 0 : training loss = 0.6473962664604187; training acc = 67.5\n",
      "Epoch 9 : Validation loss = 0.6616284549236298; Validation acc = 67.0\n",
      "Epoch 10:\n",
      "Batch 0 : training loss = 0.6268367171287537; training acc = 76.5\n",
      "Epoch 10 : Validation loss = 0.6574122309684753; Validation acc = 66.0\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6897326111793518; training acc = 53.5\n",
      "Epoch 1 : Validation loss = 0.7194868475198746; Validation acc = 48.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6582690477371216; training acc = 63.0\n",
      "Epoch 2 : Validation loss = 0.7074291110038757; Validation acc = 49.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.5968432426452637; training acc = 75.5\n",
      "Epoch 3 : Validation loss = 0.7275036573410034; Validation acc = 48.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6926214694976807; training acc = 49.0\n",
      "Epoch 1 : Validation loss = 0.6888532340526581; Validation acc = 54.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6695589423179626; training acc = 57.0\n",
      "Epoch 2 : Validation loss = 0.7028345167636871; Validation acc = 49.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6935103535652161; training acc = 48.5\n",
      "Epoch 1 : Validation loss = 0.6965645998716354; Validation acc = 50.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6736384630203247; training acc = 56.5\n",
      "Epoch 2 : Validation loss = 0.6865321695804596; Validation acc = 58.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6302204132080078; training acc = 70.0\n",
      "Epoch 3 : Validation loss = 0.6957414299249649; Validation acc = 58.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.8875961303710938; training acc = 42.0\n",
      "Epoch 1 : Validation loss = 0.9855077862739563; Validation acc = 55.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6944558024406433; training acc = 62.5\n",
      "Epoch 2 : Validation loss = 0.7257793098688126; Validation acc = 57.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.5676947236061096; training acc = 68.5\n",
      "Epoch 3 : Validation loss = 0.7575549483299255; Validation acc = 56.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6931064128875732; training acc = 54.0\n",
      "Epoch 1 : Validation loss = 0.679186537861824; Validation acc = 58.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6383621692657471; training acc = 80.5\n",
      "Epoch 2 : Validation loss = 0.7286579459905624; Validation acc = 47.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6930727362632751; training acc = 50.5\n",
      "Epoch 1 : Validation loss = 0.7275176644325256; Validation acc = 53.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.7461063861846924; training acc = 47.5\n",
      "Epoch 2 : Validation loss = 0.690651148557663; Validation acc = 51.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6811419725418091; training acc = 68.5\n",
      "Epoch 3 : Validation loss = 0.6806107461452484; Validation acc = 63.0\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.6687045097351074; training acc = 60.5\n",
      "Epoch 4 : Validation loss = 0.6712695509195328; Validation acc = 54.0\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.6360700130462646; training acc = 57.0\n",
      "Epoch 5 : Validation loss = 0.6700946539640427; Validation acc = 56.0\n",
      "Epoch 6:\n",
      "Batch 0 : training loss = 0.6199297904968262; training acc = 62.5\n",
      "Epoch 6 : Validation loss = 0.6572760492563248; Validation acc = 59.0\n",
      "Epoch 7:\n",
      "Batch 0 : training loss = 0.6014668941497803; training acc = 66.5\n",
      "Epoch 7 : Validation loss = 0.6459317952394485; Validation acc = 60.0\n",
      "Epoch 8:\n",
      "Batch 0 : training loss = 0.526319682598114; training acc = 80.5\n",
      "Epoch 8 : Validation loss = 0.6315188854932785; Validation acc = 60.0\n",
      "Epoch 9:\n",
      "Batch 0 : training loss = 0.49583661556243896; training acc = 86.0\n",
      "Epoch 9 : Validation loss = 0.6084224134683609; Validation acc = 64.0\n",
      "Epoch 10:\n",
      "Batch 0 : training loss = 0.43605363368988037; training acc = 92.0\n",
      "Epoch 10 : Validation loss = 0.5940508395433426; Validation acc = 70.0\n",
      "RUN COURANT = 2\n",
      "RUN COURANT = 2\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6916798949241638; training acc = 51.0\n",
      "Epoch 1 : Validation loss = 0.6927045658230782; Validation acc = 51.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6855839490890503; training acc = 56.5\n",
      "Epoch 2 : Validation loss = 0.6840576380491257; Validation acc = 58.5\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.659929096698761; training acc = 71.0\n",
      "Epoch 3 : Validation loss = 0.6743261441588402; Validation acc = 57.5\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.6375538110733032; training acc = 78.5\n",
      "Epoch 4 : Validation loss = 0.6669923886656761; Validation acc = 62.5\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.6277654767036438; training acc = 77.0\n",
      "Epoch 5 : Validation loss = 0.657151110470295; Validation acc = 64.0\n",
      "Epoch 6:\n",
      "Batch 0 : training loss = 0.5951758027076721; training acc = 82.5\n",
      "Epoch 6 : Validation loss = 0.6445130780339241; Validation acc = 64.0\n",
      "Epoch 7:\n",
      "Batch 0 : training loss = 0.553098738193512; training acc = 83.5\n",
      "Epoch 7 : Validation loss = 0.6288378164172173; Validation acc = 66.5\n",
      "Epoch 8:\n",
      "Batch 0 : training loss = 0.5308094620704651; training acc = 85.5\n",
      "Epoch 8 : Validation loss = 0.6135078370571136; Validation acc = 67.5\n",
      "Epoch 9:\n",
      "Batch 0 : training loss = 0.48916471004486084; training acc = 88.5\n",
      "Epoch 9 : Validation loss = 0.5983123704791069; Validation acc = 67.5\n",
      "Epoch 10:\n",
      "Batch 0 : training loss = 0.46386435627937317; training acc = 86.5\n",
      "Epoch 10 : Validation loss = 0.5787921994924545; Validation acc = 71.0\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.7151892185211182; training acc = 45.0\n",
      "Epoch 1 : Validation loss = 0.6870318651199341; Validation acc = 57.5\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6899304986000061; training acc = 53.5\n",
      "Epoch 2 : Validation loss = 0.6856439858675003; Validation acc = 61.5\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6815367937088013; training acc = 70.0\n",
      "Epoch 3 : Validation loss = 0.6823053285479546; Validation acc = 60.5\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.6788250207901001; training acc = 62.0\n",
      "Epoch 4 : Validation loss = 0.6767944842576981; Validation acc = 66.0\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.6758405566215515; training acc = 66.5\n",
      "Epoch 5 : Validation loss = 0.6731526851654053; Validation acc = 66.0\n",
      "Epoch 6:\n",
      "Batch 0 : training loss = 0.664570689201355; training acc = 67.0\n",
      "Epoch 6 : Validation loss = 0.6696803718805313; Validation acc = 65.5\n",
      "Epoch 7:\n",
      "Batch 0 : training loss = 0.669330358505249; training acc = 65.5\n",
      "Epoch 7 : Validation loss = 0.6683274656534195; Validation acc = 60.0\n",
      "Epoch 8:\n",
      "Batch 0 : training loss = 0.6666052937507629; training acc = 68.0\n",
      "Epoch 8 : Validation loss = 0.6622216701507568; Validation acc = 67.5\n",
      "Epoch 9:\n",
      "Batch 0 : training loss = 0.6614036560058594; training acc = 64.0\n",
      "Epoch 9 : Validation loss = 0.6583132222294807; Validation acc = 69.0\n",
      "Epoch 10:\n",
      "Batch 0 : training loss = 0.654723048210144; training acc = 68.0\n",
      "Epoch 10 : Validation loss = 0.6582312285900116; Validation acc = 63.5\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6988576650619507; training acc = 44.0\n",
      "Epoch 1 : Validation loss = 0.6881326213479042; Validation acc = 51.5\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.678703784942627; training acc = 62.5\n",
      "Epoch 2 : Validation loss = 0.6745868250727654; Validation acc = 69.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6660012602806091; training acc = 74.0\n",
      "Epoch 3 : Validation loss = 0.6651482060551643; Validation acc = 73.0\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.6423650979995728; training acc = 81.5\n",
      "Epoch 4 : Validation loss = 0.651261493563652; Validation acc = 74.5\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.606813907623291; training acc = 86.5\n",
      "Epoch 5 : Validation loss = 0.6348419263958931; Validation acc = 75.5\n",
      "Epoch 6:\n",
      "Batch 0 : training loss = 0.5655173659324646; training acc = 87.5\n",
      "Epoch 6 : Validation loss = 0.6145709306001663; Validation acc = 75.5\n",
      "Epoch 7:\n",
      "Batch 0 : training loss = 0.512965202331543; training acc = 87.0\n",
      "Epoch 7 : Validation loss = 0.5925274267792702; Validation acc = 76.5\n",
      "Epoch 8:\n",
      "Batch 0 : training loss = 0.48681625723838806; training acc = 88.0\n",
      "Epoch 8 : Validation loss = 0.5697266533970833; Validation acc = 77.0\n",
      "Epoch 9:\n",
      "Batch 0 : training loss = 0.4177370071411133; training acc = 92.0\n",
      "Epoch 9 : Validation loss = 0.5457878038287163; Validation acc = 77.5\n",
      "Epoch 10:\n",
      "Batch 0 : training loss = 0.3493303954601288; training acc = 96.0\n",
      "Epoch 10 : Validation loss = 0.5271295346319675; Validation acc = 76.5\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.693897545337677; training acc = 50.0\n",
      "Epoch 1 : Validation loss = 0.6849713623523712; Validation acc = 54.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6514492034912109; training acc = 67.0\n",
      "Epoch 2 : Validation loss = 0.736332081258297; Validation acc = 58.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6874732971191406; training acc = 57.5\n",
      "Epoch 1 : Validation loss = 0.6896837875247002; Validation acc = 57.5\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6836207509040833; training acc = 61.0\n",
      "Epoch 2 : Validation loss = 0.6647134125232697; Validation acc = 61.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6473662853240967; training acc = 63.5\n",
      "Epoch 3 : Validation loss = 0.6744095459580421; Validation acc = 58.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6945814490318298; training acc = 46.5\n",
      "Epoch 1 : Validation loss = 0.6523565500974655; Validation acc = 62.5\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.5934962630271912; training acc = 76.0\n",
      "Epoch 2 : Validation loss = 0.686010405421257; Validation acc = 56.5\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.7158376574516296; training acc = 52.0\n",
      "Epoch 1 : Validation loss = 0.6753357276320457; Validation acc = 59.5\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.29613929986953735; training acc = 95.0\n",
      "Epoch 2 : Validation loss = 0.652648851275444; Validation acc = 57.5\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.10784238576889038; training acc = 100.0\n",
      "Epoch 3 : Validation loss = 0.6665651202201843; Validation acc = 57.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6947953104972839; training acc = 45.0\n",
      "Epoch 1 : Validation loss = 0.6741360798478127; Validation acc = 55.5\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6641625165939331; training acc = 52.5\n",
      "Epoch 2 : Validation loss = 0.6652869284152985; Validation acc = 57.5\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.5991923809051514; training acc = 77.5\n",
      "Epoch 3 : Validation loss = 0.61563491076231; Validation acc = 70.5\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.49921905994415283; training acc = 86.5\n",
      "Epoch 4 : Validation loss = 0.5814866498112679; Validation acc = 71.0\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.41077888011932373; training acc = 88.5\n",
      "Epoch 5 : Validation loss = 0.5595212504267693; Validation acc = 72.5\n",
      "Epoch 6:\n",
      "Batch 0 : training loss = 0.33947449922561646; training acc = 92.0\n",
      "Epoch 6 : Validation loss = 0.543424230068922; Validation acc = 73.0\n",
      "Epoch 7:\n",
      "Batch 0 : training loss = 0.26716506481170654; training acc = 93.0\n",
      "Epoch 7 : Validation loss = 0.5311860889196396; Validation acc = 75.5\n",
      "Epoch 8:\n",
      "Batch 0 : training loss = 0.19764557480812073; training acc = 98.5\n",
      "Epoch 8 : Validation loss = 0.5259081497788429; Validation acc = 76.5\n",
      "Epoch 9:\n",
      "Batch 0 : training loss = 0.14331644773483276; training acc = 100.0\n",
      "Epoch 9 : Validation loss = 0.5234417803585529; Validation acc = 75.5\n",
      "Epoch 10:\n",
      "Batch 0 : training loss = 0.08133180439472198; training acc = 100.0\n",
      "Epoch 10 : Validation loss = 0.523900780826807; Validation acc = 75.5\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.7083445191383362; training acc = 47.0\n",
      "Epoch 1 : Validation loss = 0.6981284320354462; Validation acc = 43.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6894248723983765; training acc = 52.0\n",
      "Epoch 2 : Validation loss = 0.6990891471505165; Validation acc = 45.0\n",
      "Early stopping.\n",
      "RUN COURANT = 2\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.694347620010376; training acc = 51.5\n",
      "Epoch 1 : Validation loss = 0.6854064390063286; Validation acc = 60.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6879897117614746; training acc = 57.0\n",
      "Epoch 2 : Validation loss = 0.6812617406249046; Validation acc = 61.5\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6702077984809875; training acc = 66.0\n",
      "Epoch 3 : Validation loss = 0.6725118532776833; Validation acc = 65.0\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.6463356614112854; training acc = 72.5\n",
      "Epoch 4 : Validation loss = 0.6614627987146378; Validation acc = 66.0\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.6405676007270813; training acc = 67.0\n",
      "Epoch 5 : Validation loss = 0.650441586971283; Validation acc = 69.5\n",
      "Epoch 6:\n",
      "Batch 0 : training loss = 0.6124193072319031; training acc = 78.5\n",
      "Epoch 6 : Validation loss = 0.6379043683409691; Validation acc = 70.5\n",
      "Epoch 7:\n",
      "Batch 0 : training loss = 0.5839143991470337; training acc = 81.0\n",
      "Epoch 7 : Validation loss = 0.6204987689852715; Validation acc = 71.5\n",
      "Epoch 8:\n",
      "Batch 0 : training loss = 0.5453634858131409; training acc = 83.5\n",
      "Epoch 8 : Validation loss = 0.6071610897779465; Validation acc = 72.5\n",
      "Epoch 9:\n",
      "Batch 0 : training loss = 0.5135524868965149; training acc = 86.0\n",
      "Epoch 9 : Validation loss = 0.5872157588601112; Validation acc = 73.0\n",
      "Epoch 10:\n",
      "Batch 0 : training loss = 0.45082566142082214; training acc = 91.5\n",
      "Epoch 10 : Validation loss = 0.5679914578795433; Validation acc = 75.0\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6919910907745361; training acc = 51.5\n",
      "Epoch 1 : Validation loss = 0.6865449622273445; Validation acc = 55.5\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6833112835884094; training acc = 61.0\n",
      "Epoch 2 : Validation loss = 0.6882387921214104; Validation acc = 54.5\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6933943033218384; training acc = 50.5\n",
      "Epoch 1 : Validation loss = 0.682964414358139; Validation acc = 67.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6802372932434082; training acc = 66.5\n",
      "Epoch 2 : Validation loss = 0.6744667515158653; Validation acc = 68.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6603646874427795; training acc = 75.0\n",
      "Epoch 3 : Validation loss = 0.6616933271288872; Validation acc = 68.5\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.6429628729820251; training acc = 75.5\n",
      "Epoch 4 : Validation loss = 0.6516589000821114; Validation acc = 69.5\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.616946816444397; training acc = 78.0\n",
      "Epoch 5 : Validation loss = 0.6353737637400627; Validation acc = 72.0\n",
      "Epoch 6:\n",
      "Batch 0 : training loss = 0.5897768139839172; training acc = 80.5\n",
      "Epoch 6 : Validation loss = 0.6143753305077553; Validation acc = 73.0\n",
      "Epoch 7:\n",
      "Batch 0 : training loss = 0.5389034748077393; training acc = 86.0\n",
      "Epoch 7 : Validation loss = 0.5955673679709435; Validation acc = 75.0\n",
      "Epoch 8:\n",
      "Batch 0 : training loss = 0.49747639894485474; training acc = 90.0\n",
      "Epoch 8 : Validation loss = 0.5710005983710289; Validation acc = 75.5\n",
      "Epoch 9:\n",
      "Batch 0 : training loss = 0.4562038481235504; training acc = 88.0\n",
      "Epoch 9 : Validation loss = 0.5487075746059418; Validation acc = 75.5\n",
      "Epoch 10:\n",
      "Batch 0 : training loss = 0.39067164063453674; training acc = 93.0\n",
      "Epoch 10 : Validation loss = 0.5308687798678875; Validation acc = 76.5\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6938115954399109; training acc = 49.0\n",
      "Epoch 1 : Validation loss = 0.7129329144954681; Validation acc = 50.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6410468816757202; training acc = 65.5\n",
      "Epoch 2 : Validation loss = 0.7034280002117157; Validation acc = 55.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.5538436770439148; training acc = 75.5\n",
      "Epoch 3 : Validation loss = 0.7247659265995026; Validation acc = 53.5\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6950865387916565; training acc = 48.5\n",
      "Epoch 1 : Validation loss = 0.6680912971496582; Validation acc = 61.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6690875291824341; training acc = 60.5\n",
      "Epoch 2 : Validation loss = 0.6635070294141769; Validation acc = 63.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6561195850372314; training acc = 59.5\n",
      "Epoch 3 : Validation loss = 0.681792825460434; Validation acc = 54.5\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6918784976005554; training acc = 53.5\n",
      "Epoch 1 : Validation loss = 0.676994763314724; Validation acc = 55.5\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6599903702735901; training acc = 62.5\n",
      "Epoch 2 : Validation loss = 0.6760199517011642; Validation acc = 56.5\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6274961829185486; training acc = 72.5\n",
      "Epoch 3 : Validation loss = 0.6708758845925331; Validation acc = 58.5\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.6047366261482239; training acc = 72.0\n",
      "Epoch 4 : Validation loss = 0.6614205837249756; Validation acc = 61.0\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.4890993535518646; training acc = 76.5\n",
      "Epoch 5 : Validation loss = 0.7324346229434013; Validation acc = 54.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6896601319313049; training acc = 52.5\n",
      "Epoch 1 : Validation loss = 0.6592380627989769; Validation acc = 59.5\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.2956189811229706; training acc = 97.0\n",
      "Epoch 2 : Validation loss = 0.648553267121315; Validation acc = 58.5\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.10751684010028839; training acc = 100.0\n",
      "Epoch 3 : Validation loss = 0.6335575953125954; Validation acc = 63.0\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.03832261264324188; training acc = 100.0\n",
      "Epoch 4 : Validation loss = 0.6377548724412918; Validation acc = 66.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6983282566070557; training acc = 48.0\n",
      "Epoch 1 : Validation loss = 0.6882976368069649; Validation acc = 55.5\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6854150295257568; training acc = 47.5\n",
      "Epoch 2 : Validation loss = 0.6787556931376457; Validation acc = 55.5\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6737833619117737; training acc = 50.0\n",
      "Epoch 3 : Validation loss = 0.670416921377182; Validation acc = 61.5\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.6450901031494141; training acc = 74.0\n",
      "Epoch 4 : Validation loss = 0.6585726514458656; Validation acc = 61.5\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.5960586071014404; training acc = 76.0\n",
      "Epoch 5 : Validation loss = 0.6211328208446503; Validation acc = 71.5\n",
      "Epoch 6:\n",
      "Batch 0 : training loss = 0.5106846690177917; training acc = 84.0\n",
      "Epoch 6 : Validation loss = 0.6142697483301163; Validation acc = 70.5\n",
      "Epoch 7:\n",
      "Batch 0 : training loss = 0.438690185546875; training acc = 91.0\n",
      "Epoch 7 : Validation loss = 0.6081089749932289; Validation acc = 66.5\n",
      "Epoch 8:\n",
      "Batch 0 : training loss = 0.35810256004333496; training acc = 91.5\n",
      "Epoch 8 : Validation loss = 0.6004883795976639; Validation acc = 68.0\n",
      "Epoch 9:\n",
      "Batch 0 : training loss = 0.2861194312572479; training acc = 97.0\n",
      "Epoch 9 : Validation loss = 0.5989656299352646; Validation acc = 67.5\n",
      "Epoch 10:\n",
      "Batch 0 : training loss = 0.22391386330127716; training acc = 96.0\n",
      "Epoch 10 : Validation loss = 0.593223761767149; Validation acc = 69.5\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.733176589012146; training acc = 42.5\n",
      "Epoch 1 : Validation loss = 0.7007880136370659; Validation acc = 44.5\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6931682825088501; training acc = 50.5\n",
      "Epoch 2 : Validation loss = 0.7008855119347572; Validation acc = 45.0\n",
      "Early stopping.\n",
      "RUN COURANT = 2\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6992828249931335; training acc = 47.0\n",
      "Epoch 1 : Validation loss = 0.6857530921697617; Validation acc = 60.5\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6764163374900818; training acc = 63.0\n",
      "Epoch 2 : Validation loss = 0.6827573552727699; Validation acc = 59.5\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6619053483009338; training acc = 71.5\n",
      "Epoch 3 : Validation loss = 0.6743145734071732; Validation acc = 60.5\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.6547777056694031; training acc = 71.0\n",
      "Epoch 4 : Validation loss = 0.6632694527506828; Validation acc = 64.0\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.6448579430580139; training acc = 69.0\n",
      "Epoch 5 : Validation loss = 0.6567000821232796; Validation acc = 63.5\n",
      "Epoch 6:\n",
      "Batch 0 : training loss = 0.6285197734832764; training acc = 76.5\n",
      "Epoch 6 : Validation loss = 0.6423728913068771; Validation acc = 67.0\n",
      "Epoch 7:\n",
      "Batch 0 : training loss = 0.5814865231513977; training acc = 79.0\n",
      "Epoch 7 : Validation loss = 0.6291766315698624; Validation acc = 67.0\n",
      "Epoch 8:\n",
      "Batch 0 : training loss = 0.5558193325996399; training acc = 81.5\n",
      "Epoch 8 : Validation loss = 0.6159602031111717; Validation acc = 67.5\n",
      "Epoch 9:\n",
      "Batch 0 : training loss = 0.535011351108551; training acc = 82.5\n",
      "Epoch 9 : Validation loss = 0.5991996005177498; Validation acc = 68.5\n",
      "Epoch 10:\n",
      "Batch 0 : training loss = 0.510957658290863; training acc = 87.0\n",
      "Epoch 10 : Validation loss = 0.5807362571358681; Validation acc = 69.5\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6929680705070496; training acc = 51.0\n",
      "Epoch 1 : Validation loss = 0.6854171305894852; Validation acc = 58.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.683976411819458; training acc = 59.0\n",
      "Epoch 2 : Validation loss = 0.6843225136399269; Validation acc = 61.5\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6811726093292236; training acc = 61.0\n",
      "Epoch 3 : Validation loss = 0.682142823934555; Validation acc = 58.0\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.6750084757804871; training acc = 65.0\n",
      "Epoch 4 : Validation loss = 0.6764497384428978; Validation acc = 63.5\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.6725248694419861; training acc = 65.5\n",
      "Epoch 5 : Validation loss = 0.6701918989419937; Validation acc = 67.5\n",
      "Epoch 6:\n",
      "Batch 0 : training loss = 0.658527672290802; training acc = 68.5\n",
      "Epoch 6 : Validation loss = 0.6675442084670067; Validation acc = 65.5\n",
      "Epoch 7:\n",
      "Batch 0 : training loss = 0.6553950309753418; training acc = 68.0\n",
      "Epoch 7 : Validation loss = 0.6696608141064644; Validation acc = 61.5\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6942689418792725; training acc = 52.5\n",
      "Epoch 1 : Validation loss = 0.6856643185019493; Validation acc = 60.5\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6834574341773987; training acc = 64.5\n",
      "Epoch 2 : Validation loss = 0.6766833961009979; Validation acc = 63.5\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6722995042800903; training acc = 68.0\n",
      "Epoch 3 : Validation loss = 0.6761499047279358; Validation acc = 66.0\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.6524600982666016; training acc = 74.0\n",
      "Epoch 4 : Validation loss = 0.6612242832779884; Validation acc = 69.0\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.641314685344696; training acc = 76.5\n",
      "Epoch 5 : Validation loss = 0.646008275449276; Validation acc = 70.5\n",
      "Epoch 6:\n",
      "Batch 0 : training loss = 0.6143310070037842; training acc = 81.0\n",
      "Epoch 6 : Validation loss = 0.6315991953015327; Validation acc = 73.0\n",
      "Epoch 7:\n",
      "Batch 0 : training loss = 0.5778599381446838; training acc = 82.0\n",
      "Epoch 7 : Validation loss = 0.611674502491951; Validation acc = 75.0\n",
      "Epoch 8:\n",
      "Batch 0 : training loss = 0.5396949052810669; training acc = 87.5\n",
      "Epoch 8 : Validation loss = 0.59140295535326; Validation acc = 75.5\n",
      "Epoch 9:\n",
      "Batch 0 : training loss = 0.5078290700912476; training acc = 85.5\n",
      "Epoch 9 : Validation loss = 0.5661094263195992; Validation acc = 75.5\n",
      "Epoch 10:\n",
      "Batch 0 : training loss = 0.45585310459136963; training acc = 90.0\n",
      "Epoch 10 : Validation loss = 0.5494803935289383; Validation acc = 75.0\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6947395205497742; training acc = 49.5\n",
      "Epoch 1 : Validation loss = 0.7021829634904861; Validation acc = 52.5\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6416022777557373; training acc = 68.0\n",
      "Epoch 2 : Validation loss = 0.7328395992517471; Validation acc = 56.5\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6934468150138855; training acc = 49.5\n",
      "Epoch 1 : Validation loss = 0.696809396147728; Validation acc = 47.5\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6678603291511536; training acc = 61.0\n",
      "Epoch 2 : Validation loss = 0.664157435297966; Validation acc = 57.5\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.5897424817085266; training acc = 69.5\n",
      "Epoch 3 : Validation loss = 0.6622405648231506; Validation acc = 63.0\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.6595004200935364; training acc = 61.0\n",
      "Epoch 4 : Validation loss = 0.6698009595274925; Validation acc = 60.5\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6980355978012085; training acc = 47.5\n",
      "Epoch 1 : Validation loss = 0.6820373013615608; Validation acc = 57.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6696417331695557; training acc = 64.5\n",
      "Epoch 2 : Validation loss = 0.6616473272442818; Validation acc = 62.5\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.5984527468681335; training acc = 70.5\n",
      "Epoch 3 : Validation loss = 0.6880262941122055; Validation acc = 53.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.7441389560699463; training acc = 49.0\n",
      "Epoch 1 : Validation loss = 0.7251910790801048; Validation acc = 57.5\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.49502867460250854; training acc = 74.5\n",
      "Epoch 2 : Validation loss = 0.7366995587944984; Validation acc = 58.5\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.7184568643569946; training acc = 45.5\n",
      "Epoch 1 : Validation loss = 0.6905266344547272; Validation acc = 55.5\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6861532330513; training acc = 57.5\n",
      "Epoch 2 : Validation loss = 0.6887710243463516; Validation acc = 55.5\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6827311515808105; training acc = 53.0\n",
      "Epoch 3 : Validation loss = 0.6822257936000824; Validation acc = 55.5\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.6748731136322021; training acc = 49.5\n",
      "Epoch 4 : Validation loss = 0.6666150242090225; Validation acc = 55.5\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.6696831583976746; training acc = 46.0\n",
      "Epoch 5 : Validation loss = 0.6615051180124283; Validation acc = 55.5\n",
      "Epoch 6:\n",
      "Batch 0 : training loss = 0.6302764415740967; training acc = 49.5\n",
      "Epoch 6 : Validation loss = 0.6573342084884644; Validation acc = 55.5\n",
      "Epoch 7:\n",
      "Batch 0 : training loss = 0.5763939023017883; training acc = 56.5\n",
      "Epoch 7 : Validation loss = 0.6546824425458908; Validation acc = 55.5\n",
      "Epoch 8:\n",
      "Batch 0 : training loss = 0.5574217438697815; training acc = 54.0\n",
      "Epoch 8 : Validation loss = 0.6488247290253639; Validation acc = 60.0\n",
      "Epoch 9:\n",
      "Batch 0 : training loss = 0.5177032351493835; training acc = 74.5\n",
      "Epoch 9 : Validation loss = 0.64798154681921; Validation acc = 61.0\n",
      "Epoch 10:\n",
      "Batch 0 : training loss = 0.5052108764648438; training acc = 85.5\n",
      "Epoch 10 : Validation loss = 0.6481751576066017; Validation acc = 60.5\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6920111179351807; training acc = 47.0\n",
      "Epoch 1 : Validation loss = 0.6341358944773674; Validation acc = 62.5\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.5106250643730164; training acc = 84.5\n",
      "Epoch 2 : Validation loss = 0.5525902472436428; Validation acc = 73.5\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.35157185792922974; training acc = 92.5\n",
      "Epoch 3 : Validation loss = 0.5039303340017796; Validation acc = 77.5\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.20678211748600006; training acc = 99.0\n",
      "Epoch 4 : Validation loss = 0.4887244515120983; Validation acc = 76.5\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.09957348555326462; training acc = 100.0\n",
      "Epoch 5 : Validation loss = 0.48206229135394096; Validation acc = 77.5\n",
      "Epoch 6:\n",
      "Batch 0 : training loss = 0.0459151454269886; training acc = 100.0\n",
      "Epoch 6 : Validation loss = 0.49020032957196236; Validation acc = 78.5\n",
      "Early stopping.\n",
      "RUN COURANT = 2\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6952021718025208; training acc = 50.5\n",
      "Epoch 1 : Validation loss = 0.6851774901151657; Validation acc = 57.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6717537045478821; training acc = 67.0\n",
      "Epoch 2 : Validation loss = 0.6832199841737747; Validation acc = 59.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6706511974334717; training acc = 65.0\n",
      "Epoch 3 : Validation loss = 0.6792343407869339; Validation acc = 56.5\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.6574530601501465; training acc = 69.0\n",
      "Epoch 4 : Validation loss = 0.6693679615855217; Validation acc = 61.5\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.6475236415863037; training acc = 73.5\n",
      "Epoch 5 : Validation loss = 0.6589658185839653; Validation acc = 64.5\n",
      "Epoch 6:\n",
      "Batch 0 : training loss = 0.621793806552887; training acc = 74.5\n",
      "Epoch 6 : Validation loss = 0.6533680185675621; Validation acc = 62.0\n",
      "Epoch 7:\n",
      "Batch 0 : training loss = 0.6143398880958557; training acc = 79.5\n",
      "Epoch 7 : Validation loss = 0.6410498172044754; Validation acc = 66.5\n",
      "Epoch 8:\n",
      "Batch 0 : training loss = 0.591788113117218; training acc = 82.5\n",
      "Epoch 8 : Validation loss = 0.6253556683659554; Validation acc = 68.0\n",
      "Epoch 9:\n",
      "Batch 0 : training loss = 0.5598887205123901; training acc = 81.0\n",
      "Epoch 9 : Validation loss = 0.6152135208249092; Validation acc = 70.5\n",
      "Epoch 10:\n",
      "Batch 0 : training loss = 0.5257513523101807; training acc = 85.0\n",
      "Epoch 10 : Validation loss = 0.5994870141148567; Validation acc = 72.0\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6992573738098145; training acc = 41.0\n",
      "Epoch 1 : Validation loss = 0.6890566572546959; Validation acc = 62.5\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6893917322158813; training acc = 57.0\n",
      "Epoch 2 : Validation loss = 0.6899150907993317; Validation acc = 51.5\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6942197680473328; training acc = 50.0\n",
      "Epoch 1 : Validation loss = 0.6875016391277313; Validation acc = 56.5\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.678884744644165; training acc = 67.5\n",
      "Epoch 2 : Validation loss = 0.6767271757125854; Validation acc = 67.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6664117574691772; training acc = 68.0\n",
      "Epoch 3 : Validation loss = 0.6648947224020958; Validation acc = 67.5\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.6515094041824341; training acc = 72.5\n",
      "Epoch 4 : Validation loss = 0.6539626643061638; Validation acc = 68.5\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.62977135181427; training acc = 74.0\n",
      "Epoch 5 : Validation loss = 0.6388310194015503; Validation acc = 69.0\n",
      "Epoch 6:\n",
      "Batch 0 : training loss = 0.5997205972671509; training acc = 77.0\n",
      "Epoch 6 : Validation loss = 0.6204450130462646; Validation acc = 73.0\n",
      "Epoch 7:\n",
      "Batch 0 : training loss = 0.5591745972633362; training acc = 81.0\n",
      "Epoch 7 : Validation loss = 0.6017769649624825; Validation acc = 74.5\n",
      "Epoch 8:\n",
      "Batch 0 : training loss = 0.5202529430389404; training acc = 87.0\n",
      "Epoch 8 : Validation loss = 0.5806499570608139; Validation acc = 74.0\n",
      "Epoch 9:\n",
      "Batch 0 : training loss = 0.4792466461658478; training acc = 87.0\n",
      "Epoch 9 : Validation loss = 0.5588769167661667; Validation acc = 74.5\n",
      "Epoch 10:\n",
      "Batch 0 : training loss = 0.4533739984035492; training acc = 88.0\n",
      "Epoch 10 : Validation loss = 0.5378900691866875; Validation acc = 75.5\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6878043413162231; training acc = 57.0\n",
      "Epoch 1 : Validation loss = 0.688123382627964; Validation acc = 54.5\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6610353589057922; training acc = 62.5\n",
      "Epoch 2 : Validation loss = 0.7016385495662689; Validation acc = 52.5\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6918284893035889; training acc = 52.5\n",
      "Epoch 1 : Validation loss = 0.6860602870583534; Validation acc = 56.5\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6775346398353577; training acc = 60.5\n",
      "Epoch 2 : Validation loss = 0.6630208641290665; Validation acc = 61.5\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6494609117507935; training acc = 63.0\n",
      "Epoch 3 : Validation loss = 0.6799964681267738; Validation acc = 56.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6934394240379333; training acc = 51.0\n",
      "Epoch 1 : Validation loss = 0.689005084335804; Validation acc = 53.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6749362349510193; training acc = 59.0\n",
      "Epoch 2 : Validation loss = 0.6780424490571022; Validation acc = 58.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6589001417160034; training acc = 64.5\n",
      "Epoch 3 : Validation loss = 0.6863437667489052; Validation acc = 55.5\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.7176658511161804; training acc = 50.5\n",
      "Epoch 1 : Validation loss = 0.7336613535881042; Validation acc = 58.5\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.46000751852989197; training acc = 74.0\n",
      "Epoch 2 : Validation loss = 0.6677857674658298; Validation acc = 64.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.2362728863954544; training acc = 94.0\n",
      "Epoch 3 : Validation loss = 0.6568420827388763; Validation acc = 67.0\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.08951150625944138; training acc = 100.0\n",
      "Epoch 4 : Validation loss = 0.6735998392105103; Validation acc = 59.0\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6956723928451538; training acc = 50.5\n",
      "Epoch 1 : Validation loss = 0.6596066951751709; Validation acc = 56.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6392525434494019; training acc = 52.5\n",
      "Epoch 2 : Validation loss = 0.6137935519218445; Validation acc = 73.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.5247659087181091; training acc = 83.5\n",
      "Epoch 3 : Validation loss = 0.5882719159126282; Validation acc = 71.5\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.4265725314617157; training acc = 90.5\n",
      "Epoch 4 : Validation loss = 0.5458863340318203; Validation acc = 74.5\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.3154746890068054; training acc = 96.5\n",
      "Epoch 5 : Validation loss = 0.5259775593876839; Validation acc = 75.5\n",
      "Epoch 6:\n",
      "Batch 0 : training loss = 0.22120054066181183; training acc = 98.0\n",
      "Epoch 6 : Validation loss = 0.5492471009492874; Validation acc = 73.5\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6941673755645752; training acc = 49.5\n",
      "Epoch 1 : Validation loss = 0.6933003142476082; Validation acc = 45.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6785141229629517; training acc = 54.0\n",
      "Epoch 2 : Validation loss = 0.6980346664786339; Validation acc = 45.0\n",
      "Early stopping.\n",
      "RUN COURANT = 2\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6977294683456421; training acc = 47.5\n",
      "Epoch 1 : Validation loss = 0.6893128827214241; Validation acc = 59.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6764646768569946; training acc = 61.5\n",
      "Epoch 2 : Validation loss = 0.6884287372231483; Validation acc = 58.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6743972897529602; training acc = 70.0\n",
      "Epoch 3 : Validation loss = 0.6788506954908371; Validation acc = 59.0\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.665814995765686; training acc = 68.0\n",
      "Epoch 4 : Validation loss = 0.6718721091747284; Validation acc = 60.0\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.660804808139801; training acc = 67.0\n",
      "Epoch 5 : Validation loss = 0.6614112481474876; Validation acc = 62.0\n",
      "Epoch 6:\n",
      "Batch 0 : training loss = 0.6407021284103394; training acc = 71.5\n",
      "Epoch 6 : Validation loss = 0.658858560025692; Validation acc = 63.0\n",
      "Epoch 7:\n",
      "Batch 0 : training loss = 0.6360235810279846; training acc = 74.0\n",
      "Epoch 7 : Validation loss = 0.645731657743454; Validation acc = 64.5\n",
      "Epoch 8:\n",
      "Batch 0 : training loss = 0.6118353009223938; training acc = 76.0\n",
      "Epoch 8 : Validation loss = 0.6311901286244392; Validation acc = 65.5\n",
      "Epoch 9:\n",
      "Batch 0 : training loss = 0.5880157947540283; training acc = 74.5\n",
      "Epoch 9 : Validation loss = 0.6231522187590599; Validation acc = 68.5\n",
      "Epoch 10:\n",
      "Batch 0 : training loss = 0.5613387823104858; training acc = 80.5\n",
      "Epoch 10 : Validation loss = 0.6035903468728065; Validation acc = 69.0\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.7000497579574585; training acc = 49.5\n",
      "Epoch 1 : Validation loss = 0.6948871612548828; Validation acc = 44.5\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6873568892478943; training acc = 56.0\n",
      "Epoch 2 : Validation loss = 0.6886742934584618; Validation acc = 61.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6844291090965271; training acc = 70.0\n",
      "Epoch 3 : Validation loss = 0.6833454370498657; Validation acc = 62.0\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.684161901473999; training acc = 64.5\n",
      "Epoch 4 : Validation loss = 0.6837705597281456; Validation acc = 60.5\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6978715658187866; training acc = 47.0\n",
      "Epoch 1 : Validation loss = 0.688591867685318; Validation acc = 59.5\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6815037727355957; training acc = 66.0\n",
      "Epoch 2 : Validation loss = 0.679663248360157; Validation acc = 66.0\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6700259447097778; training acc = 70.5\n",
      "Epoch 3 : Validation loss = 0.6712789162993431; Validation acc = 68.0\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.6575548648834229; training acc = 71.5\n",
      "Epoch 4 : Validation loss = 0.6662194430828094; Validation acc = 64.5\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.6431482434272766; training acc = 67.5\n",
      "Epoch 5 : Validation loss = 0.6472029685974121; Validation acc = 70.5\n",
      "Epoch 6:\n",
      "Batch 0 : training loss = 0.6310788989067078; training acc = 74.5\n",
      "Epoch 6 : Validation loss = 0.6378016024827957; Validation acc = 69.0\n",
      "Epoch 7:\n",
      "Batch 0 : training loss = 0.6039175391197205; training acc = 71.0\n",
      "Epoch 7 : Validation loss = 0.6173791065812111; Validation acc = 69.5\n",
      "Epoch 8:\n",
      "Batch 0 : training loss = 0.5941614508628845; training acc = 70.0\n",
      "Epoch 8 : Validation loss = 0.6007182151079178; Validation acc = 72.5\n",
      "Epoch 9:\n",
      "Batch 0 : training loss = 0.5359000563621521; training acc = 81.5\n",
      "Epoch 9 : Validation loss = 0.5864855051040649; Validation acc = 74.5\n",
      "Epoch 10:\n",
      "Batch 0 : training loss = 0.539526104927063; training acc = 79.5\n",
      "Epoch 10 : Validation loss = 0.5591381266713142; Validation acc = 73.0\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6892233490943909; training acc = 59.0\n",
      "Epoch 1 : Validation loss = 0.7186179161071777; Validation acc = 44.5\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6446176767349243; training acc = 65.5\n",
      "Epoch 2 : Validation loss = 0.7013532221317291; Validation acc = 50.5\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6237961053848267; training acc = 68.0\n",
      "Epoch 3 : Validation loss = 0.7152267023921013; Validation acc = 53.5\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6927116513252258; training acc = 47.0\n",
      "Epoch 1 : Validation loss = 0.6907057389616966; Validation acc = 55.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.665567934513092; training acc = 58.0\n",
      "Epoch 2 : Validation loss = 0.6932808086276054; Validation acc = 54.5\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6926238536834717; training acc = 49.0\n",
      "Epoch 1 : Validation loss = 0.6884541809558868; Validation acc = 55.5\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6673121452331543; training acc = 62.5\n",
      "Epoch 2 : Validation loss = 0.6797674968838692; Validation acc = 55.5\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6504122018814087; training acc = 67.0\n",
      "Epoch 3 : Validation loss = 0.6981126293540001; Validation acc = 51.5\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.7022300958633423; training acc = 50.5\n",
      "Epoch 1 : Validation loss = 0.7035596519708633; Validation acc = 51.5\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.48530006408691406; training acc = 81.0\n",
      "Epoch 2 : Validation loss = 0.6562373414635658; Validation acc = 61.5\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.24926219880580902; training acc = 99.0\n",
      "Epoch 3 : Validation loss = 0.6821090131998062; Validation acc = 57.5\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6900283694267273; training acc = 54.0\n",
      "Epoch 1 : Validation loss = 0.6819789260625839; Validation acc = 52.0\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6458960771560669; training acc = 66.0\n",
      "Epoch 2 : Validation loss = 0.6737252995371819; Validation acc = 56.5\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.6264528036117554; training acc = 70.5\n",
      "Epoch 3 : Validation loss = 0.6256649941205978; Validation acc = 69.5\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.5481020212173462; training acc = 79.5\n",
      "Epoch 4 : Validation loss = 0.5980908423662186; Validation acc = 70.5\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.44431930780410767; training acc = 90.5\n",
      "Epoch 5 : Validation loss = 0.5679217837750912; Validation acc = 74.0\n",
      "Epoch 6:\n",
      "Batch 0 : training loss = 0.37292006611824036; training acc = 90.5\n",
      "Epoch 6 : Validation loss = 0.579544436186552; Validation acc = 70.5\n",
      "Early stopping.\n",
      "Beginning training...\n",
      "Epoch 1:\n",
      "Batch 0 : training loss = 0.6926733255386353; training acc = 53.0\n",
      "Epoch 1 : Validation loss = 0.6829027086496353; Validation acc = 53.5\n",
      "Epoch 2:\n",
      "Batch 0 : training loss = 0.6360409259796143; training acc = 69.5\n",
      "Epoch 2 : Validation loss = 0.6438929885625839; Validation acc = 65.5\n",
      "Epoch 3:\n",
      "Batch 0 : training loss = 0.5310916304588318; training acc = 85.5\n",
      "Epoch 3 : Validation loss = 0.5838910341262817; Validation acc = 72.5\n",
      "Epoch 4:\n",
      "Batch 0 : training loss = 0.42888587713241577; training acc = 88.5\n",
      "Epoch 4 : Validation loss = 0.5368174389004707; Validation acc = 75.0\n",
      "Epoch 5:\n",
      "Batch 0 : training loss = 0.2648383378982544; training acc = 97.0\n",
      "Epoch 5 : Validation loss = 0.5297736972570419; Validation acc = 78.5\n",
      "Epoch 6:\n",
      "Batch 0 : training loss = 0.17386826872825623; training acc = 99.0\n",
      "Epoch 6 : Validation loss = 0.5087758786976337; Validation acc = 77.5\n",
      "Epoch 7:\n",
      "Batch 0 : training loss = 0.0866667777299881; training acc = 99.5\n",
      "Epoch 7 : Validation loss = 0.5153353959321976; Validation acc = 79.0\n",
      "Early stopping.\n"
     ]
    }
   ],
   "source": [
    "# Range for parameters\n",
    "reduction_factors = [50, 25, 12.5]\n",
    "min_frequences = [1, 3, 5, 10, 20]\n",
    "nb_runs = 3\n",
    "\n",
    "table = []\n",
    "\n",
    "# Main loop\n",
    "for run in range(nb_runs) :\n",
    "  fichier_grid = open(\"grid_search_{}.csv\".format(run), \"a\")\n",
    "  for reduction_factor in reduction_factors:\n",
    "    # Retrieve data\n",
    "    random.seed(42)\n",
    "    (train_f, train_c), (valid_f, valid_c), (test_f, test_c) = get_splits(filenames, categories, splits)\n",
    "    reduct_len_train = int(len(train_f) / reduction_factor)\n",
    "    reduct_len_valid = int(len(valid_f) / reduction_factor)\n",
    "    reduct_len_test = int(len(test_f) / reduction_factor)\n",
    "    (train_f, train_c) = (train_f[:reduct_len_train], train_c[:reduct_len_train])\n",
    "    (valid_f, valid_c) = (valid_f[:reduct_len_valid], valid_c[:reduct_len_valid])\n",
    "    (test_f, test_c) = (test_f[:reduct_len_test], test_c[:reduct_len_test])\n",
    "    data = [open(f, encoding=\"utf8\").read() for f in train_f]\n",
    "\n",
    "    # Loop over minimum frequency\n",
    "    for min_freq in min_frequences:\n",
    "      # Build dataset, splits and vocabulary\n",
    "      training_dataset = TextClassificationDataset(train_f, train_c, min_freq=min_freq, data=data)\n",
    "      training_word2idx, training_idx2word = training_dataset.get_vocab()\n",
    "\n",
    "      valid_dataset = TextClassificationDataset(valid_f, valid_c, (training_word2idx, training_idx2word))\n",
    "      test_dataset = TextClassificationDataset(test_f, test_c, (training_word2idx, training_idx2word))\n",
    "      size_voc = len(training_word2idx)\n",
    "\n",
    "      training_dataloader = DataLoader(training_dataset, batch_size=200, shuffle=True)\n",
    "      valid_dataloader = DataLoader(valid_dataset, batch_size=25)\n",
    "      test_dataloader = DataLoader(test_dataset, batch_size=25)\n",
    "\n",
    "      GloveEmbeddings = get_glove_adapted_embeddings(loaded_glove_model, training_word2idx)\n",
    "\n",
    "      ## Average Model:\n",
    "      # Without pre-training:\n",
    "      valid_acc, test_acc = trainings(\n",
    "          model_type='Average',\n",
    "          vocabulary_size=size_voc,\n",
    "          embeddings=None\n",
    "      )\n",
    "      fichier_grid.write(\" Reduction factor = {}, Min Freq = {}, Model_type = {}, Embedding = {}, Fine-tuning = {}, Valid_Acc = {}, Test_Acc = {} \\n\".format(reduction_factor, min_freq, 'Average', 'No', 'No', valid_acc, test_acc))\n",
    "      table.append([reduction_factor, min_freq, 'Average', 'No embedding', 'No fine-tuning', valid_acc, test_acc])\n",
    "      # With pre-training and without fine-tuning:\n",
    "      valid_acc, test_acc = trainings(\n",
    "          model_type='Average',\n",
    "          vocabulary_size=size_voc,\n",
    "          embeddings=GloveEmbeddings,\n",
    "          fine_tuning=False\n",
    "      )\n",
    "      fichier_grid.write(\" Reduction factor = {}, Min Freq = {}, Model_type = {}, Embedding = {}, Fine-tuning = {}, Valid_Acc = {}, Test_Acc = {} \\n\".format(reduction_factor, min_freq, 'Average', 'Yes', 'No', valid_acc, test_acc))\n",
    "      table.append([reduction_factor, min_freq, 'Average', 'GloveEmbeddings', 'No fine-tuning', valid_acc, test_acc])\n",
    "      # With pre-training and with fine-tuning:\n",
    "      valid_acc, test_acc = trainings(\n",
    "          model_type='Average',\n",
    "          vocabulary_size=size_voc,\n",
    "          embeddings=GloveEmbeddings,\n",
    "          fine_tuning=True)\n",
    "      fichier_grid.write(\" Reduction factor = {}, Min Freq = {}, Model_type = {}, Embedding = {}, Fine-tuning = {}, Valid_Acc = {}, Test_Acc = {} \\n\".format(reduction_factor, min_freq, 'Average', 'Yes', 'Yes', valid_acc, test_acc))\n",
    "      table.append([reduction_factor, min_freq, 'Average', 'GloveEmbeddings', 'Fine-tuning', valid_acc, test_acc])\n",
    "\n",
    "      ## LSTM:\n",
    "      # Without pre-training:\n",
    "      valid_acc, test_acc = trainings(\n",
    "          model_type='LSTM',\n",
    "          vocabulary_size=size_voc,\n",
    "          embeddings=None\n",
    "      )\n",
    "      fichier_grid.write(\" Reduction factor = {}, Min Freq = {}, Model_type = {}, Embedding = {}, Fine-tuning = {}, Valid_Acc = {}, Test_Acc = {} \\n\".format(reduction_factor, min_freq, 'LSTM', 'No', 'No', valid_acc, test_acc))\n",
    "      table.append([reduction_factor, min_freq, 'LSTM', 'No embedding', 'No fine-tuning', valid_acc, test_acc])\n",
    "      # With pre-training and without fine-tuning:\n",
    "      valid_acc, test_acc = trainings(\n",
    "          model_type='LSTM',\n",
    "          vocabulary_size=size_voc,\n",
    "          embeddings=GloveEmbeddings,\n",
    "          fine_tuning=False\n",
    "      )\n",
    "      fichier_grid.write(\" Reduction factor = {}, Min Freq = {}, Model_type = {}, Embedding = {}, Fine-tuning = {}, Valid_Acc = {}, Test_Acc = {} \\n\".format(reduction_factor, min_freq, 'LSTM', 'Yes', 'No', valid_acc, test_acc))\n",
    "      table.append([reduction_factor, min_freq, 'LSTM', 'GloveEmbeddings', 'No fine-tuning', valid_acc, test_acc])\n",
    "      # With pre-training and with fine-tuning:\n",
    "      valid_acc, test_acc = trainings(\n",
    "          model_type='LSTM',\n",
    "          vocabulary_size=size_voc,\n",
    "          embeddings=GloveEmbeddings,\n",
    "          fine_tuning=True)\n",
    "      fichier_grid.write(\" Reduction factor = {}, Min Freq = {}, Model_type = {}, Embedding = {}, Fine-tuning = {}, Valid_Acc = {}, Test_Acc = {} \\n\".format(reduction_factor, min_freq, 'LSTM', 'Yes', 'Yes', valid_acc, test_acc))\n",
    "      table.append([reduction_factor, min_freq, 'LSTM', 'GloveEmbeddings', 'Fine-tuning', valid_acc, test_acc])\n",
    "\n",
    "      ## CNN:\n",
    "      # Without pre-training:\n",
    "      valid_acc, test_acc = trainings(\n",
    "          model_type='CNN',\n",
    "          vocabulary_size=size_voc,\n",
    "          embeddings=None\n",
    "      )\n",
    "      fichier_grid.write(\" Reduction factor = {}, Min Freq = {}, Model_type = {}, Embedding = {}, Fine-tuning = {}, Valid_Acc = {}, Test_Acc = {} \\n\".format(reduction_factor, min_freq, 'CNN', 'No', 'No', valid_acc, test_acc))\n",
    "      table.append([reduction_factor, min_freq, 'CNN', 'No embedding', 'No fine-tuning', valid_acc, test_acc])\n",
    "      # With pre-training and without fine-tuning:\n",
    "      valid_acc, test_acc = trainings(\n",
    "          model_type='CNN',\n",
    "          vocabulary_size=size_voc,\n",
    "          embeddings=GloveEmbeddings,\n",
    "          fine_tuning=False\n",
    "      )\n",
    "      fichier_grid.write(\" Reduction factor = {}, Min Freq = {}, Model_type = {}, Embedding = {}, Fine-tuning = {}, Valid_Acc = {}, Test_Acc = {} \\n\".format(reduction_factor, min_freq, 'CNN', 'Yes', 'No', valid_acc, test_acc))\n",
    "      table.append([reduction_factor, min_freq, 'CNN', 'GloveEmbeddings', 'No fine-tuning', valid_acc, test_acc])\n",
    "      # With pre-training and with fine-tuning:\n",
    "      valid_acc, test_acc = trainings(\n",
    "          model_type='CNN',\n",
    "          vocabulary_size=size_voc,\n",
    "          embeddings=GloveEmbeddings,\n",
    "          fine_tuning=True\n",
    "      )\n",
    "      fichier_grid.write(\" Reduction factor = {}, Min Freq = {}, Model_type = {}, Embedding = {}, Fine-tuning = {}, Valid_Acc = {}, Test_Acc = {} \\n\".format(reduction_factor, min_freq, 'CNN', 'Yes', 'Yes', valid_acc, test_acc))\n",
    "      table.append([reduction_factor, min_freq, 'CNN', 'GloveEmbeddings', 'Fine-tuning', valid_acc, test_acc])\n",
    "  fichier_grid.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fOvmyRpMDGWU"
   },
   "source": [
    "## Analysis\n",
    "\n",
    "Fixed and varying parameters are detailed in previous section. For reference, here is the correspondance between tested parameters and the size of the vocabulary.\n",
    "\n",
    "*Size of the vocabulary for different min_freq and size of dataset* \n",
    "\n",
    "min_freq \\ Training samples| 400 | 800 |1600\n",
    "---------------------------|-----|-----|-----\n",
    "1                          |11177|16683|24372\n",
    "3                          |3400 |5726 |9162\n",
    "5                          |2071 |3536 |5947\n",
    "10                         |1036 |1903 |3267\n",
    "20                         |528  |1004 |1794\n",
    "\n",
    "**Note**: these values are dependent on the data samples in the dataset - depending on the split with random seed 42.\n",
    "\n",
    "### Hypotheses\n",
    "\n",
    "The Averaging models are Bag Of Words models: they do not take into account the order of the words. For example, \"... is not good\" could be interpreted as a positive review since \"good\" carry a strong positive meaning. On the contrary, LSTM can handle sequential data (and negations). CNN should also take advantage of the positions of the words. Hence, we would expect better results for LSTM models or CNN.\n",
    "\n",
    "We expect better performances - or at least a faster convergence - for models using pretrained embeddings because they are based on meaningful decomposition of words. However, the meaning of the words could fit our current task not completely. Fine-tuning should be necessary to favor the positive/negative meaning in the embeddings of the tokens.\n",
    "\n",
    "There is a trade-off to find between the size of vocabulary and the number of training samples. With more documents in the training set, there is a higher probability to find more occurences of a given word. If we insert each word we find in the vocabulary set (`min_freq`=1), there will be useless words and the computation time is higher. Conversely, we miss useful words if the `min_freq` number is too high. Some useful words may not appear frequently because they do not appear frequently in the samples and not because they are useless."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hLK83hKBDfjM"
   },
   "source": [
    "## Results\n",
    "\n",
    "For each table, we present the results as *Final Validation Accuracy \\ Testing Accuracy* rounded to the nearest tenth. The former helps selecting the best hyperparameters (in our case, the value of `min_freq`), the latter assesses the final model and its ability to generalize to new data. Following results are average accuracies over 3 runs for each model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ilQS7bkla8yP"
   },
   "source": [
    "### Averaging models\n",
    "\n",
    "*Averaging model: not-pretrained embedding* (Valid_acc \\ Test_acc)\n",
    "\n",
    "min_freq \\ Training samples| 400       | 800       | 1600     \n",
    "---------------------------|-----------|-----------|-----------\n",
    "1                          |57.3 \\ 60.7|59.7 \\ 57.7|**72.7 \\ 72.3**\n",
    "3                          |**64.7 \\ 62.0**|59.3 \\ 61.7|69.3 \\ 70.2\n",
    "5                          |56.0 \\ 57.3|59.7 \\ 60.3|72.2 \\ 71.7\n",
    "10                         |54.0 \\ 60.7|56.7 \\ 62.3|70.3 \\ 73.0\n",
    "20                         |52.7 \\ 54.7|56.7 \\ 61.0|67.8 \\ 71.3\n",
    "\n",
    "*Averaging model: pretrained embedding, without fine-tuning*\n",
    "\n",
    "min_freq \\ Training samples| 400       | 800       |1600      \n",
    "---------------------------|-----------|-----------|-----------\n",
    "1                          |56.7 \\ 62.7|**68.0 \\ 66.7**|63.5 \\ 65.5\n",
    "3                          |56.0 \\ 64.7|62.0 \\ 68.7|53.2 \\ 55.3\n",
    "5                          |54.0 \\ 59.3|58.7 \\ 61.3|**64.3 \\ 61.3**\n",
    "10                         |54.0 \\ 59.3|58.0 \\ 60.0|55.3 \\ 58.0\n",
    "20                         |56.0 \\ 60.7|56.7 \\ 63.7|58.0 \\ 60.2\n",
    "\n",
    "*Averaging model: pretrained embedding, with fine-tuning*\n",
    "\n",
    "min_freq \\ Training samples| 400       | 800       |1600      \n",
    "---------------------------|-----------|-----------|-----------\n",
    "1                          |**70.7 \\ 68.0**|68.0 \\ 67.3|76.7 \\ 77.0\n",
    "3                          |66.0 \\ 66.7|**70.0 \\ 68.7**|**77.0 \\ 77.7**\n",
    "5                          |62.7 \\ 68.7|69.3 \\ 68.7|75.8 \\ 76.8\n",
    "10                         |64.7 \\ 68.7|68.0 \\ 68.0|75.7 \\ 77.3\n",
    "20                         |60.7 \\ 69.3|60.0 \\ 61.3|73.3 \\ 75.2\n",
    "\n",
    "Globally, bigger vocabularies implies better results. The best results are found with the fine-tuned pretrained embeddings, with a maximum of 77.7% for testing accuracy. This embedding also gives the best results for the smallest datatets and is more robust even if `min_freq` is higher, which implies smaller vocabularies.\n",
    "\n",
    "The use of pretrained embeddings without fine-tuning gives the less satisfactory results here. It could mean that GloVe embedding is not adapted enough to our task, as it is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7A5oU5aUbDAI"
   },
   "source": [
    "### LSTM models\n",
    "\n",
    "*LSTM model: not-pretrained embedding* (Valid_acc \\ Test_acc)\n",
    "\n",
    "min_freq \\ Training samples| 400       | 800       |1600      \n",
    "---------------------------|-----------|-----------|-----------\n",
    "1                          |54.7 \\ 54.0|52.7 \\ 52.7|54.8 \\ 56.0\n",
    "3                          |53.3 \\ 51.3|52.0 \\ 54.3|53.5 \\ 53.8\n",
    "5                          |58.0 \\ 52.7|48.3 \\ 52.3|54.0 \\ 53.7\n",
    "10                         |54.0 \\ 49.3|49.7 \\ 50.7|51.8 \\ 52.5\n",
    "20                         |52.7 \\ 48.0|48.7 \\ 49.0|**55.2 \\ 54.2**\n",
    "\n",
    "*LSTM model: pretrained embedding, without fine-tuning*\n",
    "\n",
    "min_freq \\ Training samples| 400       | 800       |1600      \n",
    "---------------------------|-----------|-----------|-----------\n",
    "1                          |54.0 \\ 46.7|56.7 \\ 54.0|**60.0 \\ 56.5**\n",
    "3                          |55.3 \\ 41.3|54.7 \\ 54.7|56.3 \\ 50.8\n",
    "5                          |55.3 \\ 43.3|54.0 \\ 48.7|57.8 \\ 55.3\n",
    "10                         |56.0 \\ 42.7|52.7 \\ 53.7|53.8 \\ 51.2\n",
    "20                         |58.0 \\ 47.3|50.3 \\ 49.3|53.8 \\ 53.3\n",
    "\n",
    "*LSTM model: pretrained embedding, with fine-tuning*\n",
    "\n",
    "min_freq \\ Training samples| 400       | 800       |1600      \n",
    "---------------------------|-----------|-----------|-----------\n",
    "1                          |61.3 \\ 43.3|55.0 \\ 52.0|**56.2 \\ 50.8**\n",
    "3                          |60.0 \\ 40.0|54.7 \\ 56.7|54.5 \\ 52.5\n",
    "5                          |62.0 \\ 44.0|55.3 \\ 53.0|53.2 \\ 49.8\n",
    "10                         |57.3 \\ 44.0|53.7 \\ 52.0|52.0 \\ 53.0\n",
    "20                         |60.0 \\ 43.3|55.7 \\ 50.7|53.3 \\ 53.2\n",
    "\n",
    "The obtained performances are surprisingly unsatisfactory. The `min_freq` parameter does not seem to play a very discriminating role here, as we find the best accuracy values for low and high number of documents.\n",
    "\n",
    "Regarding testing accuracy, the models struggles to generalize well. Maybe it overfits the data: 10 epochs may be too much for the trainings. However, early stopping should prevent that, and even validating accuracies are not so good. We may explain this phenomenom by the number of samples we have chosen. Among the 25 000 documents of the universe, the highest number of samples we selected is 1600. The conclusions might be different if we consider a higher number, but it requires more computation time than the one we have.\n",
    "\n",
    "Considering the results of the other models on the same datasets, we simply would have expected better results from LSTM models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mD6vR9GUQJ44"
   },
   "source": [
    "\n",
    "### CNN models\n",
    "\n",
    "*CNN model: not-pretrained embedding*\n",
    "\n",
    "min_freq \\ Training samples| 400       | 800       |1600      \n",
    "---------------------------|-----------|-----------|-----------\n",
    "1                          |57.3 \\ 56.0|55.3 \\ 58.7|60.3 \\ 63.8\n",
    "3                          |48.7 \\ 48.3|59.7 \\ 61.3|**64.3 \\ 64.5**\n",
    "5                          |54.7 \\ 58.7|54.3 \\ 57.3|56.2 \\ 55.8\n",
    "10                         |45.3 \\ 50.7|52.0 \\ 55.7|59.0 \\ 59.8\n",
    "20                         |49.3 \\ 55.3|52.0 \\ 52.7|54.5 \\ 60.0\n",
    "\n",
    "*CNN model: pretrained embedding, without fine-tuning*\n",
    "\n",
    "min_freq \\ Training samples| 400       | 800       |1600      \n",
    "---------------------------|-----------|-----------|-----------\n",
    "1                          |**61.3 \\ 59.3**|**68.0 \\ 67.0**|**76.2 \\ 78.5**\n",
    "3                          |49.3 \\ 45.3|52.7 \\ 51.0|71.8 \\ 71.2\n",
    "5                          |58.0 \\ 52.0|65.7 \\ 64.0|67.7 \\ 66.3\n",
    "10                         |48.7 \\ 47.3|58.0 \\ 59.0|69.3 \\ 72.0\n",
    "20                         |59.3 \\ 52.7|49.7 \\ 48.0|69.8 \\ 69.7\n",
    "\n",
    "*CNN model: pretrained embedding, with fine-tuning*\n",
    "\n",
    "min_freq \\ Training samples| 400       | 800       |1600      \n",
    "---------------------------|-----------|-----------|-----------\n",
    "1                          |**56.0 \\ 54.0**|**77.7 \\ 73.7**|66.5 \\ 66.0\n",
    "3                          |49.3 \\ 46.7|54.3 \\ 55.7|51.2 \\ 52.3\n",
    "5                          |48.0 \\ 48.0|58.0 \\ 59.7|**68.5 \\ 68.5**\n",
    "10                         |46.0 \\ 42.7|46.3 \\ 45.7|56.2 \\ 57.5\n",
    "20                         |47.3 \\ 44.0|71.0 \\ 67.3|67.7 \\ 65.0\n",
    "\n",
    "CNN models show satisfying results. It seems to logically favor bigger vocabularies, once again.\n",
    "\n",
    "This time, the best embedding seems to be the pretrained one, but **without fine-tuning**. It differs from the conclusion on Averaging models. It could be explained by the fact that, in this case, the convolutional layer has enough expressivity to exploit well the pretrained GloVe embeddings features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xOdfEyoPHpzp"
   },
   "source": [
    "### In a nutshell\n",
    "\n",
    "\n",
    "With every model we implemented, and regardless of the vocabulary size we consider, the best results are obtained with a higher number of training samples. The further we go into the learning, the higher accuracy score we get. We did our grid search by considering at most 10 epochs, and with `early_stopping` parameter at `True`. With `early_stopping` on, `experiment` function only allows the loss function to strictly decrease. Training the models with a higher number of epochs on a higher number of samples would allow the models to generalize better, then we would have found more diversity in the output scores and the conclusions might vary.\n",
    "\n",
    "The LSTM model we implemented is the least performant one in the context of our experiment, with the hyperparameters we fixed. In the litterature, LSTM architecture is useful for POS-Tagging and sentiment classification, often combined with a softmax activation function for multi-labelling. Therefore, considering other optimizing methods and other criterions will also be useful to have a better viewpoint on the text classification problem. CNN architecture is widely spread for classification, especially classification of images, while LSTM architecture and more generally RNN architecture have a better prediction power, as they carry information throught time and then they can infer better what's come next in a sequence.\n",
    "\n",
    "In conclusion, in the context of our experiments, we have found that on the biggest of analysed dataset (1600 training samples), the two models which can perform the best are:\n",
    "- Averaging model with min_freq=3, pretrained and fine-tuned embedding\n",
    "- CNN model, min_freq=1, pretrained embedding without fine-tuning\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Sentiment_Classification_IMDB_Ange_Valli.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
